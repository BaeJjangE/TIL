{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e96b12c6",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0d67d",
   "metadata": {},
   "source": [
    "## 1. 레이블별 폴더 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0742cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "print(len(train_df[\"label\"].unique()))  # type = numpy.array\n",
    "label_list = train_df[\"label\"].unique().tolist()\n",
    "len(label_list)  # type = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301adeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "for i in range(len(label_list)):  # 레이블 개수 만큼 \n",
    "    createFolder(f'./train/{label_list[i]}')  # 레이블 폴더를 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb0e06",
   "metadata": {},
   "source": [
    "## 2. 이미지 파일을 레이블에 맞게 각 폴더로 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1433c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.listdir('./train/')\n",
    "train_folder = sorted(train_folder)\n",
    "len(train_folder)  # -폴더개수 88 , 사진개수 = 4277개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab067e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for i in range(len(train_folder) - 88):  # 폴더 생성한것 88개 뺴주는 겁니다.\n",
    "    \n",
    "    if train_folder[i][-3:] == \"png\":   # 확장자가 png면 \n",
    "        label = train_df.loc[train_df[\"file_name\"] == f\"{train_folder[i]}\"][\"label\"][i]  # train_df에서 이미지 이름에 맞는 label을 불러와 저장\n",
    "        file_source = f'./train/{train_folder[i]}'  # train 폴더에 있는 해당 이미지를\n",
    "        file_destination = f'./train/{label}/'  # 해당 label 폴더로 이동 \n",
    "        shutil.move(file_source, file_destination)  # 이동 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48cd7bb",
   "metadata": {},
   "source": [
    "## 3. 오버샘플링\n",
    "- good 데이터 200개 이상 but 나머지 데이터들 4~15개\n",
    "- 데이터 불균형을 해소해주기 위하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "label_list = train_df[\"label\"].unique().tolist()\n",
    "label_list = sorted(label_list)\n",
    "len(label_list)  # type = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 안 파일 개수를 가져오는 함수\n",
    "def get_num_of_files(directory):\n",
    "    dirListing = os.listdir(directory)\n",
    "    return len(dirListing)\n",
    "\n",
    "\n",
    "# 15개 good 폴더의 파일 개수만 출력해보기\n",
    "for label in label_list:\n",
    "    num_files = get_num_of_files(f'train_state/{label}/')\n",
    "    if num_files > 50:\n",
    "        print(num_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39557ea",
   "metadata": {},
   "source": [
    "### -> good 중의 최솟값인 200에 맞춰서 이상치를 오버샘플링해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 폴더 이름 리스트\n",
    "anomaly_label_list = []\n",
    "\n",
    "for label in label_list:\n",
    "    if label[-4:] != 'good':\n",
    "        anomaly_label_list.append(label)\n",
    "\n",
    "\n",
    "len(anomaly_label_list) # 88-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34336d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 폴더 73개에 대해 for loop\n",
    "# 폴더 내 파일들을 복사하되, 폴더 내 파일 개수가 200개 이상이 되면 stop\n",
    "\n",
    "for dir in anomaly_label_list:\n",
    "    current_dir = f'train_state/{dir}'\n",
    "    \n",
    "    original_file_list = []\n",
    "    for file in os.listdir(current_dir):\n",
    "        if len(file) == 9:\n",
    "            original_file_list.append(file)\n",
    "\n",
    "    whole_file_list = os.listdir(current_dir)\n",
    "\n",
    "    while len(whole_file_list) < 200:\n",
    "        for file in original_file_list:\n",
    "            t = float(time.time())\n",
    "            shutil.copyfile(f'{current_dir}/{file}', f'{current_dir}/{t}-{file}')\n",
    "        whole_file_list = os.listdir(current_dir)\n",
    "\n",
    "    print(f'{dir} complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d11e4",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d02115",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import scipy as sp\n",
    "import PIL\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras import models, layers, Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, ZeroPadding2D\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import EfficientNetB3, ResNet50V2, DenseNet121, VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529e76e",
   "metadata": {},
   "source": [
    "## Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentDirectory = \"./\"\n",
    "\n",
    "train_directory = CurrentDirectory + 'train/'\n",
    "test_directory  = CurrentDirectory + 'test/'\n",
    "model_directory = CurrentDirectory + 'model/'\n",
    "tensorboard_directory = CurrentDirectory + 'Tensorboard'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b29b36",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cd1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size: 한번에 forward & Backword 하는 샘플의 수\n",
    "batch_size = 32 # 메모리 문제 때문에 AWS:16~Colab32\n",
    "\n",
    "# Epochs 수\n",
    "epochs = 50\n",
    "\n",
    "# Weight 조절 parameter\n",
    "LearningRate = 1e-3 # 0.001\n",
    "Decay = 1e-6\n",
    "\n",
    "# 이미지 데이터 입력값\n",
    "img_width = 384\n",
    "img_height = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb89af",
   "metadata": {},
   "source": [
    "## ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 도중 이미지 임의 변형 및 정규화 적용 가능\n",
    "# 1. 이미지를 전부다 불러서 램 (메모리)에 올릴 수 없기 때문\n",
    "# 2. 이미지는 Augmentation을 해주는게 좋아서\n",
    "DATAGEN_TRAIN = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=70, # 오버샘플링 해주고나서 20->70으로 높게 줌\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\",\n",
    "    validation_split=0.10) # Train / Validation\n",
    "\n",
    "# Test 데이터에는 Augmentation 적용하지 않음\n",
    "DATAGEN_TEST = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08259fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_from_directory - 이미지가 폴더별로 분류되어 있을 경우 subdirectory 이름에 맞춰 자동으로 target class 만듦\n",
    "# Generator의 instance 생성 (Train)\n",
    "TRAIN_GENERATOR = DATAGEN_TRAIN.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode= \"categorical\",\n",
    "    subset = \"training\")\n",
    "\n",
    "VALID_GENERATOR = DATAGEN_TRAIN.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset = \"validation\")\n",
    "\n",
    "# Generator의 instance 생성 (Test)\n",
    "TEST_GENERATOR = DATAGEN_TEST.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALID_GENERATOR가 target class 모두 포함하는지 확인\n",
    "len(pd.Series( VALID_GENERATOR.labels ).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b5df78",
   "metadata": {},
   "source": [
    "# Models\n",
    "- EfficientNetB3, ResNet50V2, DenseNet121, VGG19 총 4개의 모델 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf183de6",
   "metadata": {},
   "source": [
    "#### Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b498ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call-back 함수\n",
    "# CheckPoint: Epoch 마다 val_loss를 확인하여, 값이 향상되었을 경우에만 저장\n",
    "CP = ModelCheckpoint(filepath=model_directory+'Efnet-{epoch:03d}-{val_loss:.4f}-{val_acc:.4f}.hdf5',\n",
    "            monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# 학습과정 진행사항 확인\n",
    "TB = TensorBoard(log_dir=tensorboard_directory, write_graph=True, write_images=True)\n",
    "\n",
    "# 모델의 개선이 없을 경우 Learning rate 조절\n",
    "LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-7)\n",
    "\n",
    "CALLBACK = [CP, TB, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce6a5a",
   "metadata": {},
   "source": [
    "## EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_1 = tf.keras.applications.efficientnet.EfficientNetB3(\n",
    "    include_top=None,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_width,img_height,3),\n",
    "    pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(Model_1.output)\n",
    "predictions = Dense(88, activation='softmax')(x)\n",
    "\n",
    "Efnet = Model(inputs=Model_1.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "Efnet.compile(optimizer=\n",
    "         SGD(learning_rate=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc'])\n",
    "\n",
    "# Training Start\n",
    "Efnet.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        # steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2debd36b",
   "metadata": {},
   "source": [
    "### ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_2 = tf.keras.applications.ResNet50V2(\n",
    "    include_top=None,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_width,img_height,3),\n",
    "    pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(Model_2.output)\n",
    "predictions = Dense(88, activation='softmax')(x)\n",
    "\n",
    "Resnet = Model(inputs=Model_2.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "Resnet.compile(optimizer=\n",
    "         SGD(learning_rate=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc'])\n",
    "\n",
    "# Training Start\n",
    "Resnet.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        # steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2383752",
   "metadata": {},
   "source": [
    "### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_3 = tf.keras.applications.DenseNet121(\n",
    "    include_top=None,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_width,img_height,3),\n",
    "    pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(Model_3.output)\n",
    "predictions = Dense(88, activation='softmax')(x)\n",
    "\n",
    "Dsnet = Model(inputs=Model_3.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "Dsnet.compile(optimizer=\n",
    "         SGD(learning_rate=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc'])\n",
    "\n",
    "# Training Start\n",
    "Dsnet.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        # steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb56ef",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_4 = tf.keras.applications.VGG19(\n",
    "    include_top=None,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_width,img_height,3),\n",
    "    pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(Model_4.output)\n",
    "predictions = Dense(88, activation='softmax')(x)\n",
    "\n",
    "Vgg19 = Model(inputs=Model_4.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "Vgg19.compile(optimizer=\n",
    "         SGD(learning_rate=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc'])\n",
    "\n",
    "# Training Start\n",
    "Vgg19.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        # steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d042a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Efnet.load_weights(\"EfnetB3-008-0.0134-0.9951.hdf5\")\n",
    "Resnet.load_weights(\")\n",
    "Dsnet.load_weights(\"DenseNet121-019-0.0042-0.9984.hdf5\")\n",
    "Vgg19.load_weights(\" model_vgg19-036-0.0489-0.9850.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52cb79f",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_Efnet = Efnet.predict_generator(TEST_GENERATOR, verbose=1)\n",
    "prediction_Resnet = Resnet.predict_generator(TEST_GENERATOR, verbose=1)\n",
    "prediction_Dsnet = Dsnet.predict_generator(TEST_GENERATOR, verbose=1)\n",
    "prediction_Vgg19 = Vgg19.predict_generator(TEST_GENERATOR, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a15655",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d438b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]\n",
    "\n",
    "label_decoder = {val:key for key, val in label_unique.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred = []\n",
    "\n",
    "### 모델에 맞게 prediction 값 변경\n",
    "for i in range(len(prediction_Efnet)):\n",
    "    f_pred.append(prediction_Efnet[i].argmax())\n",
    "    \n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission.to_csv(\"원하는이름.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d2eeb",
   "metadata": {},
   "source": [
    "# Ensemble - SoftVoting\n",
    "- VGG19는 성능이 너무 안좋아서 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c442519",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction = (0.5 * prediction_Efnet) + (0.25 * prediction_Resnet) + (0.25 * prediction_Dsnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]\n",
    "\n",
    "label_decoder = {val:key for key, val in label_unique.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred = []\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    f_pred.append(prediction[i].argmax())\n",
    "    \n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375dd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission.to_csv(\"원하는이름.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
