{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1f38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from flask import Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d671a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0cd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import 데이터 불러오기\n",
    "DataFile = pd.read_csv(\"MY2022 Fuel Consumption Ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75231593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 946 entries, 0 to 945\n",
      "Data columns (total 15 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Model Year                         946 non-null    int64  \n",
      " 1   Make                               946 non-null    object \n",
      " 2   Model                              946 non-null    object \n",
      " 3   Vehicle Class                      946 non-null    object \n",
      " 4   Engine Size(L)                     946 non-null    float64\n",
      " 5   Cylinders                          946 non-null    int64  \n",
      " 6   Transmission                       946 non-null    object \n",
      " 7   Fuel Type                          946 non-null    object \n",
      " 8   Fuel Consumption (City (L/100 km)  946 non-null    float64\n",
      " 9   Fuel Consumption(Hwy (L/100 km))   946 non-null    float64\n",
      " 10  Fuel Consumption(Comb (L/100 km))  946 non-null    float64\n",
      " 11  Fuel Consumption(Comb (mpg))       946 non-null    int64  \n",
      " 12  CO2 Emissions(g/km)                946 non-null    int64  \n",
      " 13  CO2 Rating                         946 non-null    int64  \n",
      " 14  Smog Rating                        946 non-null    int64  \n",
      "dtypes: float64(4), int64(6), object(5)\n",
      "memory usage: 111.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분석했었던 것 읽어오기\n",
    "DataFile.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf42f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Model Year', 'Make', 'Model', 'Vehicle Class', 'Engine Size(L)',\n",
       "       'Cylinders', 'Transmission', 'Fuel Type',\n",
       "       'Fuel Consumption (City (L/100 km)', 'Fuel Consumption(Hwy (L/100 km))',\n",
       "       'Fuel Consumption(Comb (L/100 km))', 'Fuel Consumption(Comb (mpg))',\n",
       "       'CO2 Emissions(g/km)', 'CO2 Rating', 'Smog Rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column들 보기\n",
    "DataFile.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46b43ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cylinders', 'Fuel Consumption(Comb (L/100 km))', 'CO2 Rating'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중요한 변수 3가지만 일단 선택 (API 서비스를 위한)\n",
    "DataFile.columns[[5, 10, 13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cbff197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 선택 및 X, Y 데이터 선정\n",
    "Data = DataFile[DataFile.columns[[5, 10, 13]]]\n",
    "Label = DataFile['CO2 Emissions(g/km)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "972538a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Valid 나누기\n",
    "TrainX = Data.iloc[:-200,:]\n",
    "TrainY = Label[:-200]\n",
    "\n",
    "ValidX = Data.iloc[-200:,:]\n",
    "ValidY = Label[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe0bb109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Fuel Consumption(Comb (L/100 km))</th>\n",
       "      <th>CO2 Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cylinders  Fuel Consumption(Comb (L/100 km))  CO2 Rating\n",
       "0            4                                8.6           6\n",
       "1            6                               11.2           4\n",
       "2            4                                9.9           5\n",
       "3            4                               10.3           5\n",
       "4            4                                9.8           5\n",
       "..         ...                                ...         ...\n",
       "741          4                                7.3           7\n",
       "742          4                                7.9           6\n",
       "743          4                                8.1           6\n",
       "744          4                                6.7           7\n",
       "745          4                                7.7           7\n",
       "\n",
       "[746 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f885eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구조\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# CallBack 함수를 통해 LR을 낮출 것이므로, 초기 LR을 높게 잡기\n",
    "model.compile(loss='mse',\n",
    "              optimizer='Adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "#0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609eab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 32        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "377b72c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 저장할 폴더 위치 선정\n",
    "os.makedirs('Model', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d3d0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call-back 함수\n",
    "# CheckPoint: Epoch 마다 validation 성능을 검증하여, best performance 일 경우 저장\n",
    "CP = ModelCheckpoint(filepath='Model/{epoch:03d}-{loss:.4f}-{val_loss:.4f}.hdf5',\n",
    "            monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#minitor -> loss -> val_loss\n",
    "\n",
    "# Learning Rate 줄여나가기\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.95, patience=5,\n",
    "                       verbose=1, min_lr=1e-8)\n",
    "# factor: Learning rate에 곱할 것.\n",
    "#0.1 -> 0.08 -> 0.064 ....\n",
    "#monitor='loss' -> monitor='val_loss'\n",
    "\n",
    "CALLBACK = [CP, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "882e5737",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      " 1/16 [>.............................] - ETA: 4s - loss: 71109.8594 - root_mean_squared_error: 266.6643\n",
      "Epoch 1: val_loss improved from inf to 65876.73438, saving model to Model\\001-72098.7578-65876.7344.hdf5\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 72098.7578 - root_mean_squared_error: 268.5121 - val_loss: 65876.7344 - val_root_mean_squared_error: 256.6646 - lr: 0.0010\n",
      "Epoch 2/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 63821.6562 - root_mean_squared_error: 252.6295\n",
      "Epoch 2: val_loss improved from 65876.73438 to 64633.64453, saving model to Model\\002-70806.1875-64633.6445.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 70806.1875 - root_mean_squared_error: 266.0943 - val_loss: 64633.6445 - val_root_mean_squared_error: 254.2315 - lr: 0.0010\n",
      "Epoch 3/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 68692.8125 - root_mean_squared_error: 262.0931\n",
      "Epoch 3: val_loss improved from 64633.64453 to 63195.48828, saving model to Model\\003-69322.0938-63195.4883.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 69322.0938 - root_mean_squared_error: 263.2909 - val_loss: 63195.4883 - val_root_mean_squared_error: 251.3871 - lr: 0.0010\n",
      "Epoch 4/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 69631.4688 - root_mean_squared_error: 263.8777\n",
      "Epoch 4: val_loss improved from 63195.48828 to 61282.75000, saving model to Model\\004-67519.1484-61282.7500.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 67519.1484 - root_mean_squared_error: 259.8445 - val_loss: 61282.7500 - val_root_mean_squared_error: 247.5535 - lr: 0.0010\n",
      "Epoch 5/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 64667.5469 - root_mean_squared_error: 254.2981\n",
      "Epoch 5: val_loss improved from 61282.75000 to 58785.26562, saving model to Model\\005-65109.8281-58785.2656.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 65109.8281 - root_mean_squared_error: 255.1663 - val_loss: 58785.2656 - val_root_mean_squared_error: 242.4567 - lr: 0.0010\n",
      "Epoch 6/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 60022.9805 - root_mean_squared_error: 244.9959\n",
      "Epoch 6: val_loss improved from 58785.26562 to 55750.21484, saving model to Model\\006-62104.5742-55750.2148.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 62104.5742 - root_mean_squared_error: 249.2079 - val_loss: 55750.2148 - val_root_mean_squared_error: 236.1148 - lr: 0.0010\n",
      "Epoch 7/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 63764.3320 - root_mean_squared_error: 252.5160\n",
      "Epoch 7: val_loss improved from 55750.21484 to 52092.76562, saving model to Model\\007-58503.8164-52092.7656.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 58503.8164 - root_mean_squared_error: 241.8756 - val_loss: 52092.7656 - val_root_mean_squared_error: 228.2384 - lr: 0.0010\n",
      "Epoch 8/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 51824.6250 - root_mean_squared_error: 227.6502\n",
      "Epoch 8: val_loss improved from 52092.76562 to 47807.32031, saving model to Model\\008-54183.5781-47807.3203.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 54183.5781 - root_mean_squared_error: 232.7737 - val_loss: 47807.3203 - val_root_mean_squared_error: 218.6488 - lr: 0.0010\n",
      "Epoch 9/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 51328.0898 - root_mean_squared_error: 226.5570\n",
      "Epoch 9: val_loss improved from 47807.32031 to 42859.51953, saving model to Model\\009-49196.7891-42859.5195.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 49196.7891 - root_mean_squared_error: 221.8035 - val_loss: 42859.5195 - val_root_mean_squared_error: 207.0254 - lr: 0.0010\n",
      "Epoch 10/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 48920.8594 - root_mean_squared_error: 221.1806\n",
      "Epoch 10: val_loss improved from 42859.51953 to 37406.87891, saving model to Model\\010-43528.2812-37406.8789.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 43528.2812 - root_mean_squared_error: 208.6343 - val_loss: 37406.8789 - val_root_mean_squared_error: 193.4086 - lr: 0.0010\n",
      "Epoch 11/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 39171.5664 - root_mean_squared_error: 197.9181\n",
      "Epoch 11: val_loss improved from 37406.87891 to 31564.83203, saving model to Model\\011-37382.4531-31564.8320.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 37382.4531 - root_mean_squared_error: 193.3454 - val_loss: 31564.8320 - val_root_mean_squared_error: 177.6649 - lr: 0.0010\n",
      "Epoch 12/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 37619.4023 - root_mean_squared_error: 193.9572\n",
      "Epoch 12: val_loss improved from 31564.83203 to 25606.02344, saving model to Model\\012-30991.9277-25606.0234.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30991.9277 - root_mean_squared_error: 176.0452 - val_loss: 25606.0234 - val_root_mean_squared_error: 160.0188 - lr: 0.0010\n",
      "Epoch 13/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 27130.5059 - root_mean_squared_error: 164.7134\n",
      "Epoch 13: val_loss improved from 25606.02344 to 19855.07422, saving model to Model\\013-24603.0293-19855.0742.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24603.0293 - root_mean_squared_error: 156.8535 - val_loss: 19855.0742 - val_root_mean_squared_error: 140.9080 - lr: 0.0010\n",
      "Epoch 14/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 19425.0605 - root_mean_squared_error: 139.3738\n",
      "Epoch 14: val_loss improved from 19855.07422 to 14523.19238, saving model to Model\\014-18611.6660-14523.1924.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 18611.6660 - root_mean_squared_error: 136.4246 - val_loss: 14523.1924 - val_root_mean_squared_error: 120.5122 - lr: 0.0010\n",
      "Epoch 15/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 16147.7842 - root_mean_squared_error: 127.0739\n",
      "Epoch 15: val_loss improved from 14523.19238 to 9997.09473, saving model to Model\\015-13222.1768-9997.0947.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13222.1768 - root_mean_squared_error: 114.9877 - val_loss: 9997.0947 - val_root_mean_squared_error: 99.9855 - lr: 0.0010\n",
      "Epoch 16/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 12265.4580 - root_mean_squared_error: 110.7495\n",
      "Epoch 16: val_loss improved from 9997.09473 to 6373.17383, saving model to Model\\016-8801.1221-6373.1738.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8801.1221 - root_mean_squared_error: 93.8143 - val_loss: 6373.1738 - val_root_mean_squared_error: 79.8322 - lr: 0.0010\n",
      "Epoch 17/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 6978.3716 - root_mean_squared_error: 83.5367\n",
      "Epoch 17: val_loss improved from 6373.17383 to 3783.47314, saving model to Model\\017-5432.7236-3783.4731.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5432.7236 - root_mean_squared_error: 73.7070 - val_loss: 3783.4731 - val_root_mean_squared_error: 61.5099 - lr: 0.0010\n",
      "Epoch 18/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 3697.1631 - root_mean_squared_error: 60.8043\n",
      "Epoch 18: val_loss improved from 3783.47314 to 2098.95752, saving model to Model\\018-3146.2786-2098.9575.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3146.2786 - root_mean_squared_error: 56.0917 - val_loss: 2098.9575 - val_root_mean_squared_error: 45.8144 - lr: 0.0010\n",
      "Epoch 19/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 2372.5242 - root_mean_squared_error: 48.7086\n",
      "Epoch 19: val_loss improved from 2098.95752 to 1149.99194, saving model to Model\\019-1732.5552-1149.9919.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1732.5552 - root_mean_squared_error: 41.6240 - val_loss: 1149.9919 - val_root_mean_squared_error: 33.9115 - lr: 0.0010\n",
      "Epoch 20/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 1321.9507 - root_mean_squared_error: 36.3586\n",
      "Epoch 20: val_loss improved from 1149.99194 to 665.77509, saving model to Model\\020-989.3952-665.7751.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 989.3952 - root_mean_squared_error: 31.4547 - val_loss: 665.7751 - val_root_mean_squared_error: 25.8026 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 661.9717 - root_mean_squared_error: 25.7288\n",
      "Epoch 21: val_loss improved from 665.77509 to 452.71927, saving model to Model\\021-636.8138-452.7193.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 636.8138 - root_mean_squared_error: 25.2352 - val_loss: 452.7193 - val_root_mean_squared_error: 21.2772 - lr: 0.0010\n",
      "Epoch 22/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 522.1291 - root_mean_squared_error: 22.8501\n",
      "Epoch 22: val_loss improved from 452.71927 to 366.37259, saving model to Model\\022-495.3651-366.3726.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 495.3651 - root_mean_squared_error: 22.2568 - val_loss: 366.3726 - val_root_mean_squared_error: 19.1409 - lr: 0.0010\n",
      "Epoch 23/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 371.4272 - root_mean_squared_error: 19.2724\n",
      "Epoch 23: val_loss improved from 366.37259 to 335.44171, saving model to Model\\023-444.0561-335.4417.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 444.0561 - root_mean_squared_error: 21.0726 - val_loss: 335.4417 - val_root_mean_squared_error: 18.3151 - lr: 0.0010\n",
      "Epoch 24/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 647.8023 - root_mean_squared_error: 25.4520\n",
      "Epoch 24: val_loss improved from 335.44171 to 323.82819, saving model to Model\\024-427.9716-323.8282.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 427.9716 - root_mean_squared_error: 20.6875 - val_loss: 323.8282 - val_root_mean_squared_error: 17.9952 - lr: 0.0010\n",
      "Epoch 25/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 310.9982 - root_mean_squared_error: 17.6351\n",
      "Epoch 25: val_loss improved from 323.82819 to 319.64926, saving model to Model\\025-424.1386-319.6493.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 424.1386 - root_mean_squared_error: 20.5946 - val_loss: 319.6493 - val_root_mean_squared_error: 17.8787 - lr: 0.0010\n",
      "Epoch 26/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 403.5762 - root_mean_squared_error: 20.0892\n",
      "Epoch 26: val_loss improved from 319.64926 to 317.56409, saving model to Model\\026-422.8546-317.5641.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 422.8546 - root_mean_squared_error: 20.5634 - val_loss: 317.5641 - val_root_mean_squared_error: 17.8203 - lr: 0.0010\n",
      "Epoch 27/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 543.3525 - root_mean_squared_error: 23.3099\n",
      "Epoch 27: val_loss improved from 317.56409 to 315.80750, saving model to Model\\027-422.4226-315.8075.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 422.4226 - root_mean_squared_error: 20.5529 - val_loss: 315.8075 - val_root_mean_squared_error: 17.7710 - lr: 0.0010\n",
      "Epoch 28/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 303.4904 - root_mean_squared_error: 17.4210\n",
      "Epoch 28: val_loss improved from 315.80750 to 314.59024, saving model to Model\\028-421.9854-314.5902.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 421.9854 - root_mean_squared_error: 20.5423 - val_loss: 314.5902 - val_root_mean_squared_error: 17.7367 - lr: 0.0010\n",
      "Epoch 29/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 510.1516 - root_mean_squared_error: 22.5865\n",
      "Epoch 29: val_loss improved from 314.59024 to 314.13983, saving model to Model\\029-421.2693-314.1398.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 421.2693 - root_mean_squared_error: 20.5248 - val_loss: 314.1398 - val_root_mean_squared_error: 17.7240 - lr: 0.0010\n",
      "Epoch 30/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 431.7998 - root_mean_squared_error: 20.7798\n",
      "Epoch 30: val_loss did not improve from 314.13983\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 421.3621 - root_mean_squared_error: 20.5271 - val_loss: 314.2700 - val_root_mean_squared_error: 17.7277 - lr: 0.0010\n",
      "Epoch 31/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 292.3217 - root_mean_squared_error: 17.0974\n",
      "Epoch 31: val_loss improved from 314.13983 to 313.00378, saving model to Model\\031-420.2836-313.0038.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 420.2836 - root_mean_squared_error: 20.5008 - val_loss: 313.0038 - val_root_mean_squared_error: 17.6919 - lr: 0.0010\n",
      "Epoch 32/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 335.9657 - root_mean_squared_error: 18.3294\n",
      "Epoch 32: val_loss improved from 313.00378 to 311.85754, saving model to Model\\032-419.7027-311.8575.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 419.7027 - root_mean_squared_error: 20.4866 - val_loss: 311.8575 - val_root_mean_squared_error: 17.6595 - lr: 0.0010\n",
      "Epoch 33/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 425.5732 - root_mean_squared_error: 20.6294\n",
      "Epoch 33: val_loss improved from 311.85754 to 310.88275, saving model to Model\\033-419.2051-310.8828.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 419.2051 - root_mean_squared_error: 20.4745 - val_loss: 310.8828 - val_root_mean_squared_error: 17.6319 - lr: 0.0010\n",
      "Epoch 34/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 732.6622 - root_mean_squared_error: 27.0677\n",
      "Epoch 34: val_loss improved from 310.88275 to 309.23666, saving model to Model\\034-418.6296-309.2367.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 418.6296 - root_mean_squared_error: 20.4604 - val_loss: 309.2367 - val_root_mean_squared_error: 17.5851 - lr: 0.0010\n",
      "Epoch 35/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 289.0746 - root_mean_squared_error: 17.0022\n",
      "Epoch 35: val_loss improved from 309.23666 to 308.43948, saving model to Model\\035-418.2598-308.4395.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 418.2598 - root_mean_squared_error: 20.4514 - val_loss: 308.4395 - val_root_mean_squared_error: 17.5624 - lr: 0.0010\n",
      "Epoch 36/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 514.6754 - root_mean_squared_error: 22.6865\n",
      "Epoch 36: val_loss improved from 308.43948 to 307.13782, saving model to Model\\036-417.5066-307.1378.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 417.5066 - root_mean_squared_error: 20.4330 - val_loss: 307.1378 - val_root_mean_squared_error: 17.5253 - lr: 0.0010\n",
      "Epoch 37/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 385.7542 - root_mean_squared_error: 19.6406\n",
      "Epoch 37: val_loss improved from 307.13782 to 306.66632, saving model to Model\\037-416.9406-306.6663.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 416.9406 - root_mean_squared_error: 20.4191 - val_loss: 306.6663 - val_root_mean_squared_error: 17.5119 - lr: 0.0010\n",
      "Epoch 38/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 310.3084 - root_mean_squared_error: 17.6156\n",
      "Epoch 38: val_loss improved from 306.66632 to 305.57565, saving model to Model\\038-416.4463-305.5757.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 416.4463 - root_mean_squared_error: 20.4070 - val_loss: 305.5757 - val_root_mean_squared_error: 17.4807 - lr: 0.0010\n",
      "Epoch 39/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 381.0519 - root_mean_squared_error: 19.5205\n",
      "Epoch 39: val_loss improved from 305.57565 to 304.75409, saving model to Model\\039-415.8196-304.7541.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 415.8196 - root_mean_squared_error: 20.3917 - val_loss: 304.7541 - val_root_mean_squared_error: 17.4572 - lr: 0.0010\n",
      "Epoch 40/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 413.5757 - root_mean_squared_error: 20.3366\n",
      "Epoch 40: val_loss improved from 304.75409 to 303.72461, saving model to Model\\040-415.2006-303.7246.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 415.2006 - root_mean_squared_error: 20.3765 - val_loss: 303.7246 - val_root_mean_squared_error: 17.4277 - lr: 0.0010\n",
      "Epoch 41/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 815.2313 - root_mean_squared_error: 28.5523\n",
      "Epoch 41: val_loss improved from 303.72461 to 302.55423, saving model to Model\\041-414.6058-302.5542.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 414.6058 - root_mean_squared_error: 20.3619 - val_loss: 302.5542 - val_root_mean_squared_error: 17.3941 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 456.6886 - root_mean_squared_error: 21.3703\n",
      "Epoch 42: val_loss improved from 302.55423 to 301.17093, saving model to Model\\042-414.1975-301.1709.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 414.1975 - root_mean_squared_error: 20.3518 - val_loss: 301.1709 - val_root_mean_squared_error: 17.3543 - lr: 0.0010\n",
      "Epoch 43/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 238.0776 - root_mean_squared_error: 15.4298\n",
      "Epoch 43: val_loss improved from 301.17093 to 299.65106, saving model to Model\\043-413.5880-299.6511.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 413.5880 - root_mean_squared_error: 20.3369 - val_loss: 299.6511 - val_root_mean_squared_error: 17.3104 - lr: 0.0010\n",
      "Epoch 44/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 320.3386 - root_mean_squared_error: 17.8980\n",
      "Epoch 44: val_loss improved from 299.65106 to 299.35098, saving model to Model\\044-412.6516-299.3510.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 412.6516 - root_mean_squared_error: 20.3138 - val_loss: 299.3510 - val_root_mean_squared_error: 17.3018 - lr: 0.0010\n",
      "Epoch 45/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 478.8102 - root_mean_squared_error: 21.8817\n",
      "Epoch 45: val_loss improved from 299.35098 to 298.67664, saving model to Model\\045-412.1937-298.6766.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 412.1937 - root_mean_squared_error: 20.3026 - val_loss: 298.6766 - val_root_mean_squared_error: 17.2823 - lr: 0.0010\n",
      "Epoch 46/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 331.8200 - root_mean_squared_error: 18.2159\n",
      "Epoch 46: val_loss improved from 298.67664 to 296.92587, saving model to Model\\046-411.4059-296.9259.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 411.4059 - root_mean_squared_error: 20.2831 - val_loss: 296.9259 - val_root_mean_squared_error: 17.2315 - lr: 0.0010\n",
      "Epoch 47/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 449.7614 - root_mean_squared_error: 21.2076\n",
      "Epoch 47: val_loss improved from 296.92587 to 295.38098, saving model to Model\\047-411.0961-295.3810.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 411.0961 - root_mean_squared_error: 20.2755 - val_loss: 295.3810 - val_root_mean_squared_error: 17.1867 - lr: 0.0010\n",
      "Epoch 48/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 437.7193 - root_mean_squared_error: 20.9217\n",
      "Epoch 48: val_loss improved from 295.38098 to 294.87796, saving model to Model\\048-410.1749-294.8780.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 410.1749 - root_mean_squared_error: 20.2528 - val_loss: 294.8780 - val_root_mean_squared_error: 17.1720 - lr: 0.0010\n",
      "Epoch 49/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 537.4764 - root_mean_squared_error: 23.1835\n",
      "Epoch 49: val_loss improved from 294.87796 to 294.24139, saving model to Model\\049-409.5909-294.2414.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 409.5909 - root_mean_squared_error: 20.2384 - val_loss: 294.2414 - val_root_mean_squared_error: 17.1535 - lr: 0.0010\n",
      "Epoch 50/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 404.0160 - root_mean_squared_error: 20.1001\n",
      "Epoch 50: val_loss improved from 294.24139 to 292.44595, saving model to Model\\050-409.2750-292.4460.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 409.2750 - root_mean_squared_error: 20.2305 - val_loss: 292.4460 - val_root_mean_squared_error: 17.1011 - lr: 0.0010\n",
      "Epoch 51/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 705.9660 - root_mean_squared_error: 26.5700\n",
      "Epoch 51: val_loss improved from 292.44595 to 291.43396, saving model to Model\\051-408.2205-291.4340.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 408.2205 - root_mean_squared_error: 20.2045 - val_loss: 291.4340 - val_root_mean_squared_error: 17.0714 - lr: 0.0010\n",
      "Epoch 52/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 366.3051 - root_mean_squared_error: 19.1391\n",
      "Epoch 52: val_loss improved from 291.43396 to 289.91144, saving model to Model\\052-407.6180-289.9114.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 407.6180 - root_mean_squared_error: 20.1896 - val_loss: 289.9114 - val_root_mean_squared_error: 17.0268 - lr: 0.0010\n",
      "Epoch 53/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 332.8554 - root_mean_squared_error: 18.2443\n",
      "Epoch 53: val_loss improved from 289.91144 to 288.77588, saving model to Model\\053-406.9276-288.7759.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 406.9276 - root_mean_squared_error: 20.1724 - val_loss: 288.7759 - val_root_mean_squared_error: 16.9934 - lr: 0.0010\n",
      "Epoch 54/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 494.2881 - root_mean_squared_error: 22.2326\n",
      "Epoch 54: val_loss improved from 288.77588 to 288.39252, saving model to Model\\054-406.3193-288.3925.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 406.3193 - root_mean_squared_error: 20.1574 - val_loss: 288.3925 - val_root_mean_squared_error: 16.9821 - lr: 0.0010\n",
      "Epoch 55/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 470.7232 - root_mean_squared_error: 21.6962\n",
      "Epoch 55: val_loss improved from 288.39252 to 286.69653, saving model to Model\\055-406.0243-286.6965.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 406.0243 - root_mean_squared_error: 20.1500 - val_loss: 286.6965 - val_root_mean_squared_error: 16.9321 - lr: 0.0010\n",
      "Epoch 56/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 386.7269 - root_mean_squared_error: 19.6654\n",
      "Epoch 56: val_loss did not improve from 286.69653\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 405.2007 - root_mean_squared_error: 20.1296 - val_loss: 287.3761 - val_root_mean_squared_error: 16.9522 - lr: 0.0010\n",
      "Epoch 57/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 266.9173 - root_mean_squared_error: 16.3376\n",
      "Epoch 57: val_loss improved from 286.69653 to 285.61087, saving model to Model\\057-404.6556-285.6109.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 404.6556 - root_mean_squared_error: 20.1161 - val_loss: 285.6109 - val_root_mean_squared_error: 16.9000 - lr: 0.0010\n",
      "Epoch 58/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 557.9106 - root_mean_squared_error: 23.6201\n",
      "Epoch 58: val_loss improved from 285.61087 to 283.94910, saving model to Model\\058-404.0924-283.9491.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 404.0924 - root_mean_squared_error: 20.1020 - val_loss: 283.9491 - val_root_mean_squared_error: 16.8508 - lr: 0.0010\n",
      "Epoch 59/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 300.6915 - root_mean_squared_error: 17.3405\n",
      "Epoch 59: val_loss improved from 283.94910 to 282.56372, saving model to Model\\059-403.4198-282.5637.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 403.4198 - root_mean_squared_error: 20.0853 - val_loss: 282.5637 - val_root_mean_squared_error: 16.8096 - lr: 0.0010\n",
      "Epoch 60/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 597.0489 - root_mean_squared_error: 24.4346\n",
      "Epoch 60: val_loss improved from 282.56372 to 281.45935, saving model to Model\\060-402.7466-281.4594.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 402.7466 - root_mean_squared_error: 20.0685 - val_loss: 281.4594 - val_root_mean_squared_error: 16.7768 - lr: 0.0010\n",
      "Epoch 61/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 311.3015 - root_mean_squared_error: 17.6437\n",
      "Epoch 61: val_loss did not improve from 281.45935\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 402.4034 - root_mean_squared_error: 20.0600 - val_loss: 281.4932 - val_root_mean_squared_error: 16.7778 - lr: 0.0010\n",
      "Epoch 62/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 418.2130 - root_mean_squared_error: 20.4503\n",
      "Epoch 62: val_loss improved from 281.45935 to 279.71820, saving model to Model\\062-401.6516-279.7182.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 401.6516 - root_mean_squared_error: 20.0412 - val_loss: 279.7182 - val_root_mean_squared_error: 16.7248 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 273.7302 - root_mean_squared_error: 16.5448\n",
      "Epoch 63: val_loss improved from 279.71820 to 279.24670, saving model to Model\\063-400.9953-279.2467.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 400.9953 - root_mean_squared_error: 20.0249 - val_loss: 279.2467 - val_root_mean_squared_error: 16.7107 - lr: 0.0010\n",
      "Epoch 64/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 474.3464 - root_mean_squared_error: 21.7795\n",
      "Epoch 64: val_loss improved from 279.24670 to 278.57556, saving model to Model\\064-400.6055-278.5756.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 400.6055 - root_mean_squared_error: 20.0151 - val_loss: 278.5756 - val_root_mean_squared_error: 16.6906 - lr: 0.0010\n",
      "Epoch 65/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 215.9086 - root_mean_squared_error: 14.6938\n",
      "Epoch 65: val_loss improved from 278.57556 to 276.85577, saving model to Model\\065-399.6939-276.8558.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 399.6939 - root_mean_squared_error: 19.9923 - val_loss: 276.8558 - val_root_mean_squared_error: 16.6390 - lr: 0.0010\n",
      "Epoch 66/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 381.9333 - root_mean_squared_error: 19.5431\n",
      "Epoch 66: val_loss improved from 276.85577 to 274.95663, saving model to Model\\066-399.0980-274.9566.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 399.0980 - root_mean_squared_error: 19.9774 - val_loss: 274.9566 - val_root_mean_squared_error: 16.5818 - lr: 0.0010\n",
      "Epoch 67/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 207.8134 - root_mean_squared_error: 14.4157\n",
      "Epoch 67: val_loss improved from 274.95663 to 274.24905, saving model to Model\\067-398.5291-274.2491.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 398.5291 - root_mean_squared_error: 19.9632 - val_loss: 274.2491 - val_root_mean_squared_error: 16.5605 - lr: 0.0010\n",
      "Epoch 68/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 231.5799 - root_mean_squared_error: 15.2177\n",
      "Epoch 68: val_loss improved from 274.24905 to 273.19153, saving model to Model\\068-397.9259-273.1915.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 397.9259 - root_mean_squared_error: 19.9481 - val_loss: 273.1915 - val_root_mean_squared_error: 16.5285 - lr: 0.0010\n",
      "Epoch 69/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 425.4184 - root_mean_squared_error: 20.6257\n",
      "Epoch 69: val_loss improved from 273.19153 to 272.54312, saving model to Model\\069-397.5395-272.5431.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 397.5395 - root_mean_squared_error: 19.9384 - val_loss: 272.5431 - val_root_mean_squared_error: 16.5089 - lr: 0.0010\n",
      "Epoch 70/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 267.9228 - root_mean_squared_error: 16.3683\n",
      "Epoch 70: val_loss improved from 272.54312 to 271.92575, saving model to Model\\070-397.2740-271.9258.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 397.2740 - root_mean_squared_error: 19.9317 - val_loss: 271.9258 - val_root_mean_squared_error: 16.4902 - lr: 0.0010\n",
      "Epoch 71/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 343.2337 - root_mean_squared_error: 18.5266\n",
      "Epoch 71: val_loss improved from 271.92575 to 270.23593, saving model to Model\\071-396.1223-270.2359.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 396.1223 - root_mean_squared_error: 19.9028 - val_loss: 270.2359 - val_root_mean_squared_error: 16.4389 - lr: 0.0010\n",
      "Epoch 72/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 299.2510 - root_mean_squared_error: 17.2989\n",
      "Epoch 72: val_loss improved from 270.23593 to 269.07864, saving model to Model\\072-395.6674-269.0786.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 395.6674 - root_mean_squared_error: 19.8914 - val_loss: 269.0786 - val_root_mean_squared_error: 16.4036 - lr: 0.0010\n",
      "Epoch 73/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 786.8664 - root_mean_squared_error: 28.0511\n",
      "Epoch 73: val_loss did not improve from 269.07864\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 395.1351 - root_mean_squared_error: 19.8780 - val_loss: 269.1057 - val_root_mean_squared_error: 16.4044 - lr: 0.0010\n",
      "Epoch 74/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 382.5764 - root_mean_squared_error: 19.5596\n",
      "Epoch 74: val_loss improved from 269.07864 to 267.52112, saving model to Model\\074-394.4228-267.5211.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 394.4228 - root_mean_squared_error: 19.8601 - val_loss: 267.5211 - val_root_mean_squared_error: 16.3561 - lr: 0.0010\n",
      "Epoch 75/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 381.9495 - root_mean_squared_error: 19.5435\n",
      "Epoch 75: val_loss improved from 267.52112 to 266.27542, saving model to Model\\075-393.7265-266.2754.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 393.7265 - root_mean_squared_error: 19.8425 - val_loss: 266.2754 - val_root_mean_squared_error: 16.3179 - lr: 0.0010\n",
      "Epoch 76/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 269.6622 - root_mean_squared_error: 16.4214\n",
      "Epoch 76: val_loss improved from 266.27542 to 265.59167, saving model to Model\\076-393.2334-265.5917.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 393.2334 - root_mean_squared_error: 19.8301 - val_loss: 265.5917 - val_root_mean_squared_error: 16.2970 - lr: 0.0010\n",
      "Epoch 77/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 253.2014 - root_mean_squared_error: 15.9123\n",
      "Epoch 77: val_loss improved from 265.59167 to 264.40686, saving model to Model\\077-392.6505-264.4069.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 392.6505 - root_mean_squared_error: 19.8154 - val_loss: 264.4069 - val_root_mean_squared_error: 16.2606 - lr: 0.0010\n",
      "Epoch 78/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 375.2723 - root_mean_squared_error: 19.3719\n",
      "Epoch 78: val_loss improved from 264.40686 to 264.20218, saving model to Model\\078-392.3594-264.2022.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 392.3594 - root_mean_squared_error: 19.8081 - val_loss: 264.2022 - val_root_mean_squared_error: 16.2543 - lr: 0.0010\n",
      "Epoch 79/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 227.9907 - root_mean_squared_error: 15.0994\n",
      "Epoch 79: val_loss improved from 264.20218 to 261.68738, saving model to Model\\079-391.3746-261.6874.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 391.3746 - root_mean_squared_error: 19.7832 - val_loss: 261.6874 - val_root_mean_squared_error: 16.1768 - lr: 0.0010\n",
      "Epoch 80/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 466.0990 - root_mean_squared_error: 21.5893\n",
      "Epoch 80: val_loss improved from 261.68738 to 261.11633, saving model to Model\\080-390.8186-261.1163.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 390.8186 - root_mean_squared_error: 19.7691 - val_loss: 261.1163 - val_root_mean_squared_error: 16.1591 - lr: 0.0010\n",
      "Epoch 81/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 142.6002 - root_mean_squared_error: 11.9415\n",
      "Epoch 81: val_loss improved from 261.11633 to 260.35919, saving model to Model\\081-390.4108-260.3592.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 390.4108 - root_mean_squared_error: 19.7588 - val_loss: 260.3592 - val_root_mean_squared_error: 16.1357 - lr: 0.0010\n",
      "Epoch 82/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 372.6747 - root_mean_squared_error: 19.3048\n",
      "Epoch 82: val_loss improved from 260.35919 to 259.76843, saving model to Model\\082-389.6465-259.7684.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 389.6465 - root_mean_squared_error: 19.7395 - val_loss: 259.7684 - val_root_mean_squared_error: 16.1173 - lr: 0.0010\n",
      "Epoch 83/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 250.8979 - root_mean_squared_error: 15.8398\n",
      "Epoch 83: val_loss improved from 259.76843 to 259.59286, saving model to Model\\083-389.2427-259.5929.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 389.2427 - root_mean_squared_error: 19.7292 - val_loss: 259.5929 - val_root_mean_squared_error: 16.1119 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 289.2902 - root_mean_squared_error: 17.0085\n",
      "Epoch 84: val_loss improved from 259.59286 to 257.76053, saving model to Model\\084-388.7055-257.7605.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 388.7055 - root_mean_squared_error: 19.7156 - val_loss: 257.7605 - val_root_mean_squared_error: 16.0549 - lr: 0.0010\n",
      "Epoch 85/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 608.5681 - root_mean_squared_error: 24.6692\n",
      "Epoch 85: val_loss improved from 257.76053 to 256.94342, saving model to Model\\085-388.0251-256.9434.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 388.0251 - root_mean_squared_error: 19.6984 - val_loss: 256.9434 - val_root_mean_squared_error: 16.0295 - lr: 0.0010\n",
      "Epoch 86/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 173.1776 - root_mean_squared_error: 13.1597\n",
      "Epoch 86: val_loss improved from 256.94342 to 255.71291, saving model to Model\\086-387.4040-255.7129.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 387.4040 - root_mean_squared_error: 19.6826 - val_loss: 255.7129 - val_root_mean_squared_error: 15.9910 - lr: 0.0010\n",
      "Epoch 87/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 236.7366 - root_mean_squared_error: 15.3862\n",
      "Epoch 87: val_loss improved from 255.71291 to 254.75978, saving model to Model\\087-386.9774-254.7598.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 386.9774 - root_mean_squared_error: 19.6717 - val_loss: 254.7598 - val_root_mean_squared_error: 15.9612 - lr: 0.0010\n",
      "Epoch 88/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 597.8881 - root_mean_squared_error: 24.4518\n",
      "Epoch 88: val_loss improved from 254.75978 to 253.46600, saving model to Model\\088-386.1904-253.4660.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 386.1904 - root_mean_squared_error: 19.6517 - val_loss: 253.4660 - val_root_mean_squared_error: 15.9206 - lr: 0.0010\n",
      "Epoch 89/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 832.0251 - root_mean_squared_error: 28.8448\n",
      "Epoch 89: val_loss improved from 253.46600 to 252.74925, saving model to Model\\089-385.6249-252.7493.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 385.6249 - root_mean_squared_error: 19.6373 - val_loss: 252.7493 - val_root_mean_squared_error: 15.8981 - lr: 0.0010\n",
      "Epoch 90/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 259.1546 - root_mean_squared_error: 16.0983\n",
      "Epoch 90: val_loss improved from 252.74925 to 251.73111, saving model to Model\\090-384.9095-251.7311.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 384.9095 - root_mean_squared_error: 19.6191 - val_loss: 251.7311 - val_root_mean_squared_error: 15.8660 - lr: 0.0010\n",
      "Epoch 91/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 269.2014 - root_mean_squared_error: 16.4074\n",
      "Epoch 91: val_loss improved from 251.73111 to 251.19740, saving model to Model\\091-384.4037-251.1974.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 384.4037 - root_mean_squared_error: 19.6062 - val_loss: 251.1974 - val_root_mean_squared_error: 15.8492 - lr: 0.0010\n",
      "Epoch 92/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 273.3858 - root_mean_squared_error: 16.5344\n",
      "Epoch 92: val_loss improved from 251.19740 to 250.39923, saving model to Model\\092-383.7110-250.3992.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 383.7110 - root_mean_squared_error: 19.5885 - val_loss: 250.3992 - val_root_mean_squared_error: 15.8240 - lr: 0.0010\n",
      "Epoch 93/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 210.6149 - root_mean_squared_error: 14.5126\n",
      "Epoch 93: val_loss improved from 250.39923 to 249.26730, saving model to Model\\093-383.1629-249.2673.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 383.1629 - root_mean_squared_error: 19.5745 - val_loss: 249.2673 - val_root_mean_squared_error: 15.7882 - lr: 0.0010\n",
      "Epoch 94/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 381.0437 - root_mean_squared_error: 19.5203\n",
      "Epoch 94: val_loss improved from 249.26730 to 247.40390, saving model to Model\\094-382.5263-247.4039.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 382.5263 - root_mean_squared_error: 19.5583 - val_loss: 247.4039 - val_root_mean_squared_error: 15.7291 - lr: 0.0010\n",
      "Epoch 95/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 680.0491 - root_mean_squared_error: 26.0778\n",
      "Epoch 95: val_loss improved from 247.40390 to 246.51445, saving model to Model\\095-382.0362-246.5145.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 382.0362 - root_mean_squared_error: 19.5457 - val_loss: 246.5145 - val_root_mean_squared_error: 15.7008 - lr: 0.0010\n",
      "Epoch 96/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 387.8949 - root_mean_squared_error: 19.6950\n",
      "Epoch 96: val_loss improved from 246.51445 to 246.34508, saving model to Model\\096-381.4652-246.3451.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 381.4652 - root_mean_squared_error: 19.5311 - val_loss: 246.3451 - val_root_mean_squared_error: 15.6954 - lr: 0.0010\n",
      "Epoch 97/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 579.7272 - root_mean_squared_error: 24.0775\n",
      "Epoch 97: val_loss improved from 246.34508 to 244.12167, saving model to Model\\097-380.4563-244.1217.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 380.4563 - root_mean_squared_error: 19.5053 - val_loss: 244.1217 - val_root_mean_squared_error: 15.6244 - lr: 0.0010\n",
      "Epoch 98/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 316.1290 - root_mean_squared_error: 17.7800\n",
      "Epoch 98: val_loss improved from 244.12167 to 243.38588, saving model to Model\\098-380.0615-243.3859.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 380.0615 - root_mean_squared_error: 19.4952 - val_loss: 243.3859 - val_root_mean_squared_error: 15.6008 - lr: 0.0010\n",
      "Epoch 99/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 325.5766 - root_mean_squared_error: 18.0437\n",
      "Epoch 99: val_loss improved from 243.38588 to 242.71562, saving model to Model\\099-379.4691-242.7156.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 379.4691 - root_mean_squared_error: 19.4800 - val_loss: 242.7156 - val_root_mean_squared_error: 15.5793 - lr: 0.0010\n",
      "Epoch 100/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 200.3786 - root_mean_squared_error: 14.1555\n",
      "Epoch 100: val_loss did not improve from 242.71562\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 379.3703 - root_mean_squared_error: 19.4774 - val_loss: 242.7787 - val_root_mean_squared_error: 15.5814 - lr: 0.0010\n",
      "Epoch 101/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 313.0260 - root_mean_squared_error: 17.6925\n",
      "Epoch 101: val_loss improved from 242.71562 to 239.81384, saving model to Model\\101-378.2722-239.8138.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 378.2722 - root_mean_squared_error: 19.4492 - val_loss: 239.8138 - val_root_mean_squared_error: 15.4859 - lr: 0.0010\n",
      "Epoch 102/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 546.1130 - root_mean_squared_error: 23.3691\n",
      "Epoch 102: val_loss did not improve from 239.81384\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 378.3409 - root_mean_squared_error: 19.4510 - val_loss: 241.1511 - val_root_mean_squared_error: 15.5290 - lr: 0.0010\n",
      "Epoch 103/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 371.3680 - root_mean_squared_error: 19.2709\n",
      "Epoch 103: val_loss improved from 239.81384 to 239.28329, saving model to Model\\103-377.0081-239.2833.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 377.0081 - root_mean_squared_error: 19.4167 - val_loss: 239.2833 - val_root_mean_squared_error: 15.4688 - lr: 0.0010\n",
      "Epoch 104/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 331.2588 - root_mean_squared_error: 18.2005\n",
      "Epoch 104: val_loss improved from 239.28329 to 237.31258, saving model to Model\\104-376.3610-237.3126.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 376.3610 - root_mean_squared_error: 19.4000 - val_loss: 237.3126 - val_root_mean_squared_error: 15.4050 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 646.8663 - root_mean_squared_error: 25.4336\n",
      "Epoch 105: val_loss did not improve from 237.31258\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 375.9245 - root_mean_squared_error: 19.3888 - val_loss: 237.5047 - val_root_mean_squared_error: 15.4112 - lr: 0.0010\n",
      "Epoch 106/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 253.7805 - root_mean_squared_error: 15.9305\n",
      "Epoch 106: val_loss improved from 237.31258 to 236.15402, saving model to Model\\106-375.4183-236.1540.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 375.4183 - root_mean_squared_error: 19.3757 - val_loss: 236.1540 - val_root_mean_squared_error: 15.3673 - lr: 0.0010\n",
      "Epoch 107/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 414.4054 - root_mean_squared_error: 20.3570\n",
      "Epoch 107: val_loss improved from 236.15402 to 235.58113, saving model to Model\\107-374.6603-235.5811.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 374.6603 - root_mean_squared_error: 19.3561 - val_loss: 235.5811 - val_root_mean_squared_error: 15.3487 - lr: 0.0010\n",
      "Epoch 108/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 367.0275 - root_mean_squared_error: 19.1580\n",
      "Epoch 108: val_loss improved from 235.58113 to 234.06911, saving model to Model\\108-374.0509-234.0691.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 374.0509 - root_mean_squared_error: 19.3404 - val_loss: 234.0691 - val_root_mean_squared_error: 15.2993 - lr: 0.0010\n",
      "Epoch 109/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 374.2997 - root_mean_squared_error: 19.3468\n",
      "Epoch 109: val_loss improved from 234.06911 to 231.99095, saving model to Model\\109-373.4718-231.9910.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 373.4718 - root_mean_squared_error: 19.3254 - val_loss: 231.9910 - val_root_mean_squared_error: 15.2312 - lr: 0.0010\n",
      "Epoch 110/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 391.6365 - root_mean_squared_error: 19.7898\n",
      "Epoch 110: val_loss did not improve from 231.99095\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 372.7872 - root_mean_squared_error: 19.3077 - val_loss: 232.1865 - val_root_mean_squared_error: 15.2377 - lr: 0.0010\n",
      "Epoch 111/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 295.9891 - root_mean_squared_error: 17.2043\n",
      "Epoch 111: val_loss improved from 231.99095 to 231.51793, saving model to Model\\111-372.0793-231.5179.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 372.0793 - root_mean_squared_error: 19.2894 - val_loss: 231.5179 - val_root_mean_squared_error: 15.2157 - lr: 0.0010\n",
      "Epoch 112/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 459.3199 - root_mean_squared_error: 21.4318\n",
      "Epoch 112: val_loss did not improve from 231.51793\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 371.7847 - root_mean_squared_error: 19.2817 - val_loss: 231.8064 - val_root_mean_squared_error: 15.2252 - lr: 0.0010\n",
      "Epoch 113/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 204.3553 - root_mean_squared_error: 14.2953\n",
      "Epoch 113: val_loss improved from 231.51793 to 228.95041, saving model to Model\\113-370.7064-228.9504.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 370.7064 - root_mean_squared_error: 19.2537 - val_loss: 228.9504 - val_root_mean_squared_error: 15.1311 - lr: 0.0010\n",
      "Epoch 114/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 556.9120 - root_mean_squared_error: 23.5990\n",
      "Epoch 114: val_loss improved from 228.95041 to 228.14168, saving model to Model\\114-370.3058-228.1417.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 370.3058 - root_mean_squared_error: 19.2433 - val_loss: 228.1417 - val_root_mean_squared_error: 15.1044 - lr: 0.0010\n",
      "Epoch 115/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 685.1241 - root_mean_squared_error: 26.1749\n",
      "Epoch 115: val_loss improved from 228.14168 to 226.75948, saving model to Model\\115-369.9929-226.7595.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 369.9929 - root_mean_squared_error: 19.2352 - val_loss: 226.7595 - val_root_mean_squared_error: 15.0585 - lr: 0.0010\n",
      "Epoch 116/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 340.1349 - root_mean_squared_error: 18.4427\n",
      "Epoch 116: val_loss did not improve from 226.75948\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 369.4173 - root_mean_squared_error: 19.2202 - val_loss: 227.6636 - val_root_mean_squared_error: 15.0885 - lr: 0.0010\n",
      "Epoch 117/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 351.5765 - root_mean_squared_error: 18.7504\n",
      "Epoch 117: val_loss improved from 226.75948 to 225.54626, saving model to Model\\117-368.2214-225.5463.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 368.2214 - root_mean_squared_error: 19.1891 - val_loss: 225.5463 - val_root_mean_squared_error: 15.0182 - lr: 0.0010\n",
      "Epoch 118/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 385.3032 - root_mean_squared_error: 19.6291\n",
      "Epoch 118: val_loss improved from 225.54626 to 222.86356, saving model to Model\\118-367.8738-222.8636.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 367.8738 - root_mean_squared_error: 19.1800 - val_loss: 222.8636 - val_root_mean_squared_error: 14.9286 - lr: 0.0010\n",
      "Epoch 119/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 345.1389 - root_mean_squared_error: 18.5779\n",
      "Epoch 119: val_loss did not improve from 222.86356\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 367.1488 - root_mean_squared_error: 19.1611 - val_loss: 223.0954 - val_root_mean_squared_error: 14.9364 - lr: 0.0010\n",
      "Epoch 120/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 237.0122 - root_mean_squared_error: 15.3952\n",
      "Epoch 120: val_loss did not improve from 222.86356\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 366.5264 - root_mean_squared_error: 19.1449 - val_loss: 223.1688 - val_root_mean_squared_error: 14.9388 - lr: 0.0010\n",
      "Epoch 121/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 363.8814 - root_mean_squared_error: 19.0757\n",
      "Epoch 121: val_loss improved from 222.86356 to 222.12450, saving model to Model\\121-366.1013-222.1245.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 366.1013 - root_mean_squared_error: 19.1338 - val_loss: 222.1245 - val_root_mean_squared_error: 14.9038 - lr: 0.0010\n",
      "Epoch 122/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 162.7031 - root_mean_squared_error: 12.7555\n",
      "Epoch 122: val_loss improved from 222.12450 to 220.03117, saving model to Model\\122-365.0750-220.0312.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 365.0750 - root_mean_squared_error: 19.1069 - val_loss: 220.0312 - val_root_mean_squared_error: 14.8334 - lr: 0.0010\n",
      "Epoch 123/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 154.4227 - root_mean_squared_error: 12.4267\n",
      "Epoch 123: val_loss improved from 220.03117 to 219.51271, saving model to Model\\123-364.8636-219.5127.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 364.8636 - root_mean_squared_error: 19.1014 - val_loss: 219.5127 - val_root_mean_squared_error: 14.8160 - lr: 0.0010\n",
      "Epoch 124/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 263.0310 - root_mean_squared_error: 16.2182\n",
      "Epoch 124: val_loss improved from 219.51271 to 218.45193, saving model to Model\\124-363.8394-218.4519.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 363.8394 - root_mean_squared_error: 19.0746 - val_loss: 218.4519 - val_root_mean_squared_error: 14.7801 - lr: 0.0010\n",
      "Epoch 125/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 348.1488 - root_mean_squared_error: 18.6587\n",
      "Epoch 125: val_loss improved from 218.45193 to 217.17641, saving model to Model\\125-363.3854-217.1764.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 363.3854 - root_mean_squared_error: 19.0627 - val_loss: 217.1764 - val_root_mean_squared_error: 14.7369 - lr: 0.0010\n",
      "Epoch 126/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 289.0986 - root_mean_squared_error: 17.0029\n",
      "Epoch 126: val_loss improved from 217.17641 to 216.92964, saving model to Model\\126-363.0056-216.9296.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 363.0056 - root_mean_squared_error: 19.0527 - val_loss: 216.9296 - val_root_mean_squared_error: 14.7285 - lr: 0.0010\n",
      "Epoch 127/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 227.0123 - root_mean_squared_error: 15.0669\n",
      "Epoch 127: val_loss improved from 216.92964 to 215.95222, saving model to Model\\127-362.0101-215.9522.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 362.0101 - root_mean_squared_error: 19.0266 - val_loss: 215.9522 - val_root_mean_squared_error: 14.6953 - lr: 0.0010\n",
      "Epoch 128/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 363.5544 - root_mean_squared_error: 19.0671\n",
      "Epoch 128: val_loss improved from 215.95222 to 215.08237, saving model to Model\\128-361.4227-215.0824.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 361.4227 - root_mean_squared_error: 19.0111 - val_loss: 215.0824 - val_root_mean_squared_error: 14.6657 - lr: 0.0010\n",
      "Epoch 129/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 593.4970 - root_mean_squared_error: 24.3618\n",
      "Epoch 129: val_loss improved from 215.08237 to 214.41273, saving model to Model\\129-360.9365-214.4127.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 360.9365 - root_mean_squared_error: 18.9983 - val_loss: 214.4127 - val_root_mean_squared_error: 14.6428 - lr: 0.0010\n",
      "Epoch 130/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 355.5435 - root_mean_squared_error: 18.8559\n",
      "Epoch 130: val_loss improved from 214.41273 to 212.29497, saving model to Model\\130-360.1599-212.2950.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 360.1599 - root_mean_squared_error: 18.9779 - val_loss: 212.2950 - val_root_mean_squared_error: 14.5703 - lr: 0.0010\n",
      "Epoch 131/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 271.1035 - root_mean_squared_error: 16.4652\n",
      "Epoch 131: val_loss did not improve from 212.29497\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 359.5199 - root_mean_squared_error: 18.9610 - val_loss: 212.9495 - val_root_mean_squared_error: 14.5928 - lr: 0.0010\n",
      "Epoch 132/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 408.6959 - root_mean_squared_error: 20.2162\n",
      "Epoch 132: val_loss improved from 212.29497 to 211.19638, saving model to Model\\132-358.8510-211.1964.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 358.8510 - root_mean_squared_error: 18.9434 - val_loss: 211.1964 - val_root_mean_squared_error: 14.5326 - lr: 0.0010\n",
      "Epoch 133/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 372.7152 - root_mean_squared_error: 19.3058\n",
      "Epoch 133: val_loss improved from 211.19638 to 210.17067, saving model to Model\\133-358.2943-210.1707.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 358.2943 - root_mean_squared_error: 18.9287 - val_loss: 210.1707 - val_root_mean_squared_error: 14.4973 - lr: 0.0010\n",
      "Epoch 134/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 211.3369 - root_mean_squared_error: 14.5374\n",
      "Epoch 134: val_loss did not improve from 210.17067\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 357.9935 - root_mean_squared_error: 18.9207 - val_loss: 210.5535 - val_root_mean_squared_error: 14.5105 - lr: 0.0010\n",
      "Epoch 135/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 268.2617 - root_mean_squared_error: 16.3787\n",
      "Epoch 135: val_loss improved from 210.17067 to 207.06401, saving model to Model\\135-357.4030-207.0640.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 357.4030 - root_mean_squared_error: 18.9051 - val_loss: 207.0640 - val_root_mean_squared_error: 14.3897 - lr: 0.0010\n",
      "Epoch 136/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 169.5646 - root_mean_squared_error: 13.0217\n",
      "Epoch 136: val_loss did not improve from 207.06401\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 356.0234 - root_mean_squared_error: 18.8686 - val_loss: 207.5417 - val_root_mean_squared_error: 14.4063 - lr: 0.0010\n",
      "Epoch 137/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 470.7556 - root_mean_squared_error: 21.6969\n",
      "Epoch 137: val_loss did not improve from 207.06401\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 355.5762 - root_mean_squared_error: 18.8567 - val_loss: 207.8292 - val_root_mean_squared_error: 14.4163 - lr: 0.0010\n",
      "Epoch 138/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 472.5503 - root_mean_squared_error: 21.7382\n",
      "Epoch 138: val_loss improved from 207.06401 to 204.92360, saving model to Model\\138-355.0086-204.9236.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 355.0086 - root_mean_squared_error: 18.8417 - val_loss: 204.9236 - val_root_mean_squared_error: 14.3152 - lr: 0.0010\n",
      "Epoch 139/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 393.1480 - root_mean_squared_error: 19.8280\n",
      "Epoch 139: val_loss did not improve from 204.92360\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 354.5980 - root_mean_squared_error: 18.8308 - val_loss: 206.1675 - val_root_mean_squared_error: 14.3585 - lr: 0.0010\n",
      "Epoch 140/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 565.4357 - root_mean_squared_error: 23.7789\n",
      "Epoch 140: val_loss improved from 204.92360 to 203.22864, saving model to Model\\140-353.3690-203.2286.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 353.3690 - root_mean_squared_error: 18.7981 - val_loss: 203.2286 - val_root_mean_squared_error: 14.2558 - lr: 0.0010\n",
      "Epoch 141/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 140.9641 - root_mean_squared_error: 11.8728\n",
      "Epoch 141: val_loss improved from 203.22864 to 202.23911, saving model to Model\\141-353.2349-202.2391.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 353.2349 - root_mean_squared_error: 18.7945 - val_loss: 202.2391 - val_root_mean_squared_error: 14.2211 - lr: 0.0010\n",
      "Epoch 142/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 170.9220 - root_mean_squared_error: 13.0737\n",
      "Epoch 142: val_loss improved from 202.23911 to 200.66171, saving model to Model\\142-352.6218-200.6617.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 352.6218 - root_mean_squared_error: 18.7782 - val_loss: 200.6617 - val_root_mean_squared_error: 14.1655 - lr: 0.0010\n",
      "Epoch 143/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 252.6588 - root_mean_squared_error: 15.8952\n",
      "Epoch 143: val_loss did not improve from 200.66171\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 351.8226 - root_mean_squared_error: 18.7569 - val_loss: 202.0641 - val_root_mean_squared_error: 14.2149 - lr: 0.0010\n",
      "Epoch 144/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 512.0775 - root_mean_squared_error: 22.6291\n",
      "Epoch 144: val_loss improved from 200.66171 to 198.94733, saving model to Model\\144-351.6085-198.9473.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 351.6085 - root_mean_squared_error: 18.7512 - val_loss: 198.9473 - val_root_mean_squared_error: 14.1049 - lr: 0.0010\n",
      "Epoch 145/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 243.7397 - root_mean_squared_error: 15.6122\n",
      "Epoch 145: val_loss did not improve from 198.94733\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 350.8790 - root_mean_squared_error: 18.7318 - val_loss: 202.2255 - val_root_mean_squared_error: 14.2206 - lr: 0.0010\n",
      "Epoch 146/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 243.6177 - root_mean_squared_error: 15.6083\n",
      "Epoch 146: val_loss improved from 198.94733 to 195.77130, saving model to Model\\146-350.6935-195.7713.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 350.6935 - root_mean_squared_error: 18.7268 - val_loss: 195.7713 - val_root_mean_squared_error: 13.9918 - lr: 0.0010\n",
      "Epoch 147/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 252.5800 - root_mean_squared_error: 15.8928\n",
      "Epoch 147: val_loss did not improve from 195.77130\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 348.6300 - root_mean_squared_error: 18.6716 - val_loss: 198.0497 - val_root_mean_squared_error: 14.0730 - lr: 0.0010\n",
      "Epoch 148/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/16 [>.............................] - ETA: 0s - loss: 352.0621 - root_mean_squared_error: 18.7633\n",
      "Epoch 148: val_loss did not improve from 195.77130\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 349.0661 - root_mean_squared_error: 18.6833 - val_loss: 198.7824 - val_root_mean_squared_error: 14.0990 - lr: 0.0010\n",
      "Epoch 149/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 205.9881 - root_mean_squared_error: 14.3523\n",
      "Epoch 149: val_loss did not improve from 195.77130\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 347.7353 - root_mean_squared_error: 18.6477 - val_loss: 196.1428 - val_root_mean_squared_error: 14.0051 - lr: 0.0010\n",
      "Epoch 150/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 390.7005 - root_mean_squared_error: 19.7661\n",
      "Epoch 150: val_loss improved from 195.77130 to 192.87163, saving model to Model\\150-346.8789-192.8716.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 346.8789 - root_mean_squared_error: 18.6247 - val_loss: 192.8716 - val_root_mean_squared_error: 13.8878 - lr: 0.0010\n",
      "Epoch 151/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 239.8045 - root_mean_squared_error: 15.4856\n",
      "Epoch 151: val_loss improved from 192.87163 to 192.60065, saving model to Model\\151-346.6341-192.6006.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 346.6341 - root_mean_squared_error: 18.6181 - val_loss: 192.6006 - val_root_mean_squared_error: 13.8781 - lr: 0.0010\n",
      "Epoch 152/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 293.3079 - root_mean_squared_error: 17.1262\n",
      "Epoch 152: val_loss did not improve from 192.60065\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 346.1701 - root_mean_squared_error: 18.6056 - val_loss: 193.1919 - val_root_mean_squared_error: 13.8993 - lr: 0.0010\n",
      "Epoch 153/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 368.7574 - root_mean_squared_error: 19.2031\n",
      "Epoch 153: val_loss improved from 192.60065 to 191.68608, saving model to Model\\153-345.3156-191.6861.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 345.3156 - root_mean_squared_error: 18.5827 - val_loss: 191.6861 - val_root_mean_squared_error: 13.8451 - lr: 0.0010\n",
      "Epoch 154/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 326.4893 - root_mean_squared_error: 18.0690\n",
      "Epoch 154: val_loss improved from 191.68608 to 189.59143, saving model to Model\\154-344.4460-189.5914.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 344.4460 - root_mean_squared_error: 18.5593 - val_loss: 189.5914 - val_root_mean_squared_error: 13.7692 - lr: 0.0010\n",
      "Epoch 155/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 227.7583 - root_mean_squared_error: 15.0917\n",
      "Epoch 155: val_loss improved from 189.59143 to 189.02126, saving model to Model\\155-343.9099-189.0213.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 343.9099 - root_mean_squared_error: 18.5448 - val_loss: 189.0213 - val_root_mean_squared_error: 13.7485 - lr: 0.0010\n",
      "Epoch 156/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 304.5787 - root_mean_squared_error: 17.4522\n",
      "Epoch 156: val_loss did not improve from 189.02126\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 343.2817 - root_mean_squared_error: 18.5279 - val_loss: 190.9507 - val_root_mean_squared_error: 13.8185 - lr: 0.0010\n",
      "Epoch 157/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 198.9405 - root_mean_squared_error: 14.1046\n",
      "Epoch 157: val_loss improved from 189.02126 to 186.87129, saving model to Model\\157-342.9153-186.8713.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 342.9153 - root_mean_squared_error: 18.5180 - val_loss: 186.8713 - val_root_mean_squared_error: 13.6701 - lr: 0.0010\n",
      "Epoch 158/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 451.5802 - root_mean_squared_error: 21.2504\n",
      "Epoch 158: val_loss did not improve from 186.87129\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 341.6232 - root_mean_squared_error: 18.4831 - val_loss: 187.2040 - val_root_mean_squared_error: 13.6823 - lr: 0.0010\n",
      "Epoch 159/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 198.8756 - root_mean_squared_error: 14.1023\n",
      "Epoch 159: val_loss did not improve from 186.87129\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 340.9735 - root_mean_squared_error: 18.4655 - val_loss: 186.8749 - val_root_mean_squared_error: 13.6702 - lr: 0.0010\n",
      "Epoch 160/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 164.0339 - root_mean_squared_error: 12.8076\n",
      "Epoch 160: val_loss improved from 186.87129 to 185.34996, saving model to Model\\160-340.4854-185.3500.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 340.4854 - root_mean_squared_error: 18.4522 - val_loss: 185.3500 - val_root_mean_squared_error: 13.6143 - lr: 0.0010\n",
      "Epoch 161/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 231.9853 - root_mean_squared_error: 15.2311\n",
      "Epoch 161: val_loss improved from 185.34996 to 183.29243, saving model to Model\\161-339.6314-183.2924.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 339.6314 - root_mean_squared_error: 18.4291 - val_loss: 183.2924 - val_root_mean_squared_error: 13.5386 - lr: 0.0010\n",
      "Epoch 162/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 505.8446 - root_mean_squared_error: 22.4910\n",
      "Epoch 162: val_loss did not improve from 183.29243\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 339.8687 - root_mean_squared_error: 18.4355 - val_loss: 183.8633 - val_root_mean_squared_error: 13.5596 - lr: 0.0010\n",
      "Epoch 163/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 732.9765 - root_mean_squared_error: 27.0735\n",
      "Epoch 163: val_loss improved from 183.29243 to 180.60129, saving model to Model\\163-338.4058-180.6013.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 338.4058 - root_mean_squared_error: 18.3958 - val_loss: 180.6013 - val_root_mean_squared_error: 13.4388 - lr: 0.0010\n",
      "Epoch 164/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 326.3165 - root_mean_squared_error: 18.0642\n",
      "Epoch 164: val_loss improved from 180.60129 to 179.37921, saving model to Model\\164-337.9580-179.3792.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 337.9580 - root_mean_squared_error: 18.3836 - val_loss: 179.3792 - val_root_mean_squared_error: 13.3933 - lr: 0.0010\n",
      "Epoch 165/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 186.1617 - root_mean_squared_error: 13.6441\n",
      "Epoch 165: val_loss did not improve from 179.37921\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 337.1214 - root_mean_squared_error: 18.3609 - val_loss: 180.9922 - val_root_mean_squared_error: 13.4533 - lr: 0.0010\n",
      "Epoch 166/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 378.8280 - root_mean_squared_error: 19.4635\n",
      "Epoch 166: val_loss did not improve from 179.37921\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 337.1756 - root_mean_squared_error: 18.3623 - val_loss: 181.6562 - val_root_mean_squared_error: 13.4780 - lr: 0.0010\n",
      "Epoch 167/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 283.3788 - root_mean_squared_error: 16.8339\n",
      "Epoch 167: val_loss improved from 179.37921 to 175.02917, saving model to Model\\167-338.0126-175.0292.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 338.0126 - root_mean_squared_error: 18.3851 - val_loss: 175.0292 - val_root_mean_squared_error: 13.2299 - lr: 0.0010\n",
      "Epoch 168/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 163.7873 - root_mean_squared_error: 12.7979\n",
      "Epoch 168: val_loss did not improve from 175.02917\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 334.5585 - root_mean_squared_error: 18.2909 - val_loss: 179.2669 - val_root_mean_squared_error: 13.3891 - lr: 0.0010\n",
      "Epoch 169/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 617.1622 - root_mean_squared_error: 24.8427\n",
      "Epoch 169: val_loss did not improve from 175.02917\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 334.9187 - root_mean_squared_error: 18.3008 - val_loss: 177.6337 - val_root_mean_squared_error: 13.3279 - lr: 0.0010\n",
      "Epoch 170/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/16 [>.............................] - ETA: 0s - loss: 126.1400 - root_mean_squared_error: 11.2312\n",
      "Epoch 170: val_loss did not improve from 175.02917\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 334.0965 - root_mean_squared_error: 18.2783 - val_loss: 175.7183 - val_root_mean_squared_error: 13.2559 - lr: 0.0010\n",
      "Epoch 171/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 119.4296 - root_mean_squared_error: 10.9284\n",
      "Epoch 171: val_loss improved from 175.02917 to 174.50598, saving model to Model\\171-333.0706-174.5060.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 333.0706 - root_mean_squared_error: 18.2502 - val_loss: 174.5060 - val_root_mean_squared_error: 13.2101 - lr: 0.0010\n",
      "Epoch 172/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 251.8431 - root_mean_squared_error: 15.8696\n",
      "Epoch 172: val_loss improved from 174.50598 to 171.98096, saving model to Model\\172-333.9400-171.9810.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 333.9400 - root_mean_squared_error: 18.2740 - val_loss: 171.9810 - val_root_mean_squared_error: 13.1142 - lr: 0.0010\n",
      "Epoch 173/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 414.3798 - root_mean_squared_error: 20.3563\n",
      "Epoch 173: val_loss did not improve from 171.98096\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 332.7021 - root_mean_squared_error: 18.2401 - val_loss: 176.8265 - val_root_mean_squared_error: 13.2976 - lr: 0.0010\n",
      "Epoch 174/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 442.0550 - root_mean_squared_error: 21.0251\n",
      "Epoch 174: val_loss improved from 171.98096 to 171.33679, saving model to Model\\174-331.3766-171.3368.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 331.3766 - root_mean_squared_error: 18.2038 - val_loss: 171.3368 - val_root_mean_squared_error: 13.0896 - lr: 0.0010\n",
      "Epoch 175/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 223.9409 - root_mean_squared_error: 14.9647\n",
      "Epoch 175: val_loss improved from 171.33679 to 170.88916, saving model to Model\\175-330.5437-170.8892.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 330.5437 - root_mean_squared_error: 18.1809 - val_loss: 170.8892 - val_root_mean_squared_error: 13.0725 - lr: 0.0010\n",
      "Epoch 176/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 133.1629 - root_mean_squared_error: 11.5396\n",
      "Epoch 176: val_loss did not improve from 170.88916\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 330.0669 - root_mean_squared_error: 18.1677 - val_loss: 171.0653 - val_root_mean_squared_error: 13.0792 - lr: 0.0010\n",
      "Epoch 177/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 184.3989 - root_mean_squared_error: 13.5794\n",
      "Epoch 177: val_loss improved from 170.88916 to 166.85663, saving model to Model\\177-329.8945-166.8566.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 329.8945 - root_mean_squared_error: 18.1630 - val_loss: 166.8566 - val_root_mean_squared_error: 12.9173 - lr: 0.0010\n",
      "Epoch 178/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 210.9702 - root_mean_squared_error: 14.5248\n",
      "Epoch 178: val_loss did not improve from 166.85663\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 328.3845 - root_mean_squared_error: 18.1214 - val_loss: 167.8988 - val_root_mean_squared_error: 12.9576 - lr: 0.0010\n",
      "Epoch 179/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 324.5364 - root_mean_squared_error: 18.0149\n",
      "Epoch 179: val_loss did not improve from 166.85663\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 329.2032 - root_mean_squared_error: 18.1440 - val_loss: 168.1088 - val_root_mean_squared_error: 12.9657 - lr: 0.0010\n",
      "Epoch 180/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 204.6002 - root_mean_squared_error: 14.3039\n",
      "Epoch 180: val_loss improved from 166.85663 to 165.59984, saving model to Model\\180-327.2120-165.5998.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 327.2120 - root_mean_squared_error: 18.0890 - val_loss: 165.5998 - val_root_mean_squared_error: 12.8686 - lr: 0.0010\n",
      "Epoch 181/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 673.3762 - root_mean_squared_error: 25.9495\n",
      "Epoch 181: val_loss improved from 165.59984 to 164.64703, saving model to Model\\181-327.5909-164.6470.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 327.5909 - root_mean_squared_error: 18.0995 - val_loss: 164.6470 - val_root_mean_squared_error: 12.8315 - lr: 0.0010\n",
      "Epoch 182/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 201.0478 - root_mean_squared_error: 14.1791\n",
      "Epoch 182: val_loss improved from 164.64703 to 163.41350, saving model to Model\\182-325.7120-163.4135.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 325.7120 - root_mean_squared_error: 18.0475 - val_loss: 163.4135 - val_root_mean_squared_error: 12.7833 - lr: 0.0010\n",
      "Epoch 183/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 571.4977 - root_mean_squared_error: 23.9060\n",
      "Epoch 183: val_loss did not improve from 163.41350\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 325.4016 - root_mean_squared_error: 18.0389 - val_loss: 163.7094 - val_root_mean_squared_error: 12.7949 - lr: 0.0010\n",
      "Epoch 184/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 509.4888 - root_mean_squared_error: 22.5719\n",
      "Epoch 184: val_loss improved from 163.41350 to 162.17119, saving model to Model\\184-324.4291-162.1712.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 324.4291 - root_mean_squared_error: 18.0119 - val_loss: 162.1712 - val_root_mean_squared_error: 12.7346 - lr: 0.0010\n",
      "Epoch 185/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 250.1359 - root_mean_squared_error: 15.8157\n",
      "Epoch 185: val_loss improved from 162.17119 to 159.52167, saving model to Model\\185-325.1694-159.5217.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 325.1694 - root_mean_squared_error: 18.0325 - val_loss: 159.5217 - val_root_mean_squared_error: 12.6302 - lr: 0.0010\n",
      "Epoch 186/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 171.7717 - root_mean_squared_error: 13.1062\n",
      "Epoch 186: val_loss did not improve from 159.52167\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 323.5323 - root_mean_squared_error: 17.9870 - val_loss: 162.7124 - val_root_mean_squared_error: 12.7559 - lr: 0.0010\n",
      "Epoch 187/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 387.3373 - root_mean_squared_error: 19.6809\n",
      "Epoch 187: val_loss improved from 159.52167 to 158.17215, saving model to Model\\187-322.0796-158.1721.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 322.0796 - root_mean_squared_error: 17.9466 - val_loss: 158.1721 - val_root_mean_squared_error: 12.5767 - lr: 0.0010\n",
      "Epoch 188/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 348.0329 - root_mean_squared_error: 18.6556\n",
      "Epoch 188: val_loss did not improve from 158.17215\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 324.2297 - root_mean_squared_error: 18.0064 - val_loss: 159.1509 - val_root_mean_squared_error: 12.6155 - lr: 0.0010\n",
      "Epoch 189/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 144.2840 - root_mean_squared_error: 12.0118\n",
      "Epoch 189: val_loss improved from 158.17215 to 154.80670, saving model to Model\\189-322.3386-154.8067.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 322.3386 - root_mean_squared_error: 17.9538 - val_loss: 154.8067 - val_root_mean_squared_error: 12.4421 - lr: 0.0010\n",
      "Epoch 190/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 316.0063 - root_mean_squared_error: 17.7766\n",
      "Epoch 190: val_loss did not improve from 154.80670\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 320.7748 - root_mean_squared_error: 17.9102 - val_loss: 157.7587 - val_root_mean_squared_error: 12.5602 - lr: 0.0010\n",
      "Epoch 191/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 360.0971 - root_mean_squared_error: 18.9762\n",
      "Epoch 191: val_loss improved from 154.80670 to 154.28023, saving model to Model\\191-320.5888-154.2802.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 320.5888 - root_mean_squared_error: 17.9050 - val_loss: 154.2802 - val_root_mean_squared_error: 12.4210 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 226.0392 - root_mean_squared_error: 15.0346\n",
      "Epoch 192: val_loss did not improve from 154.28023\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 319.0745 - root_mean_squared_error: 17.8627 - val_loss: 154.5916 - val_root_mean_squared_error: 12.4335 - lr: 0.0010\n",
      "Epoch 193/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 189.1553 - root_mean_squared_error: 13.7534\n",
      "Epoch 193: val_loss did not improve from 154.28023\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 318.7428 - root_mean_squared_error: 17.8534 - val_loss: 156.1553 - val_root_mean_squared_error: 12.4962 - lr: 0.0010\n",
      "Epoch 194/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 435.4818 - root_mean_squared_error: 20.8682\n",
      "Epoch 194: val_loss improved from 154.28023 to 150.20372, saving model to Model\\194-318.3100-150.2037.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 318.3100 - root_mean_squared_error: 17.8412 - val_loss: 150.2037 - val_root_mean_squared_error: 12.2558 - lr: 0.0010\n",
      "Epoch 195/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 570.1183 - root_mean_squared_error: 23.8771\n",
      "Epoch 195: val_loss did not improve from 150.20372\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 317.3257 - root_mean_squared_error: 17.8136 - val_loss: 152.6064 - val_root_mean_squared_error: 12.3534 - lr: 0.0010\n",
      "Epoch 196/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 585.0312 - root_mean_squared_error: 24.1874\n",
      "Epoch 196: val_loss did not improve from 150.20372\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 316.5145 - root_mean_squared_error: 17.7909 - val_loss: 152.0333 - val_root_mean_squared_error: 12.3302 - lr: 0.0010\n",
      "Epoch 197/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 368.4297 - root_mean_squared_error: 19.1945\n",
      "Epoch 197: val_loss improved from 150.20372 to 148.83939, saving model to Model\\197-316.0560-148.8394.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 316.0560 - root_mean_squared_error: 17.7780 - val_loss: 148.8394 - val_root_mean_squared_error: 12.2000 - lr: 0.0010\n",
      "Epoch 198/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 125.6575 - root_mean_squared_error: 11.2097\n",
      "Epoch 198: val_loss did not improve from 148.83939\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 315.7988 - root_mean_squared_error: 17.7707 - val_loss: 149.2007 - val_root_mean_squared_error: 12.2148 - lr: 0.0010\n",
      "Epoch 199/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 324.1744 - root_mean_squared_error: 18.0048\n",
      "Epoch 199: val_loss improved from 148.83939 to 146.45453, saving model to Model\\199-315.5002-146.4545.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 315.5002 - root_mean_squared_error: 17.7623 - val_loss: 146.4545 - val_root_mean_squared_error: 12.1018 - lr: 0.0010\n",
      "Epoch 200/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 372.4359 - root_mean_squared_error: 19.2986\n",
      "Epoch 200: val_loss did not improve from 146.45453\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 314.2169 - root_mean_squared_error: 17.7262 - val_loss: 149.7800 - val_root_mean_squared_error: 12.2385 - lr: 0.0010\n",
      "Epoch 201/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 557.8770 - root_mean_squared_error: 23.6194\n",
      "Epoch 201: val_loss improved from 146.45453 to 143.96613, saving model to Model\\201-314.2623-143.9661.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 314.2623 - root_mean_squared_error: 17.7274 - val_loss: 143.9661 - val_root_mean_squared_error: 11.9986 - lr: 0.0010\n",
      "Epoch 202/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 123.2171 - root_mean_squared_error: 11.1003\n",
      "Epoch 202: val_loss did not improve from 143.96613\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 312.6674 - root_mean_squared_error: 17.6824 - val_loss: 145.3263 - val_root_mean_squared_error: 12.0551 - lr: 0.0010\n",
      "Epoch 203/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 95.0117 - root_mean_squared_error: 9.7474\n",
      "Epoch 203: val_loss did not improve from 143.96613\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 314.1901 - root_mean_squared_error: 17.7254 - val_loss: 148.8892 - val_root_mean_squared_error: 12.2020 - lr: 0.0010\n",
      "Epoch 204/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 181.8214 - root_mean_squared_error: 13.4841\n",
      "Epoch 204: val_loss improved from 143.96613 to 142.17049, saving model to Model\\204-313.2968-142.1705.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 313.2968 - root_mean_squared_error: 17.7002 - val_loss: 142.1705 - val_root_mean_squared_error: 11.9235 - lr: 0.0010\n",
      "Epoch 205/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 139.2538 - root_mean_squared_error: 11.8006\n",
      "Epoch 205: val_loss improved from 142.17049 to 141.88947, saving model to Model\\205-310.8529-141.8895.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 310.8529 - root_mean_squared_error: 17.6310 - val_loss: 141.8895 - val_root_mean_squared_error: 11.9117 - lr: 0.0010\n",
      "Epoch 206/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 439.8421 - root_mean_squared_error: 20.9724\n",
      "Epoch 206: val_loss did not improve from 141.88947\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 310.7909 - root_mean_squared_error: 17.6293 - val_loss: 145.7066 - val_root_mean_squared_error: 12.0709 - lr: 0.0010\n",
      "Epoch 207/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 348.0699 - root_mean_squared_error: 18.6566\n",
      "Epoch 207: val_loss improved from 141.88947 to 137.92053, saving model to Model\\207-309.4136-137.9205.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 309.4136 - root_mean_squared_error: 17.5902 - val_loss: 137.9205 - val_root_mean_squared_error: 11.7440 - lr: 0.0010\n",
      "Epoch 208/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 424.4705 - root_mean_squared_error: 20.6027\n",
      "Epoch 208: val_loss did not improve from 137.92053\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 310.7178 - root_mean_squared_error: 17.6272 - val_loss: 139.7660 - val_root_mean_squared_error: 11.8223 - lr: 0.0010\n",
      "Epoch 209/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 119.5460 - root_mean_squared_error: 10.9337\n",
      "Epoch 209: val_loss did not improve from 137.92053\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 309.8521 - root_mean_squared_error: 17.6026 - val_loss: 139.1330 - val_root_mean_squared_error: 11.7955 - lr: 0.0010\n",
      "Epoch 210/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 184.7426 - root_mean_squared_error: 13.5920\n",
      "Epoch 210: val_loss improved from 137.92053 to 137.53047, saving model to Model\\210-307.8399-137.5305.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 307.8399 - root_mean_squared_error: 17.5454 - val_loss: 137.5305 - val_root_mean_squared_error: 11.7273 - lr: 0.0010\n",
      "Epoch 211/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 484.9048 - root_mean_squared_error: 22.0206\n",
      "Epoch 211: val_loss improved from 137.53047 to 136.46101, saving model to Model\\211-307.4785-136.4610.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 307.4785 - root_mean_squared_error: 17.5351 - val_loss: 136.4610 - val_root_mean_squared_error: 11.6817 - lr: 0.0010\n",
      "Epoch 212/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 176.7532 - root_mean_squared_error: 13.2949\n",
      "Epoch 212: val_loss did not improve from 136.46101\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 306.4543 - root_mean_squared_error: 17.5058 - val_loss: 136.8248 - val_root_mean_squared_error: 11.6972 - lr: 0.0010\n",
      "Epoch 213/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 293.5217 - root_mean_squared_error: 17.1325\n",
      "Epoch 213: val_loss improved from 136.46101 to 133.40089, saving model to Model\\213-305.6067-133.4009.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 305.6067 - root_mean_squared_error: 17.4816 - val_loss: 133.4009 - val_root_mean_squared_error: 11.5499 - lr: 0.0010\n",
      "Epoch 214/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/16 [>.............................] - ETA: 0s - loss: 149.2636 - root_mean_squared_error: 12.2173\n",
      "Epoch 214: val_loss did not improve from 133.40089\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 305.4566 - root_mean_squared_error: 17.4773 - val_loss: 135.1355 - val_root_mean_squared_error: 11.6248 - lr: 0.0010\n",
      "Epoch 215/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 188.1429 - root_mean_squared_error: 13.7165\n",
      "Epoch 215: val_loss improved from 133.40089 to 131.15221, saving model to Model\\215-304.5515-131.1522.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 304.5515 - root_mean_squared_error: 17.4514 - val_loss: 131.1522 - val_root_mean_squared_error: 11.4522 - lr: 0.0010\n",
      "Epoch 216/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 374.3147 - root_mean_squared_error: 19.3472\n",
      "Epoch 216: val_loss did not improve from 131.15221\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 305.0660 - root_mean_squared_error: 17.4661 - val_loss: 133.9401 - val_root_mean_squared_error: 11.5733 - lr: 0.0010\n",
      "Epoch 217/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 394.7658 - root_mean_squared_error: 19.8687\n",
      "Epoch 217: val_loss improved from 131.15221 to 128.91632, saving model to Model\\217-302.6849-128.9163.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 302.6849 - root_mean_squared_error: 17.3978 - val_loss: 128.9163 - val_root_mean_squared_error: 11.3541 - lr: 0.0010\n",
      "Epoch 218/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 506.9946 - root_mean_squared_error: 22.5165\n",
      "Epoch 218: val_loss did not improve from 128.91632\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 303.4832 - root_mean_squared_error: 17.4208 - val_loss: 128.9296 - val_root_mean_squared_error: 11.3547 - lr: 0.0010\n",
      "Epoch 219/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 181.6935 - root_mean_squared_error: 13.4794\n",
      "Epoch 219: val_loss improved from 128.91632 to 126.07144, saving model to Model\\219-302.8181-126.0714.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 302.8181 - root_mean_squared_error: 17.4017 - val_loss: 126.0714 - val_root_mean_squared_error: 11.2282 - lr: 0.0010\n",
      "Epoch 220/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 390.8551 - root_mean_squared_error: 19.7701\n",
      "Epoch 220: val_loss did not improve from 126.07144\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 303.0504 - root_mean_squared_error: 17.4083 - val_loss: 131.5027 - val_root_mean_squared_error: 11.4675 - lr: 0.0010\n",
      "Epoch 221/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 432.1712 - root_mean_squared_error: 20.7887\n",
      "Epoch 221: val_loss improved from 126.07144 to 124.07703, saving model to Model\\221-302.3134-124.0770.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 302.3134 - root_mean_squared_error: 17.3872 - val_loss: 124.0770 - val_root_mean_squared_error: 11.1390 - lr: 0.0010\n",
      "Epoch 222/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 227.5724 - root_mean_squared_error: 15.0855\n",
      "Epoch 222: val_loss did not improve from 124.07703\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 300.2733 - root_mean_squared_error: 17.3284 - val_loss: 129.4556 - val_root_mean_squared_error: 11.3779 - lr: 0.0010\n",
      "Epoch 223/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 484.9138 - root_mean_squared_error: 22.0208\n",
      "Epoch 223: val_loss improved from 124.07703 to 122.16259, saving model to Model\\223-302.9883-122.1626.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 302.9883 - root_mean_squared_error: 17.4066 - val_loss: 122.1626 - val_root_mean_squared_error: 11.0527 - lr: 0.0010\n",
      "Epoch 224/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 410.9814 - root_mean_squared_error: 20.2727\n",
      "Epoch 224: val_loss did not improve from 122.16259\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 301.5892 - root_mean_squared_error: 17.3663 - val_loss: 129.3038 - val_root_mean_squared_error: 11.3712 - lr: 0.0010\n",
      "Epoch 225/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 135.5271 - root_mean_squared_error: 11.6416\n",
      "Epoch 225: val_loss did not improve from 122.16259\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 299.5359 - root_mean_squared_error: 17.3071 - val_loss: 122.6708 - val_root_mean_squared_error: 11.0757 - lr: 0.0010\n",
      "Epoch 226/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 218.5150 - root_mean_squared_error: 14.7823\n",
      "Epoch 226: val_loss did not improve from 122.16259\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 298.4258 - root_mean_squared_error: 17.2750 - val_loss: 122.9139 - val_root_mean_squared_error: 11.0867 - lr: 0.0010\n",
      "Epoch 227/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 547.8398 - root_mean_squared_error: 23.4060\n",
      "Epoch 227: val_loss did not improve from 122.16259\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 297.2691 - root_mean_squared_error: 17.2415 - val_loss: 123.1935 - val_root_mean_squared_error: 11.0993 - lr: 0.0010\n",
      "Epoch 228/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 511.6092 - root_mean_squared_error: 22.6188\n",
      "Epoch 228: val_loss improved from 122.16259 to 119.95781, saving model to Model\\228-297.5255-119.9578.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 297.5255 - root_mean_squared_error: 17.2489 - val_loss: 119.9578 - val_root_mean_squared_error: 10.9525 - lr: 0.0010\n",
      "Epoch 229/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 74.8807 - root_mean_squared_error: 8.6534\n",
      "Epoch 229: val_loss improved from 119.95781 to 117.50730, saving model to Model\\229-298.5301-117.5073.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 298.5301 - root_mean_squared_error: 17.2780 - val_loss: 117.5073 - val_root_mean_squared_error: 10.8401 - lr: 0.0010\n",
      "Epoch 230/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 331.9810 - root_mean_squared_error: 18.2203\n",
      "Epoch 230: val_loss did not improve from 117.50730\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 296.1596 - root_mean_squared_error: 17.2093 - val_loss: 121.5549 - val_root_mean_squared_error: 11.0252 - lr: 0.0010\n",
      "Epoch 231/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 321.9984 - root_mean_squared_error: 17.9443\n",
      "Epoch 231: val_loss did not improve from 117.50730\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 295.9223 - root_mean_squared_error: 17.2024 - val_loss: 118.0039 - val_root_mean_squared_error: 10.8630 - lr: 0.0010\n",
      "Epoch 232/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 176.2959 - root_mean_squared_error: 13.2776\n",
      "Epoch 232: val_loss did not improve from 117.50730\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 294.2835 - root_mean_squared_error: 17.1547 - val_loss: 119.3067 - val_root_mean_squared_error: 10.9228 - lr: 0.0010\n",
      "Epoch 233/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 240.9726 - root_mean_squared_error: 15.5233\n",
      "Epoch 233: val_loss did not improve from 117.50730\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 294.9624 - root_mean_squared_error: 17.1745 - val_loss: 117.9958 - val_root_mean_squared_error: 10.8626 - lr: 0.0010\n",
      "Epoch 234/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 119.8235 - root_mean_squared_error: 10.9464\n",
      "Epoch 234: val_loss improved from 117.50730 to 114.81807, saving model to Model\\234-295.2809-114.8181.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 295.2809 - root_mean_squared_error: 17.1837 - val_loss: 114.8181 - val_root_mean_squared_error: 10.7153 - lr: 0.0010\n",
      "Epoch 235/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 186.4870 - root_mean_squared_error: 13.6560\n",
      "Epoch 235: val_loss did not improve from 114.81807\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 292.3262 - root_mean_squared_error: 17.0976 - val_loss: 117.3207 - val_root_mean_squared_error: 10.8315 - lr: 0.0010\n",
      "Epoch 236/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 915.3870 - root_mean_squared_error: 30.2554\n",
      "Epoch 236: val_loss improved from 114.81807 to 113.18378, saving model to Model\\236-294.6727-113.1838.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 294.6727 - root_mean_squared_error: 17.1660 - val_loss: 113.1838 - val_root_mean_squared_error: 10.6388 - lr: 0.0010\n",
      "Epoch 237/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 480.0697 - root_mean_squared_error: 21.9105\n",
      "Epoch 237: val_loss improved from 113.18378 to 112.05943, saving model to Model\\237-292.5905-112.0594.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 292.5905 - root_mean_squared_error: 17.1053 - val_loss: 112.0594 - val_root_mean_squared_error: 10.5858 - lr: 0.0010\n",
      "Epoch 238/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 460.3149 - root_mean_squared_error: 21.4550\n",
      "Epoch 238: val_loss did not improve from 112.05943\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 291.6030 - root_mean_squared_error: 17.0764 - val_loss: 112.5793 - val_root_mean_squared_error: 10.6103 - lr: 0.0010\n",
      "Epoch 239/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 381.7373 - root_mean_squared_error: 19.5381\n",
      "Epoch 239: val_loss did not improve from 112.05943\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 291.2989 - root_mean_squared_error: 17.0675 - val_loss: 112.7618 - val_root_mean_squared_error: 10.6189 - lr: 0.0010\n",
      "Epoch 240/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 85.7149 - root_mean_squared_error: 9.2582\n",
      "Epoch 240: val_loss did not improve from 112.05943\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 291.3885 - root_mean_squared_error: 17.0701 - val_loss: 114.1017 - val_root_mean_squared_error: 10.6818 - lr: 0.0010\n",
      "Epoch 241/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 130.7698 - root_mean_squared_error: 11.4355\n",
      "Epoch 241: val_loss improved from 112.05943 to 110.60538, saving model to Model\\241-290.8174-110.6054.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 290.8174 - root_mean_squared_error: 17.0534 - val_loss: 110.6054 - val_root_mean_squared_error: 10.5169 - lr: 0.0010\n",
      "Epoch 242/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 120.8744 - root_mean_squared_error: 10.9943\n",
      "Epoch 242: val_loss did not improve from 110.60538\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 290.0201 - root_mean_squared_error: 17.0300 - val_loss: 111.9123 - val_root_mean_squared_error: 10.5789 - lr: 0.0010\n",
      "Epoch 243/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 144.8649 - root_mean_squared_error: 12.0360\n",
      "Epoch 243: val_loss improved from 110.60538 to 108.20776, saving model to Model\\243-288.7737-108.2078.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 288.7737 - root_mean_squared_error: 16.9933 - val_loss: 108.2078 - val_root_mean_squared_error: 10.4023 - lr: 0.0010\n",
      "Epoch 244/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 353.0239 - root_mean_squared_error: 18.7889\n",
      "Epoch 244: val_loss improved from 108.20776 to 106.00878, saving model to Model\\244-288.5706-106.0088.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 288.5706 - root_mean_squared_error: 16.9874 - val_loss: 106.0088 - val_root_mean_squared_error: 10.2961 - lr: 0.0010\n",
      "Epoch 245/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 213.0991 - root_mean_squared_error: 14.5979\n",
      "Epoch 245: val_loss did not improve from 106.00878\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 287.4137 - root_mean_squared_error: 16.9533 - val_loss: 108.4983 - val_root_mean_squared_error: 10.4163 - lr: 0.0010\n",
      "Epoch 246/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 387.8938 - root_mean_squared_error: 19.6950\n",
      "Epoch 246: val_loss did not improve from 106.00878\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 288.7369 - root_mean_squared_error: 16.9923 - val_loss: 107.3257 - val_root_mean_squared_error: 10.3598 - lr: 0.0010\n",
      "Epoch 247/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 94.6550 - root_mean_squared_error: 9.7291\n",
      "Epoch 247: val_loss improved from 106.00878 to 103.51974, saving model to Model\\247-288.9982-103.5197.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 288.9982 - root_mean_squared_error: 16.9999 - val_loss: 103.5197 - val_root_mean_squared_error: 10.1745 - lr: 0.0010\n",
      "Epoch 248/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 203.7153 - root_mean_squared_error: 14.2729\n",
      "Epoch 248: val_loss did not improve from 103.51974\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 287.1507 - root_mean_squared_error: 16.9455 - val_loss: 105.7052 - val_root_mean_squared_error: 10.2813 - lr: 0.0010\n",
      "Epoch 249/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 96.2056 - root_mean_squared_error: 9.8084\n",
      "Epoch 249: val_loss improved from 103.51974 to 101.96564, saving model to Model\\249-285.5541-101.9656.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 285.5541 - root_mean_squared_error: 16.8983 - val_loss: 101.9656 - val_root_mean_squared_error: 10.0978 - lr: 0.0010\n",
      "Epoch 250/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 453.2283 - root_mean_squared_error: 21.2892\n",
      "Epoch 250: val_loss did not improve from 101.96564\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 285.0542 - root_mean_squared_error: 16.8835 - val_loss: 103.8364 - val_root_mean_squared_error: 10.1900 - lr: 0.0010\n",
      "Epoch 251/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 501.1139 - root_mean_squared_error: 22.3856\n",
      "Epoch 251: val_loss did not improve from 101.96564\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 285.7500 - root_mean_squared_error: 16.9041 - val_loss: 102.2268 - val_root_mean_squared_error: 10.1107 - lr: 0.0010\n",
      "Epoch 252/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 416.5323 - root_mean_squared_error: 20.4091\n",
      "Epoch 252: val_loss did not improve from 101.96564\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 284.0168 - root_mean_squared_error: 16.8528 - val_loss: 102.1296 - val_root_mean_squared_error: 10.1059 - lr: 0.0010\n",
      "Epoch 253/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 79.0290 - root_mean_squared_error: 8.8898\n",
      "Epoch 253: val_loss improved from 101.96564 to 100.40042, saving model to Model\\253-283.7389-100.4004.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 283.7389 - root_mean_squared_error: 16.8446 - val_loss: 100.4004 - val_root_mean_squared_error: 10.0200 - lr: 0.0010\n",
      "Epoch 254/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 347.7181 - root_mean_squared_error: 18.6472\n",
      "Epoch 254: val_loss did not improve from 100.40042\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 283.1615 - root_mean_squared_error: 16.8274 - val_loss: 100.5191 - val_root_mean_squared_error: 10.0259 - lr: 0.0010\n",
      "Epoch 255/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 366.5801 - root_mean_squared_error: 19.1463\n",
      "Epoch 255: val_loss improved from 100.40042 to 97.78620, saving model to Model\\255-282.3747-97.7862.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 282.3747 - root_mean_squared_error: 16.8040 - val_loss: 97.7862 - val_root_mean_squared_error: 9.8887 - lr: 0.0010\n",
      "Epoch 256/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 395.4354 - root_mean_squared_error: 19.8856\n",
      "Epoch 256: val_loss did not improve from 97.78620\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 285.3290 - root_mean_squared_error: 16.8917 - val_loss: 99.4564 - val_root_mean_squared_error: 9.9728 - lr: 0.0010\n",
      "Epoch 257/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 334.5486 - root_mean_squared_error: 18.2907\n",
      "Epoch 257: val_loss did not improve from 97.78620\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 285.4881 - root_mean_squared_error: 16.8964 - val_loss: 100.5482 - val_root_mean_squared_error: 10.0274 - lr: 0.0010\n",
      "Epoch 258/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 225.3320 - root_mean_squared_error: 15.0111\n",
      "Epoch 258: val_loss improved from 97.78620 to 94.14189, saving model to Model\\258-282.2813-94.1419.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 282.2813 - root_mean_squared_error: 16.8012 - val_loss: 94.1419 - val_root_mean_squared_error: 9.7027 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 120.2446 - root_mean_squared_error: 10.9656\n",
      "Epoch 259: val_loss did not improve from 94.14189\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 280.5778 - root_mean_squared_error: 16.7505 - val_loss: 97.6327 - val_root_mean_squared_error: 9.8809 - lr: 0.0010\n",
      "Epoch 260/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 526.8168 - root_mean_squared_error: 22.9525\n",
      "Epoch 260: val_loss did not improve from 94.14189\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 281.9037 - root_mean_squared_error: 16.7900 - val_loss: 98.1296 - val_root_mean_squared_error: 9.9060 - lr: 0.0010\n",
      "Epoch 261/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 69.4004 - root_mean_squared_error: 8.3307\n",
      "Epoch 261: val_loss did not improve from 94.14189\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 280.9065 - root_mean_squared_error: 16.7603 - val_loss: 96.8466 - val_root_mean_squared_error: 9.8411 - lr: 0.0010\n",
      "Epoch 262/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 92.2931 - root_mean_squared_error: 9.6069\n",
      "Epoch 262: val_loss improved from 94.14189 to 94.02763, saving model to Model\\262-280.9739-94.0276.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 280.9739 - root_mean_squared_error: 16.7623 - val_loss: 94.0276 - val_root_mean_squared_error: 9.6968 - lr: 0.0010\n",
      "Epoch 263/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 69.8757 - root_mean_squared_error: 8.3592\n",
      "Epoch 263: val_loss improved from 94.02763 to 93.96729, saving model to Model\\263-279.6613-93.9673.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 279.6613 - root_mean_squared_error: 16.7231 - val_loss: 93.9673 - val_root_mean_squared_error: 9.6937 - lr: 0.0010\n",
      "Epoch 264/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 106.8539 - root_mean_squared_error: 10.3370\n",
      "Epoch 264: val_loss improved from 93.96729 to 93.49173, saving model to Model\\264-279.1183-93.4917.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 279.1183 - root_mean_squared_error: 16.7068 - val_loss: 93.4917 - val_root_mean_squared_error: 9.6691 - lr: 0.0010\n",
      "Epoch 265/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 562.7899 - root_mean_squared_error: 23.7232\n",
      "Epoch 265: val_loss improved from 93.49173 to 91.47988, saving model to Model\\265-279.9727-91.4799.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 279.9727 - root_mean_squared_error: 16.7324 - val_loss: 91.4799 - val_root_mean_squared_error: 9.5645 - lr: 0.0010\n",
      "Epoch 266/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 511.5627 - root_mean_squared_error: 22.6178\n",
      "Epoch 266: val_loss did not improve from 91.47988\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 277.7672 - root_mean_squared_error: 16.6663 - val_loss: 93.7065 - val_root_mean_squared_error: 9.6802 - lr: 0.0010\n",
      "Epoch 267/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 264.3336 - root_mean_squared_error: 16.2583\n",
      "Epoch 267: val_loss did not improve from 91.47988\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 279.1609 - root_mean_squared_error: 16.7081 - val_loss: 92.2052 - val_root_mean_squared_error: 9.6024 - lr: 0.0010\n",
      "Epoch 268/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 277.2852 - root_mean_squared_error: 16.6519\n",
      "Epoch 268: val_loss improved from 91.47988 to 90.87135, saving model to Model\\268-276.8604-90.8713.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 276.8604 - root_mean_squared_error: 16.6391 - val_loss: 90.8713 - val_root_mean_squared_error: 9.5326 - lr: 0.0010\n",
      "Epoch 269/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 183.5908 - root_mean_squared_error: 13.5496\n",
      "Epoch 269: val_loss improved from 90.87135 to 88.72188, saving model to Model\\269-276.4956-88.7219.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 276.4956 - root_mean_squared_error: 16.6282 - val_loss: 88.7219 - val_root_mean_squared_error: 9.4192 - lr: 0.0010\n",
      "Epoch 270/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 328.8401 - root_mean_squared_error: 18.1339\n",
      "Epoch 270: val_loss improved from 88.72188 to 88.20589, saving model to Model\\270-276.2737-88.2059.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 276.2737 - root_mean_squared_error: 16.6215 - val_loss: 88.2059 - val_root_mean_squared_error: 9.3918 - lr: 0.0010\n",
      "Epoch 271/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 149.6012 - root_mean_squared_error: 12.2312\n",
      "Epoch 271: val_loss did not improve from 88.20589\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 276.3053 - root_mean_squared_error: 16.6224 - val_loss: 92.4119 - val_root_mean_squared_error: 9.6131 - lr: 0.0010\n",
      "Epoch 272/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 209.1858 - root_mean_squared_error: 14.4633\n",
      "Epoch 272: val_loss improved from 88.20589 to 85.40665, saving model to Model\\272-275.8730-85.4066.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 275.8730 - root_mean_squared_error: 16.6094 - val_loss: 85.4066 - val_root_mean_squared_error: 9.2416 - lr: 0.0010\n",
      "Epoch 273/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 183.9089 - root_mean_squared_error: 13.5613\n",
      "Epoch 273: val_loss did not improve from 85.40665\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 275.4289 - root_mean_squared_error: 16.5961 - val_loss: 91.6911 - val_root_mean_squared_error: 9.5755 - lr: 0.0010\n",
      "Epoch 274/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 100.4393 - root_mean_squared_error: 10.0219\n",
      "Epoch 274: val_loss did not improve from 85.40665\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 275.9133 - root_mean_squared_error: 16.6106 - val_loss: 87.8290 - val_root_mean_squared_error: 9.3717 - lr: 0.0010\n",
      "Epoch 275/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 229.5890 - root_mean_squared_error: 15.1522\n",
      "Epoch 275: val_loss improved from 85.40665 to 84.89044, saving model to Model\\275-275.7979-84.8904.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 275.7979 - root_mean_squared_error: 16.6072 - val_loss: 84.8904 - val_root_mean_squared_error: 9.2136 - lr: 0.0010\n",
      "Epoch 276/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 209.3387 - root_mean_squared_error: 14.4685\n",
      "Epoch 276: val_loss did not improve from 84.89044\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 274.7645 - root_mean_squared_error: 16.5760 - val_loss: 87.8997 - val_root_mean_squared_error: 9.3755 - lr: 0.0010\n",
      "Epoch 277/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 189.3277 - root_mean_squared_error: 13.7596\n",
      "Epoch 277: val_loss improved from 84.89044 to 84.62806, saving model to Model\\277-275.2224-84.6281.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 275.2224 - root_mean_squared_error: 16.5898 - val_loss: 84.6281 - val_root_mean_squared_error: 9.1994 - lr: 0.0010\n",
      "Epoch 278/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 235.0267 - root_mean_squared_error: 15.3306\n",
      "Epoch 278: val_loss did not improve from 84.62806\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 273.2169 - root_mean_squared_error: 16.5293 - val_loss: 85.6706 - val_root_mean_squared_error: 9.2558 - lr: 0.0010\n",
      "Epoch 279/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 288.9967 - root_mean_squared_error: 16.9999\n",
      "Epoch 279: val_loss did not improve from 84.62806\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 273.1464 - root_mean_squared_error: 16.5271 - val_loss: 85.2182 - val_root_mean_squared_error: 9.2314 - lr: 0.0010\n",
      "Epoch 280/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 101.4140 - root_mean_squared_error: 10.0705\n",
      "Epoch 280: val_loss improved from 84.62806 to 84.21454, saving model to Model\\280-272.9666-84.2145.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 272.9666 - root_mean_squared_error: 16.5217 - val_loss: 84.2145 - val_root_mean_squared_error: 9.1768 - lr: 0.0010\n",
      "Epoch 281/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/16 [>.............................] - ETA: 0s - loss: 420.7975 - root_mean_squared_error: 20.5133\n",
      "Epoch 281: val_loss improved from 84.21454 to 80.68102, saving model to Model\\281-272.8581-80.6810.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 272.8581 - root_mean_squared_error: 16.5184 - val_loss: 80.6810 - val_root_mean_squared_error: 8.9823 - lr: 0.0010\n",
      "Epoch 282/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 309.1361 - root_mean_squared_error: 17.5823\n",
      "Epoch 282: val_loss did not improve from 80.68102\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 271.5171 - root_mean_squared_error: 16.4778 - val_loss: 84.6274 - val_root_mean_squared_error: 9.1993 - lr: 0.0010\n",
      "Epoch 283/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 208.4389 - root_mean_squared_error: 14.4374\n",
      "Epoch 283: val_loss improved from 80.68102 to 80.45328, saving model to Model\\283-273.1105-80.4533.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 273.1105 - root_mean_squared_error: 16.5261 - val_loss: 80.4533 - val_root_mean_squared_error: 8.9696 - lr: 0.0010\n",
      "Epoch 284/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 310.6443 - root_mean_squared_error: 17.6251\n",
      "Epoch 284: val_loss did not improve from 80.45328\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 274.4993 - root_mean_squared_error: 16.5680 - val_loss: 80.8554 - val_root_mean_squared_error: 8.9920 - lr: 0.0010\n",
      "Epoch 285/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 321.8405 - root_mean_squared_error: 17.9399\n",
      "Epoch 285: val_loss did not improve from 80.45328\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 273.6612 - root_mean_squared_error: 16.5427 - val_loss: 80.5621 - val_root_mean_squared_error: 8.9756 - lr: 0.0010\n",
      "Epoch 286/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 269.4477 - root_mean_squared_error: 16.4149\n",
      "Epoch 286: val_loss did not improve from 80.45328\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 271.3469 - root_mean_squared_error: 16.4726 - val_loss: 81.5953 - val_root_mean_squared_error: 9.0330 - lr: 0.0010\n",
      "Epoch 287/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 76.8135 - root_mean_squared_error: 8.7643\n",
      "Epoch 287: val_loss improved from 80.45328 to 76.45597, saving model to Model\\287-270.0101-76.4560.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 270.0101 - root_mean_squared_error: 16.4320 - val_loss: 76.4560 - val_root_mean_squared_error: 8.7439 - lr: 0.0010\n",
      "Epoch 288/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 69.0172 - root_mean_squared_error: 8.3077\n",
      "Epoch 288: val_loss did not improve from 76.45597\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 270.9205 - root_mean_squared_error: 16.4597 - val_loss: 79.6568 - val_root_mean_squared_error: 8.9251 - lr: 0.0010\n",
      "Epoch 289/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 88.4241 - root_mean_squared_error: 9.4034\n",
      "Epoch 289: val_loss did not improve from 76.45597\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 269.3026 - root_mean_squared_error: 16.4104 - val_loss: 77.7532 - val_root_mean_squared_error: 8.8178 - lr: 0.0010\n",
      "Epoch 290/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 100.2253 - root_mean_squared_error: 10.0113\n",
      "Epoch 290: val_loss did not improve from 76.45597\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 269.6219 - root_mean_squared_error: 16.4202 - val_loss: 77.0674 - val_root_mean_squared_error: 8.7788 - lr: 0.0010\n",
      "Epoch 291/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 519.5446 - root_mean_squared_error: 22.7935\n",
      "Epoch 291: val_loss improved from 76.45597 to 75.88474, saving model to Model\\291-268.8170-75.8847.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 268.8170 - root_mean_squared_error: 16.3956 - val_loss: 75.8847 - val_root_mean_squared_error: 8.7112 - lr: 0.0010\n",
      "Epoch 292/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 271.5452 - root_mean_squared_error: 16.4786\n",
      "Epoch 292: val_loss did not improve from 75.88474\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 268.3502 - root_mean_squared_error: 16.3814 - val_loss: 77.3933 - val_root_mean_squared_error: 8.7973 - lr: 0.0010\n",
      "Epoch 293/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 394.6474 - root_mean_squared_error: 19.8657\n",
      "Epoch 293: val_loss improved from 75.88474 to 73.63905, saving model to Model\\293-267.9090-73.6391.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 267.9090 - root_mean_squared_error: 16.3679 - val_loss: 73.6391 - val_root_mean_squared_error: 8.5813 - lr: 0.0010\n",
      "Epoch 294/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 131.9947 - root_mean_squared_error: 11.4889\n",
      "Epoch 294: val_loss did not improve from 73.63905\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 267.3819 - root_mean_squared_error: 16.3518 - val_loss: 78.2771 - val_root_mean_squared_error: 8.8474 - lr: 0.0010\n",
      "Epoch 295/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 109.1757 - root_mean_squared_error: 10.4487\n",
      "Epoch 295: val_loss did not improve from 73.63905\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 267.3493 - root_mean_squared_error: 16.3508 - val_loss: 74.3137 - val_root_mean_squared_error: 8.6205 - lr: 0.0010\n",
      "Epoch 296/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 201.1088 - root_mean_squared_error: 14.1813\n",
      "Epoch 296: val_loss did not improve from 73.63905\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 267.9583 - root_mean_squared_error: 16.3694 - val_loss: 73.9244 - val_root_mean_squared_error: 8.5979 - lr: 0.0010\n",
      "Epoch 297/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 91.8372 - root_mean_squared_error: 9.5832\n",
      "Epoch 297: val_loss did not improve from 73.63905\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 268.8792 - root_mean_squared_error: 16.3975 - val_loss: 74.5927 - val_root_mean_squared_error: 8.6367 - lr: 0.0010\n",
      "Epoch 298/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 104.8859 - root_mean_squared_error: 10.2414\n",
      "Epoch 298: val_loss did not improve from 73.63905\n",
      "\n",
      "Epoch 298: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 270.7991 - root_mean_squared_error: 16.4560 - val_loss: 74.9686 - val_root_mean_squared_error: 8.6584 - lr: 0.0010\n",
      "Epoch 299/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 68.6464 - root_mean_squared_error: 8.2853\n",
      "Epoch 299: val_loss improved from 73.63905 to 73.20662, saving model to Model\\299-266.5394-73.2066.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 266.5394 - root_mean_squared_error: 16.3260 - val_loss: 73.2066 - val_root_mean_squared_error: 8.5561 - lr: 9.5000e-04\n",
      "Epoch 300/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 523.2020 - root_mean_squared_error: 22.8736\n",
      "Epoch 300: val_loss improved from 73.20662 to 70.35958, saving model to Model\\300-266.3597-70.3596.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 266.3597 - root_mean_squared_error: 16.3205 - val_loss: 70.3596 - val_root_mean_squared_error: 8.3881 - lr: 9.5000e-04\n",
      "Epoch 301/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 246.8944 - root_mean_squared_error: 15.7129\n",
      "Epoch 301: val_loss did not improve from 70.35958\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 266.7130 - root_mean_squared_error: 16.3314 - val_loss: 76.1637 - val_root_mean_squared_error: 8.7272 - lr: 9.5000e-04\n",
      "Epoch 302/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 71.9490 - root_mean_squared_error: 8.4823\n",
      "Epoch 302: val_loss improved from 70.35958 to 68.95363, saving model to Model\\302-265.5410-68.9536.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 265.5410 - root_mean_squared_error: 16.2954 - val_loss: 68.9536 - val_root_mean_squared_error: 8.3038 - lr: 9.5000e-04\n",
      "Epoch 303/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 145.6221 - root_mean_squared_error: 12.0674\n",
      "Epoch 303: val_loss did not improve from 68.95363\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 266.1672 - root_mean_squared_error: 16.3146 - val_loss: 75.5238 - val_root_mean_squared_error: 8.6904 - lr: 9.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 120.6374 - root_mean_squared_error: 10.9835\n",
      "Epoch 304: val_loss improved from 68.95363 to 68.73154, saving model to Model\\304-265.5148-68.7315.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 265.5148 - root_mean_squared_error: 16.2946 - val_loss: 68.7315 - val_root_mean_squared_error: 8.2904 - lr: 9.5000e-04\n",
      "Epoch 305/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 432.9943 - root_mean_squared_error: 20.8085\n",
      "Epoch 305: val_loss did not improve from 68.73154\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 264.4190 - root_mean_squared_error: 16.2610 - val_loss: 71.7051 - val_root_mean_squared_error: 8.4679 - lr: 9.5000e-04\n",
      "Epoch 306/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 64.0410 - root_mean_squared_error: 8.0026\n",
      "Epoch 306: val_loss improved from 68.73154 to 68.08440, saving model to Model\\306-264.1623-68.0844.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 264.1623 - root_mean_squared_error: 16.2531 - val_loss: 68.0844 - val_root_mean_squared_error: 8.2513 - lr: 9.5000e-04\n",
      "Epoch 307/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 590.1008 - root_mean_squared_error: 24.2920\n",
      "Epoch 307: val_loss did not improve from 68.08440\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 264.9832 - root_mean_squared_error: 16.2783 - val_loss: 68.3442 - val_root_mean_squared_error: 8.2671 - lr: 9.5000e-04\n",
      "Epoch 308/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 501.2069 - root_mean_squared_error: 22.3876\n",
      "Epoch 308: val_loss improved from 68.08440 to 65.50899, saving model to Model\\308-263.7056-65.5090.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 263.7056 - root_mean_squared_error: 16.2390 - val_loss: 65.5090 - val_root_mean_squared_error: 8.0938 - lr: 9.5000e-04\n",
      "Epoch 309/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 243.9330 - root_mean_squared_error: 15.6184\n",
      "Epoch 309: val_loss did not improve from 65.50899\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 264.8766 - root_mean_squared_error: 16.2750 - val_loss: 70.2070 - val_root_mean_squared_error: 8.3790 - lr: 9.5000e-04\n",
      "Epoch 310/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 287.0908 - root_mean_squared_error: 16.9438\n",
      "Epoch 310: val_loss did not improve from 65.50899\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 263.8310 - root_mean_squared_error: 16.2429 - val_loss: 66.2269 - val_root_mean_squared_error: 8.1380 - lr: 9.5000e-04\n",
      "Epoch 311/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 955.3489 - root_mean_squared_error: 30.9087\n",
      "Epoch 311: val_loss improved from 65.50899 to 63.61175, saving model to Model\\311-265.5053-63.6118.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 265.5053 - root_mean_squared_error: 16.2943 - val_loss: 63.6118 - val_root_mean_squared_error: 7.9757 - lr: 9.5000e-04\n",
      "Epoch 312/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 71.2728 - root_mean_squared_error: 8.4423\n",
      "Epoch 312: val_loss did not improve from 63.61175\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 263.4415 - root_mean_squared_error: 16.2309 - val_loss: 67.1423 - val_root_mean_squared_error: 8.1940 - lr: 9.5000e-04\n",
      "Epoch 313/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 83.1929 - root_mean_squared_error: 9.1210\n",
      "Epoch 313: val_loss did not improve from 63.61175\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 263.4146 - root_mean_squared_error: 16.2301 - val_loss: 66.3361 - val_root_mean_squared_error: 8.1447 - lr: 9.5000e-04\n",
      "Epoch 314/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 357.8763 - root_mean_squared_error: 18.9176\n",
      "Epoch 314: val_loss did not improve from 63.61175\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 262.4438 - root_mean_squared_error: 16.2001 - val_loss: 64.9689 - val_root_mean_squared_error: 8.0603 - lr: 9.5000e-04\n",
      "Epoch 315/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 173.4638 - root_mean_squared_error: 13.1706\n",
      "Epoch 315: val_loss did not improve from 63.61175\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 261.8123 - root_mean_squared_error: 16.1806 - val_loss: 67.4281 - val_root_mean_squared_error: 8.2115 - lr: 9.5000e-04\n",
      "Epoch 316/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 271.7577 - root_mean_squared_error: 16.4851\n",
      "Epoch 316: val_loss improved from 63.61175 to 63.48929, saving model to Model\\316-261.8416-63.4893.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 261.8416 - root_mean_squared_error: 16.1815 - val_loss: 63.4893 - val_root_mean_squared_error: 7.9680 - lr: 9.5000e-04\n",
      "Epoch 317/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 494.6354 - root_mean_squared_error: 22.2404\n",
      "Epoch 317: val_loss improved from 63.48929 to 63.06316, saving model to Model\\317-262.0698-63.0632.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 262.0698 - root_mean_squared_error: 16.1886 - val_loss: 63.0632 - val_root_mean_squared_error: 7.9412 - lr: 9.5000e-04\n",
      "Epoch 318/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 465.4450 - root_mean_squared_error: 21.5742\n",
      "Epoch 318: val_loss did not improve from 63.06316\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 261.3183 - root_mean_squared_error: 16.1653 - val_loss: 64.0085 - val_root_mean_squared_error: 8.0005 - lr: 9.5000e-04\n",
      "Epoch 319/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 274.7694 - root_mean_squared_error: 16.5762\n",
      "Epoch 319: val_loss improved from 63.06316 to 61.37333, saving model to Model\\319-262.3728-61.3733.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 262.3728 - root_mean_squared_error: 16.1979 - val_loss: 61.3733 - val_root_mean_squared_error: 7.8341 - lr: 9.5000e-04\n",
      "Epoch 320/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 667.3002 - root_mean_squared_error: 25.8322\n",
      "Epoch 320: val_loss did not improve from 61.37333\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 261.1831 - root_mean_squared_error: 16.1612 - val_loss: 62.0352 - val_root_mean_squared_error: 7.8762 - lr: 9.5000e-04\n",
      "Epoch 321/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 249.4990 - root_mean_squared_error: 15.7955\n",
      "Epoch 321: val_loss did not improve from 61.37333\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 263.2638 - root_mean_squared_error: 16.2254 - val_loss: 65.3643 - val_root_mean_squared_error: 8.0848 - lr: 9.5000e-04\n",
      "Epoch 322/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 209.2105 - root_mean_squared_error: 14.4641\n",
      "Epoch 322: val_loss improved from 61.37333 to 59.47078, saving model to Model\\322-262.2039-59.4708.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 262.2039 - root_mean_squared_error: 16.1927 - val_loss: 59.4708 - val_root_mean_squared_error: 7.7117 - lr: 9.5000e-04\n",
      "Epoch 323/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 406.3670 - root_mean_squared_error: 20.1585\n",
      "Epoch 323: val_loss did not improve from 59.47078\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 260.2110 - root_mean_squared_error: 16.1311 - val_loss: 67.3312 - val_root_mean_squared_error: 8.2056 - lr: 9.5000e-04\n",
      "Epoch 324/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 185.4574 - root_mean_squared_error: 13.6183\n",
      "Epoch 324: val_loss did not improve from 59.47078\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 260.0175 - root_mean_squared_error: 16.1251 - val_loss: 60.1295 - val_root_mean_squared_error: 7.7543 - lr: 9.5000e-04\n",
      "Epoch 325/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 102.0067 - root_mean_squared_error: 10.0998\n",
      "Epoch 325: val_loss did not improve from 59.47078\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 260.3221 - root_mean_squared_error: 16.1345 - val_loss: 61.6973 - val_root_mean_squared_error: 7.8548 - lr: 9.5000e-04\n",
      "Epoch 326/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 66.0827 - root_mean_squared_error: 8.1291\n",
      "Epoch 326: val_loss did not improve from 59.47078\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 259.8757 - root_mean_squared_error: 16.1207 - val_loss: 60.9525 - val_root_mean_squared_error: 7.8072 - lr: 9.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 308.6278 - root_mean_squared_error: 17.5678\n",
      "Epoch 327: val_loss improved from 59.47078 to 57.83347, saving model to Model\\327-261.7610-57.8335.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 261.7610 - root_mean_squared_error: 16.1790 - val_loss: 57.8335 - val_root_mean_squared_error: 7.6048 - lr: 9.5000e-04\n",
      "Epoch 328/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 137.1652 - root_mean_squared_error: 11.7118\n",
      "Epoch 328: val_loss did not improve from 57.83347\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 259.4703 - root_mean_squared_error: 16.1081 - val_loss: 61.1223 - val_root_mean_squared_error: 7.8181 - lr: 9.5000e-04\n",
      "Epoch 329/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 84.6020 - root_mean_squared_error: 9.1979\n",
      "Epoch 329: val_loss did not improve from 57.83347\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 259.3253 - root_mean_squared_error: 16.1036 - val_loss: 61.6269 - val_root_mean_squared_error: 7.8503 - lr: 9.5000e-04\n",
      "Epoch 330/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 89.2631 - root_mean_squared_error: 9.4479\n",
      "Epoch 330: val_loss did not improve from 57.83347\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 259.0566 - root_mean_squared_error: 16.0952 - val_loss: 63.5235 - val_root_mean_squared_error: 7.9702 - lr: 9.5000e-04\n",
      "Epoch 331/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 79.6604 - root_mean_squared_error: 8.9253\n",
      "Epoch 331: val_loss did not improve from 57.83347\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 260.1077 - root_mean_squared_error: 16.1279 - val_loss: 59.3689 - val_root_mean_squared_error: 7.7051 - lr: 9.5000e-04\n",
      "Epoch 332/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 544.2164 - root_mean_squared_error: 23.3284\n",
      "Epoch 332: val_loss did not improve from 57.83347\n",
      "\n",
      "Epoch 332: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 258.5785 - root_mean_squared_error: 16.0804 - val_loss: 58.7821 - val_root_mean_squared_error: 7.6669 - lr: 9.5000e-04\n",
      "Epoch 333/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 194.0376 - root_mean_squared_error: 13.9297\n",
      "Epoch 333: val_loss did not improve from 57.83347\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 259.0540 - root_mean_squared_error: 16.0952 - val_loss: 59.0007 - val_root_mean_squared_error: 7.6812 - lr: 9.0250e-04\n",
      "Epoch 334/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 340.0403 - root_mean_squared_error: 18.4402\n",
      "Epoch 334: val_loss improved from 57.83347 to 56.88246, saving model to Model\\334-257.8627-56.8825.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 257.8627 - root_mean_squared_error: 16.0581 - val_loss: 56.8825 - val_root_mean_squared_error: 7.5420 - lr: 9.0250e-04\n",
      "Epoch 335/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 92.9230 - root_mean_squared_error: 9.6397\n",
      "Epoch 335: val_loss did not improve from 56.88246\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 257.7070 - root_mean_squared_error: 16.0533 - val_loss: 59.1181 - val_root_mean_squared_error: 7.6888 - lr: 9.0250e-04\n",
      "Epoch 336/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 296.9647 - root_mean_squared_error: 17.2327\n",
      "Epoch 336: val_loss did not improve from 56.88246\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 260.9333 - root_mean_squared_error: 16.1534 - val_loss: 57.1229 - val_root_mean_squared_error: 7.5580 - lr: 9.0250e-04\n",
      "Epoch 337/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 56.1111 - root_mean_squared_error: 7.4907\n",
      "Epoch 337: val_loss did not improve from 56.88246\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 257.3522 - root_mean_squared_error: 16.0422 - val_loss: 57.4321 - val_root_mean_squared_error: 7.5784 - lr: 9.0250e-04\n",
      "Epoch 338/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 392.9763 - root_mean_squared_error: 19.8236\n",
      "Epoch 338: val_loss did not improve from 56.88246\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 257.4763 - root_mean_squared_error: 16.0461 - val_loss: 57.2960 - val_root_mean_squared_error: 7.5694 - lr: 9.0250e-04\n",
      "Epoch 339/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 207.3306 - root_mean_squared_error: 14.3990\n",
      "Epoch 339: val_loss did not improve from 56.88246\n",
      "\n",
      "Epoch 339: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 257.4939 - root_mean_squared_error: 16.0466 - val_loss: 57.8272 - val_root_mean_squared_error: 7.6044 - lr: 9.0250e-04\n",
      "Epoch 340/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 512.0142 - root_mean_squared_error: 22.6277\n",
      "Epoch 340: val_loss did not improve from 56.88246\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 257.4454 - root_mean_squared_error: 16.0451 - val_loss: 58.0229 - val_root_mean_squared_error: 7.6173 - lr: 8.5737e-04\n",
      "Epoch 341/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 52.3840 - root_mean_squared_error: 7.2377\n",
      "Epoch 341: val_loss improved from 56.88246 to 54.44172, saving model to Model\\341-256.7174-54.4417.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 256.7174 - root_mean_squared_error: 16.0224 - val_loss: 54.4417 - val_root_mean_squared_error: 7.3785 - lr: 8.5737e-04\n",
      "Epoch 342/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 86.2185 - root_mean_squared_error: 9.2854\n",
      "Epoch 342: val_loss did not improve from 54.44172\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 256.9374 - root_mean_squared_error: 16.0293 - val_loss: 56.8319 - val_root_mean_squared_error: 7.5387 - lr: 8.5737e-04\n",
      "Epoch 343/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 187.5169 - root_mean_squared_error: 13.6937\n",
      "Epoch 343: val_loss did not improve from 54.44172\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 256.7267 - root_mean_squared_error: 16.0227 - val_loss: 58.9470 - val_root_mean_squared_error: 7.6777 - lr: 8.5737e-04\n",
      "Epoch 344/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 652.1389 - root_mean_squared_error: 25.5370\n",
      "Epoch 344: val_loss improved from 54.44172 to 54.29912, saving model to Model\\344-256.3330-54.2991.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 256.3330 - root_mean_squared_error: 16.0104 - val_loss: 54.2991 - val_root_mean_squared_error: 7.3688 - lr: 8.5737e-04\n",
      "Epoch 345/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 546.1002 - root_mean_squared_error: 23.3688\n",
      "Epoch 345: val_loss did not improve from 54.29912\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 256.4817 - root_mean_squared_error: 16.0150 - val_loss: 55.4851 - val_root_mean_squared_error: 7.4488 - lr: 8.5737e-04\n",
      "Epoch 346/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 689.9013 - root_mean_squared_error: 26.2660\n",
      "Epoch 346: val_loss improved from 54.29912 to 52.62136, saving model to Model\\346-257.0957-52.6214.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 257.0957 - root_mean_squared_error: 16.0342 - val_loss: 52.6214 - val_root_mean_squared_error: 7.2541 - lr: 8.5737e-04\n",
      "Epoch 347/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 60.3435 - root_mean_squared_error: 7.7681\n",
      "Epoch 347: val_loss did not improve from 52.62136\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 258.3690 - root_mean_squared_error: 16.0739 - val_loss: 56.8628 - val_root_mean_squared_error: 7.5407 - lr: 8.5737e-04\n",
      "Epoch 348/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 80.1259 - root_mean_squared_error: 8.9513\n",
      "Epoch 348: val_loss did not improve from 52.62136\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 257.1097 - root_mean_squared_error: 16.0346 - val_loss: 56.9160 - val_root_mean_squared_error: 7.5443 - lr: 8.5737e-04\n",
      "Epoch 349/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 321.4584 - root_mean_squared_error: 17.9293\n",
      "Epoch 349: val_loss did not improve from 52.62136\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 255.2932 - root_mean_squared_error: 15.9779 - val_loss: 52.6886 - val_root_mean_squared_error: 7.2587 - lr: 8.5737e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 63.1519 - root_mean_squared_error: 7.9468\n",
      "Epoch 350: val_loss did not improve from 52.62136\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 256.1259 - root_mean_squared_error: 16.0039 - val_loss: 53.8929 - val_root_mean_squared_error: 7.3412 - lr: 8.5737e-04\n",
      "Epoch 351/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 77.2633 - root_mean_squared_error: 8.7900\n",
      "Epoch 351: val_loss did not improve from 52.62136\n",
      "\n",
      "Epoch 351: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 254.9854 - root_mean_squared_error: 15.9683 - val_loss: 55.1828 - val_root_mean_squared_error: 7.4285 - lr: 8.5737e-04\n",
      "Epoch 352/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 470.9040 - root_mean_squared_error: 21.7003\n",
      "Epoch 352: val_loss improved from 52.62136 to 52.13738, saving model to Model\\352-256.3097-52.1374.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 256.3097 - root_mean_squared_error: 16.0097 - val_loss: 52.1374 - val_root_mean_squared_error: 7.2206 - lr: 8.1451e-04\n",
      "Epoch 353/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 293.6118 - root_mean_squared_error: 17.1351\n",
      "Epoch 353: val_loss improved from 52.13738 to 52.00172, saving model to Model\\353-254.5498-52.0017.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 254.5498 - root_mean_squared_error: 15.9546 - val_loss: 52.0017 - val_root_mean_squared_error: 7.2112 - lr: 8.1451e-04\n",
      "Epoch 354/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 270.0599 - root_mean_squared_error: 16.4335\n",
      "Epoch 354: val_loss did not improve from 52.00172\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 255.4390 - root_mean_squared_error: 15.9825 - val_loss: 53.0661 - val_root_mean_squared_error: 7.2846 - lr: 8.1451e-04\n",
      "Epoch 355/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 62.5505 - root_mean_squared_error: 7.9089\n",
      "Epoch 355: val_loss did not improve from 52.00172\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 254.0801 - root_mean_squared_error: 15.9399 - val_loss: 53.9453 - val_root_mean_squared_error: 7.3447 - lr: 8.1451e-04\n",
      "Epoch 356/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 300.7257 - root_mean_squared_error: 17.3414\n",
      "Epoch 356: val_loss improved from 52.00172 to 51.60242, saving model to Model\\356-253.9973-51.6024.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 253.9973 - root_mean_squared_error: 15.9373 - val_loss: 51.6024 - val_root_mean_squared_error: 7.1835 - lr: 8.1451e-04\n",
      "Epoch 357/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 310.4969 - root_mean_squared_error: 17.6209\n",
      "Epoch 357: val_loss did not improve from 51.60242\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 254.4725 - root_mean_squared_error: 15.9522 - val_loss: 51.8586 - val_root_mean_squared_error: 7.2013 - lr: 8.1451e-04\n",
      "Epoch 358/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 467.9861 - root_mean_squared_error: 21.6330\n",
      "Epoch 358: val_loss did not improve from 51.60242\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 253.5600 - root_mean_squared_error: 15.9236 - val_loss: 51.9316 - val_root_mean_squared_error: 7.2064 - lr: 8.1451e-04\n",
      "Epoch 359/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 144.2077 - root_mean_squared_error: 12.0087\n",
      "Epoch 359: val_loss did not improve from 51.60242\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 256.0604 - root_mean_squared_error: 16.0019 - val_loss: 53.6015 - val_root_mean_squared_error: 7.3213 - lr: 8.1451e-04\n",
      "Epoch 360/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 704.8304 - root_mean_squared_error: 26.5486\n",
      "Epoch 360: val_loss improved from 51.60242 to 48.86287, saving model to Model\\360-254.7424-48.8629.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 254.7424 - root_mean_squared_error: 15.9607 - val_loss: 48.8629 - val_root_mean_squared_error: 6.9902 - lr: 8.1451e-04\n",
      "Epoch 361/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 41.9664 - root_mean_squared_error: 6.4781\n",
      "Epoch 361: val_loss did not improve from 48.86287\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 257.0382 - root_mean_squared_error: 16.0324 - val_loss: 53.8699 - val_root_mean_squared_error: 7.3396 - lr: 8.1451e-04\n",
      "Epoch 362/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 141.8460 - root_mean_squared_error: 11.9099\n",
      "Epoch 362: val_loss did not improve from 48.86287\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 253.7273 - root_mean_squared_error: 15.9288 - val_loss: 51.8781 - val_root_mean_squared_error: 7.2026 - lr: 8.1451e-04\n",
      "Epoch 363/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 481.9161 - root_mean_squared_error: 21.9526\n",
      "Epoch 363: val_loss did not improve from 48.86287\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 253.0844 - root_mean_squared_error: 15.9086 - val_loss: 51.0709 - val_root_mean_squared_error: 7.1464 - lr: 8.1451e-04\n",
      "Epoch 364/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 61.7944 - root_mean_squared_error: 7.8609\n",
      "Epoch 364: val_loss did not improve from 48.86287\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 255.1891 - root_mean_squared_error: 15.9746 - val_loss: 52.2036 - val_root_mean_squared_error: 7.2252 - lr: 8.1451e-04\n",
      "Epoch 365/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 261.7281 - root_mean_squared_error: 16.1780\n",
      "Epoch 365: val_loss did not improve from 48.86287\n",
      "\n",
      "Epoch 365: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 254.2742 - root_mean_squared_error: 15.9460 - val_loss: 50.2168 - val_root_mean_squared_error: 7.0864 - lr: 8.1451e-04\n",
      "Epoch 366/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 90.0848 - root_mean_squared_error: 9.4913\n",
      "Epoch 366: val_loss did not improve from 48.86287\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 254.4585 - root_mean_squared_error: 15.9518 - val_loss: 54.0295 - val_root_mean_squared_error: 7.3505 - lr: 7.7378e-04\n",
      "Epoch 367/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 511.5181 - root_mean_squared_error: 22.6168\n",
      "Epoch 367: val_loss did not improve from 48.86287\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 255.1146 - root_mean_squared_error: 15.9723 - val_loss: 49.3783 - val_root_mean_squared_error: 7.0270 - lr: 7.7378e-04\n",
      "Epoch 368/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 46.5879 - root_mean_squared_error: 6.8255\n",
      "Epoch 368: val_loss did not improve from 48.86287\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 253.3815 - root_mean_squared_error: 15.9180 - val_loss: 51.8186 - val_root_mean_squared_error: 7.1985 - lr: 7.7378e-04\n",
      "Epoch 369/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 129.1817 - root_mean_squared_error: 11.3658\n",
      "Epoch 369: val_loss improved from 48.86287 to 46.72050, saving model to Model\\369-252.1573-46.7205.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 252.1573 - root_mean_squared_error: 15.8795 - val_loss: 46.7205 - val_root_mean_squared_error: 6.8352 - lr: 7.7378e-04\n",
      "Epoch 370/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 273.5275 - root_mean_squared_error: 16.5387\n",
      "Epoch 370: val_loss did not improve from 46.72050\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 252.7887 - root_mean_squared_error: 15.8993 - val_loss: 52.4696 - val_root_mean_squared_error: 7.2436 - lr: 7.7378e-04\n",
      "Epoch 371/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 123.6097 - root_mean_squared_error: 11.1180\n",
      "Epoch 371: val_loss did not improve from 46.72050\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 255.7626 - root_mean_squared_error: 15.9926 - val_loss: 50.0224 - val_root_mean_squared_error: 7.0727 - lr: 7.7378e-04\n",
      "Epoch 372/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 342.5005 - root_mean_squared_error: 18.5068\n",
      "Epoch 372: val_loss did not improve from 46.72050\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 253.4921 - root_mean_squared_error: 15.9214 - val_loss: 47.5382 - val_root_mean_squared_error: 6.8948 - lr: 7.7378e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 756.2666 - root_mean_squared_error: 27.5003\n",
      "Epoch 373: val_loss did not improve from 46.72050\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.8999 - root_mean_squared_error: 15.8714 - val_loss: 48.1075 - val_root_mean_squared_error: 6.9360 - lr: 7.7378e-04\n",
      "Epoch 374/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 460.7012 - root_mean_squared_error: 21.4640\n",
      "Epoch 374: val_loss did not improve from 46.72050\n",
      "\n",
      "Epoch 374: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 252.1208 - root_mean_squared_error: 15.8783 - val_loss: 49.7948 - val_root_mean_squared_error: 7.0565 - lr: 7.7378e-04\n",
      "Epoch 375/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 132.7471 - root_mean_squared_error: 11.5216\n",
      "Epoch 375: val_loss did not improve from 46.72050\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 253.9271 - root_mean_squared_error: 15.9351 - val_loss: 47.3173 - val_root_mean_squared_error: 6.8788 - lr: 7.3509e-04\n",
      "Epoch 376/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 296.7009 - root_mean_squared_error: 17.2250\n",
      "Epoch 376: val_loss did not improve from 46.72050\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.4178 - root_mean_squared_error: 15.8562 - val_loss: 49.2318 - val_root_mean_squared_error: 7.0165 - lr: 7.3509e-04\n",
      "Epoch 377/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 89.8667 - root_mean_squared_error: 9.4798\n",
      "Epoch 377: val_loss did not improve from 46.72050\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.3952 - root_mean_squared_error: 15.8554 - val_loss: 47.0329 - val_root_mean_squared_error: 6.8581 - lr: 7.3509e-04\n",
      "Epoch 378/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 80.1519 - root_mean_squared_error: 8.9528\n",
      "Epoch 378: val_loss did not improve from 46.72050\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 250.8164 - root_mean_squared_error: 15.8372 - val_loss: 47.7677 - val_root_mean_squared_error: 6.9114 - lr: 7.3509e-04\n",
      "Epoch 379/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 111.4847 - root_mean_squared_error: 10.5586\n",
      "Epoch 379: val_loss did not improve from 46.72050\n",
      "\n",
      "Epoch 379: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.7676 - root_mean_squared_error: 15.8672 - val_loss: 47.9482 - val_root_mean_squared_error: 6.9245 - lr: 7.3509e-04\n",
      "Epoch 380/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 177.2517 - root_mean_squared_error: 13.3136\n",
      "Epoch 380: val_loss did not improve from 46.72050\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.3950 - root_mean_squared_error: 15.8554 - val_loss: 49.8011 - val_root_mean_squared_error: 7.0570 - lr: 6.9834e-04\n",
      "Epoch 381/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 86.2131 - root_mean_squared_error: 9.2851\n",
      "Epoch 381: val_loss improved from 46.72050 to 46.44191, saving model to Model\\381-251.8714-46.4419.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.8714 - root_mean_squared_error: 15.8705 - val_loss: 46.4419 - val_root_mean_squared_error: 6.8148 - lr: 6.9834e-04\n",
      "Epoch 382/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 475.8076 - root_mean_squared_error: 21.8130\n",
      "Epoch 382: val_loss improved from 46.44191 to 45.51539, saving model to Model\\382-250.4709-45.5154.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 250.4709 - root_mean_squared_error: 15.8263 - val_loss: 45.5154 - val_root_mean_squared_error: 6.7465 - lr: 6.9834e-04\n",
      "Epoch 383/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 306.0743 - root_mean_squared_error: 17.4950\n",
      "Epoch 383: val_loss improved from 45.51539 to 45.48308, saving model to Model\\383-250.4149-45.4831.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 250.4149 - root_mean_squared_error: 15.8245 - val_loss: 45.4831 - val_root_mean_squared_error: 6.7441 - lr: 6.9834e-04\n",
      "Epoch 384/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 529.0973 - root_mean_squared_error: 23.0021\n",
      "Epoch 384: val_loss did not improve from 45.48308\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.2323 - root_mean_squared_error: 15.8503 - val_loss: 46.7748 - val_root_mean_squared_error: 6.8392 - lr: 6.9834e-04\n",
      "Epoch 385/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 81.6236 - root_mean_squared_error: 9.0346\n",
      "Epoch 385: val_loss improved from 45.48308 to 44.36975, saving model to Model\\385-250.4947-44.3698.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 250.4947 - root_mean_squared_error: 15.8270 - val_loss: 44.3698 - val_root_mean_squared_error: 6.6611 - lr: 6.9834e-04\n",
      "Epoch 386/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 275.7559 - root_mean_squared_error: 16.6059\n",
      "Epoch 386: val_loss did not improve from 44.36975\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.0634 - root_mean_squared_error: 15.8450 - val_loss: 47.7533 - val_root_mean_squared_error: 6.9104 - lr: 6.9834e-04\n",
      "Epoch 387/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 313.5638 - root_mean_squared_error: 17.7077\n",
      "Epoch 387: val_loss did not improve from 44.36975\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.8728 - root_mean_squared_error: 15.8705 - val_loss: 45.4130 - val_root_mean_squared_error: 6.7389 - lr: 6.9834e-04\n",
      "Epoch 388/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 453.1029 - root_mean_squared_error: 21.2862\n",
      "Epoch 388: val_loss did not improve from 44.36975\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 250.6365 - root_mean_squared_error: 15.8315 - val_loss: 44.8104 - val_root_mean_squared_error: 6.6941 - lr: 6.9834e-04\n",
      "Epoch 389/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 37.6057 - root_mean_squared_error: 6.1323\n",
      "Epoch 389: val_loss did not improve from 44.36975\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.3906 - root_mean_squared_error: 15.8553 - val_loss: 45.4488 - val_root_mean_squared_error: 6.7416 - lr: 6.9834e-04\n",
      "Epoch 390/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 100.8833 - root_mean_squared_error: 10.0441\n",
      "Epoch 390: val_loss did not improve from 44.36975\n",
      "\n",
      "Epoch 390: ReduceLROnPlateau reducing learning rate to 0.0006634203542489559.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 250.7783 - root_mean_squared_error: 15.8360 - val_loss: 46.7929 - val_root_mean_squared_error: 6.8405 - lr: 6.9834e-04\n",
      "Epoch 391/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 88.4969 - root_mean_squared_error: 9.4073\n",
      "Epoch 391: val_loss did not improve from 44.36975\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 250.8986 - root_mean_squared_error: 15.8398 - val_loss: 48.0972 - val_root_mean_squared_error: 6.9352 - lr: 6.6342e-04\n",
      "Epoch 392/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 64.4866 - root_mean_squared_error: 8.0304\n",
      "Epoch 392: val_loss did not improve from 44.36975\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 251.5792 - root_mean_squared_error: 15.8612 - val_loss: 44.3865 - val_root_mean_squared_error: 6.6623 - lr: 6.6342e-04\n",
      "Epoch 393/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 624.5970 - root_mean_squared_error: 24.9919\n",
      "Epoch 393: val_loss did not improve from 44.36975\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 256.3352 - root_mean_squared_error: 16.0105 - val_loss: 45.7162 - val_root_mean_squared_error: 6.7614 - lr: 6.6342e-04\n",
      "Epoch 394/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 207.9138 - root_mean_squared_error: 14.4192\n",
      "Epoch 394: val_loss improved from 44.36975 to 42.41335, saving model to Model\\394-250.5576-42.4133.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 250.5576 - root_mean_squared_error: 15.8290 - val_loss: 42.4133 - val_root_mean_squared_error: 6.5126 - lr: 6.6342e-04\n",
      "Epoch 395/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/16 [>.............................] - ETA: 0s - loss: 272.6784 - root_mean_squared_error: 16.5130\n",
      "Epoch 395: val_loss did not improve from 42.41335\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 249.8567 - root_mean_squared_error: 15.8069 - val_loss: 45.8606 - val_root_mean_squared_error: 6.7720 - lr: 6.6342e-04\n",
      "Epoch 396/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 493.8419 - root_mean_squared_error: 22.2226\n",
      "Epoch 396: val_loss did not improve from 42.41335\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 249.2501 - root_mean_squared_error: 15.7877 - val_loss: 44.0514 - val_root_mean_squared_error: 6.6371 - lr: 6.6342e-04\n",
      "Epoch 397/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 471.6769 - root_mean_squared_error: 21.7181\n",
      "Epoch 397: val_loss did not improve from 42.41335\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.7360 - root_mean_squared_error: 15.7714 - val_loss: 44.1119 - val_root_mean_squared_error: 6.6417 - lr: 6.6342e-04\n",
      "Epoch 398/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 406.4768 - root_mean_squared_error: 20.1613\n",
      "Epoch 398: val_loss did not improve from 42.41335\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.8319 - root_mean_squared_error: 15.7744 - val_loss: 44.3095 - val_root_mean_squared_error: 6.6565 - lr: 6.6342e-04\n",
      "Epoch 399/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 57.2815 - root_mean_squared_error: 7.5685\n",
      "Epoch 399: val_loss did not improve from 42.41335\n",
      "\n",
      "Epoch 399: ReduceLROnPlateau reducing learning rate to 0.0006302493420662358.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 250.7628 - root_mean_squared_error: 15.8355 - val_loss: 45.4545 - val_root_mean_squared_error: 6.7420 - lr: 6.6342e-04\n",
      "Epoch 400/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 53.5329 - root_mean_squared_error: 7.3166\n",
      "Epoch 400: val_loss did not improve from 42.41335\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.7708 - root_mean_squared_error: 15.7725 - val_loss: 44.4435 - val_root_mean_squared_error: 6.6666 - lr: 6.3025e-04\n",
      "Epoch 401/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 537.8378 - root_mean_squared_error: 23.1913\n",
      "Epoch 401: val_loss did not improve from 42.41335\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 249.6884 - root_mean_squared_error: 15.8015 - val_loss: 42.4944 - val_root_mean_squared_error: 6.5188 - lr: 6.3025e-04\n",
      "Epoch 402/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 42.8776 - root_mean_squared_error: 6.5481\n",
      "Epoch 402: val_loss did not improve from 42.41335\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.8714 - root_mean_squared_error: 15.7757 - val_loss: 47.3093 - val_root_mean_squared_error: 6.8782 - lr: 6.3025e-04\n",
      "Epoch 403/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 504.4259 - root_mean_squared_error: 22.4594\n",
      "Epoch 403: val_loss improved from 42.41335 to 41.33491, saving model to Model\\403-248.9361-41.3349.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.9361 - root_mean_squared_error: 15.7777 - val_loss: 41.3349 - val_root_mean_squared_error: 6.4292 - lr: 6.3025e-04\n",
      "Epoch 404/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 306.4851 - root_mean_squared_error: 17.5067\n",
      "Epoch 404: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.6487 - root_mean_squared_error: 15.7686 - val_loss: 48.8558 - val_root_mean_squared_error: 6.9897 - lr: 6.3025e-04\n",
      "Epoch 405/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 767.3968 - root_mean_squared_error: 27.7019\n",
      "Epoch 405: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.9785 - root_mean_squared_error: 15.7473 - val_loss: 41.5417 - val_root_mean_squared_error: 6.4453 - lr: 6.3025e-04\n",
      "Epoch 406/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 231.4116 - root_mean_squared_error: 15.2122\n",
      "Epoch 406: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 249.9867 - root_mean_squared_error: 15.8110 - val_loss: 46.9113 - val_root_mean_squared_error: 6.8492 - lr: 6.3025e-04\n",
      "Epoch 407/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 64.0913 - root_mean_squared_error: 8.0057\n",
      "Epoch 407: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.7059 - root_mean_squared_error: 15.7704 - val_loss: 45.0702 - val_root_mean_squared_error: 6.7134 - lr: 6.3025e-04\n",
      "Epoch 408/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 317.6586 - root_mean_squared_error: 17.8230\n",
      "Epoch 408: val_loss did not improve from 41.33491\n",
      "\n",
      "Epoch 408: ReduceLROnPlateau reducing learning rate to 0.0005987368611386045.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.4814 - root_mean_squared_error: 15.7315 - val_loss: 42.7470 - val_root_mean_squared_error: 6.5381 - lr: 6.3025e-04\n",
      "Epoch 409/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 56.3376 - root_mean_squared_error: 7.5058\n",
      "Epoch 409: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.3971 - root_mean_squared_error: 15.7289 - val_loss: 44.2934 - val_root_mean_squared_error: 6.6553 - lr: 5.9874e-04\n",
      "Epoch 410/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 60.3271 - root_mean_squared_error: 7.7671\n",
      "Epoch 410: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.7163 - root_mean_squared_error: 15.7707 - val_loss: 41.8225 - val_root_mean_squared_error: 6.4670 - lr: 5.9874e-04\n",
      "Epoch 411/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 222.1151 - root_mean_squared_error: 14.9035\n",
      "Epoch 411: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.4293 - root_mean_squared_error: 15.7299 - val_loss: 43.0934 - val_root_mean_squared_error: 6.5646 - lr: 5.9874e-04\n",
      "Epoch 412/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 368.2061 - root_mean_squared_error: 19.1887\n",
      "Epoch 412: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.1662 - root_mean_squared_error: 15.7533 - val_loss: 44.6515 - val_root_mean_squared_error: 6.6822 - lr: 5.9874e-04\n",
      "Epoch 413/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 135.7109 - root_mean_squared_error: 11.6495\n",
      "Epoch 413: val_loss did not improve from 41.33491\n",
      "\n",
      "Epoch 413: ReduceLROnPlateau reducing learning rate to 0.0005688000208465382.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.6578 - root_mean_squared_error: 15.7371 - val_loss: 43.0151 - val_root_mean_squared_error: 6.5586 - lr: 5.9874e-04\n",
      "Epoch 414/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 274.9218 - root_mean_squared_error: 16.5808\n",
      "Epoch 414: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.0264 - root_mean_squared_error: 15.7171 - val_loss: 42.8171 - val_root_mean_squared_error: 6.5435 - lr: 5.6880e-04\n",
      "Epoch 415/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 114.7877 - root_mean_squared_error: 10.7139\n",
      "Epoch 415: val_loss did not improve from 41.33491\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.1703 - root_mean_squared_error: 15.7217 - val_loss: 42.3619 - val_root_mean_squared_error: 6.5086 - lr: 5.6880e-04\n",
      "Epoch 416/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 293.6125 - root_mean_squared_error: 17.1351\n",
      "Epoch 416: val_loss improved from 41.33491 to 41.27323, saving model to Model\\416-247.6560-41.2732.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.6560 - root_mean_squared_error: 15.7371 - val_loss: 41.2732 - val_root_mean_squared_error: 6.4244 - lr: 5.6880e-04\n",
      "Epoch 417/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 304.1758 - root_mean_squared_error: 17.4406\n",
      "Epoch 417: val_loss did not improve from 41.27323\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.9141 - root_mean_squared_error: 15.7770 - val_loss: 45.9129 - val_root_mean_squared_error: 6.7759 - lr: 5.6880e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 74.4890 - root_mean_squared_error: 8.6307\n",
      "Epoch 418: val_loss improved from 41.27323 to 40.94534, saving model to Model\\418-248.6010-40.9453.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 248.6010 - root_mean_squared_error: 15.7671 - val_loss: 40.9453 - val_root_mean_squared_error: 6.3989 - lr: 5.6880e-04\n",
      "Epoch 419/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 372.1813 - root_mean_squared_error: 19.2920\n",
      "Epoch 419: val_loss did not improve from 40.94534\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.1370 - root_mean_squared_error: 15.7206 - val_loss: 41.6410 - val_root_mean_squared_error: 6.4530 - lr: 5.6880e-04\n",
      "Epoch 420/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 77.0593 - root_mean_squared_error: 8.7783\n",
      "Epoch 420: val_loss did not improve from 40.94534\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 246.6438 - root_mean_squared_error: 15.7049 - val_loss: 42.3965 - val_root_mean_squared_error: 6.5113 - lr: 5.6880e-04\n",
      "Epoch 421/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 289.1884 - root_mean_squared_error: 17.0055\n",
      "Epoch 421: val_loss improved from 40.94534 to 40.91543, saving model to Model\\421-247.3228-40.9154.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.3228 - root_mean_squared_error: 15.7265 - val_loss: 40.9154 - val_root_mean_squared_error: 6.3965 - lr: 5.6880e-04\n",
      "Epoch 422/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 634.4019 - root_mean_squared_error: 25.1873\n",
      "Epoch 422: val_loss did not improve from 40.91543\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.1945 - root_mean_squared_error: 15.7224 - val_loss: 42.5162 - val_root_mean_squared_error: 6.5204 - lr: 5.6880e-04\n",
      "Epoch 423/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 253.4487 - root_mean_squared_error: 15.9201\n",
      "Epoch 423: val_loss improved from 40.91543 to 40.00092, saving model to Model\\423-245.8979-40.0009.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.8979 - root_mean_squared_error: 15.6811 - val_loss: 40.0009 - val_root_mean_squared_error: 6.3246 - lr: 5.6880e-04\n",
      "Epoch 424/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 253.0249 - root_mean_squared_error: 15.9068\n",
      "Epoch 424: val_loss did not improve from 40.00092\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.1908 - root_mean_squared_error: 15.7223 - val_loss: 41.8869 - val_root_mean_squared_error: 6.4720 - lr: 5.6880e-04\n",
      "Epoch 425/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 483.4546 - root_mean_squared_error: 21.9876\n",
      "Epoch 425: val_loss improved from 40.00092 to 39.85707, saving model to Model\\425-246.1272-39.8571.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 246.1272 - root_mean_squared_error: 15.6884 - val_loss: 39.8571 - val_root_mean_squared_error: 6.3132 - lr: 5.6880e-04\n",
      "Epoch 426/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 285.0563 - root_mean_squared_error: 16.8836\n",
      "Epoch 426: val_loss did not improve from 39.85707\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.4888 - root_mean_squared_error: 15.7318 - val_loss: 42.8881 - val_root_mean_squared_error: 6.5489 - lr: 5.6880e-04\n",
      "Epoch 427/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 259.8090 - root_mean_squared_error: 16.1186\n",
      "Epoch 427: val_loss improved from 39.85707 to 39.46555, saving model to Model\\427-246.2696-39.4656.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 246.2696 - root_mean_squared_error: 15.6930 - val_loss: 39.4656 - val_root_mean_squared_error: 6.2822 - lr: 5.6880e-04\n",
      "Epoch 428/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 1079.9357 - root_mean_squared_error: 32.8624\n",
      "Epoch 428: val_loss did not improve from 39.46555\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 249.3013 - root_mean_squared_error: 15.7893 - val_loss: 39.6999 - val_root_mean_squared_error: 6.3008 - lr: 5.6880e-04\n",
      "Epoch 429/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 485.2832 - root_mean_squared_error: 22.0291\n",
      "Epoch 429: val_loss did not improve from 39.46555\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 246.1415 - root_mean_squared_error: 15.6889 - val_loss: 39.9581 - val_root_mean_squared_error: 6.3212 - lr: 5.6880e-04\n",
      "Epoch 430/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 238.1285 - root_mean_squared_error: 15.4314\n",
      "Epoch 430: val_loss did not improve from 39.46555\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.8746 - root_mean_squared_error: 15.6804 - val_loss: 41.6373 - val_root_mean_squared_error: 6.4527 - lr: 5.6880e-04\n",
      "Epoch 431/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 280.5432 - root_mean_squared_error: 16.7494\n",
      "Epoch 431: val_loss did not improve from 39.46555\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 246.1463 - root_mean_squared_error: 15.6891 - val_loss: 40.5918 - val_root_mean_squared_error: 6.3712 - lr: 5.6880e-04\n",
      "Epoch 432/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 218.9749 - root_mean_squared_error: 14.7978\n",
      "Epoch 432: val_loss did not improve from 39.46555\n",
      "\n",
      "Epoch 432: ReduceLROnPlateau reducing learning rate to 0.0005403600225690752.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.7161 - root_mean_squared_error: 15.6753 - val_loss: 40.4453 - val_root_mean_squared_error: 6.3597 - lr: 5.6880e-04\n",
      "Epoch 433/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 306.6628 - root_mean_squared_error: 17.5118\n",
      "Epoch 433: val_loss did not improve from 39.46555\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.4722 - root_mean_squared_error: 15.6676 - val_loss: 40.3978 - val_root_mean_squared_error: 6.3559 - lr: 5.4036e-04\n",
      "Epoch 434/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 596.2149 - root_mean_squared_error: 24.4175\n",
      "Epoch 434: val_loss improved from 39.46555 to 39.01039, saving model to Model\\434-245.2564-39.0104.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.2564 - root_mean_squared_error: 15.6607 - val_loss: 39.0104 - val_root_mean_squared_error: 6.2458 - lr: 5.4036e-04\n",
      "Epoch 435/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 48.7480 - root_mean_squared_error: 6.9820\n",
      "Epoch 435: val_loss did not improve from 39.01039\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.6549 - root_mean_squared_error: 15.6734 - val_loss: 42.6518 - val_root_mean_squared_error: 6.5308 - lr: 5.4036e-04\n",
      "Epoch 436/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 242.2585 - root_mean_squared_error: 15.5647\n",
      "Epoch 436: val_loss did not improve from 39.01039\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.9227 - root_mean_squared_error: 15.6500 - val_loss: 39.6859 - val_root_mean_squared_error: 6.2997 - lr: 5.4036e-04\n",
      "Epoch 437/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 56.3850 - root_mean_squared_error: 7.5090\n",
      "Epoch 437: val_loss improved from 39.01039 to 38.97198, saving model to Model\\437-246.3751-38.9720.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 246.3751 - root_mean_squared_error: 15.6963 - val_loss: 38.9720 - val_root_mean_squared_error: 6.2428 - lr: 5.4036e-04\n",
      "Epoch 438/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 339.5605 - root_mean_squared_error: 18.4272\n",
      "Epoch 438: val_loss did not improve from 38.97198\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.8307 - root_mean_squared_error: 15.6790 - val_loss: 42.7631 - val_root_mean_squared_error: 6.5393 - lr: 5.4036e-04\n",
      "Epoch 439/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 195.9553 - root_mean_squared_error: 13.9984\n",
      "Epoch 439: val_loss did not improve from 38.97198\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.2805 - root_mean_squared_error: 15.6614 - val_loss: 39.0969 - val_root_mean_squared_error: 6.2528 - lr: 5.4036e-04\n",
      "Epoch 440/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 73.3952 - root_mean_squared_error: 8.5671\n",
      "Epoch 440: val_loss did not improve from 38.97198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 244.6506 - root_mean_squared_error: 15.6413 - val_loss: 42.0788 - val_root_mean_squared_error: 6.4868 - lr: 5.4036e-04\n",
      "Epoch 441/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 484.6748 - root_mean_squared_error: 22.0153\n",
      "Epoch 441: val_loss did not improve from 38.97198\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.5287 - root_mean_squared_error: 15.6374 - val_loss: 39.4488 - val_root_mean_squared_error: 6.2808 - lr: 5.4036e-04\n",
      "Epoch 442/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 370.2156 - root_mean_squared_error: 19.2410\n",
      "Epoch 442: val_loss improved from 38.97198 to 38.40146, saving model to Model\\442-244.9608-38.4015.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.9608 - root_mean_squared_error: 15.6512 - val_loss: 38.4015 - val_root_mean_squared_error: 6.1969 - lr: 5.4036e-04\n",
      "Epoch 443/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 447.5454 - root_mean_squared_error: 21.1553\n",
      "Epoch 443: val_loss did not improve from 38.40146\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 246.6645 - root_mean_squared_error: 15.7056 - val_loss: 41.6823 - val_root_mean_squared_error: 6.4562 - lr: 5.4036e-04\n",
      "Epoch 444/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 175.0832 - root_mean_squared_error: 13.2319\n",
      "Epoch 444: val_loss did not improve from 38.40146\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 247.1400 - root_mean_squared_error: 15.7207 - val_loss: 38.7002 - val_root_mean_squared_error: 6.2209 - lr: 5.4036e-04\n",
      "Epoch 445/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 355.7149 - root_mean_squared_error: 18.8604\n",
      "Epoch 445: val_loss did not improve from 38.40146\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.2928 - root_mean_squared_error: 15.6299 - val_loss: 39.9922 - val_root_mean_squared_error: 6.3239 - lr: 5.4036e-04\n",
      "Epoch 446/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 243.8681 - root_mean_squared_error: 15.6163\n",
      "Epoch 446: val_loss improved from 38.40146 to 37.73674, saving model to Model\\446-244.6878-37.7367.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.6878 - root_mean_squared_error: 15.6425 - val_loss: 37.7367 - val_root_mean_squared_error: 6.1430 - lr: 5.4036e-04\n",
      "Epoch 447/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 272.0894 - root_mean_squared_error: 16.4951\n",
      "Epoch 447: val_loss did not improve from 37.73674\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.1950 - root_mean_squared_error: 15.6587 - val_loss: 43.4198 - val_root_mean_squared_error: 6.5894 - lr: 5.4036e-04\n",
      "Epoch 448/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 53.6613 - root_mean_squared_error: 7.3254\n",
      "Epoch 448: val_loss did not improve from 37.73674\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.5082 - root_mean_squared_error: 15.6368 - val_loss: 38.9269 - val_root_mean_squared_error: 6.2391 - lr: 5.4036e-04\n",
      "Epoch 449/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 287.6305 - root_mean_squared_error: 16.9597\n",
      "Epoch 449: val_loss did not improve from 37.73674\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.3635 - root_mean_squared_error: 15.6641 - val_loss: 40.4644 - val_root_mean_squared_error: 6.3612 - lr: 5.4036e-04\n",
      "Epoch 450/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 158.9665 - root_mean_squared_error: 12.6082\n",
      "Epoch 450: val_loss did not improve from 37.73674\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.8962 - root_mean_squared_error: 15.6172 - val_loss: 39.3016 - val_root_mean_squared_error: 6.2691 - lr: 5.4036e-04\n",
      "Epoch 451/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 331.1088 - root_mean_squared_error: 18.1964\n",
      "Epoch 451: val_loss improved from 37.73674 to 36.86192, saving model to Model\\451-245.0145-36.8619.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.0145 - root_mean_squared_error: 15.6529 - val_loss: 36.8619 - val_root_mean_squared_error: 6.0714 - lr: 5.4036e-04\n",
      "Epoch 452/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 289.0761 - root_mean_squared_error: 17.0022\n",
      "Epoch 452: val_loss did not improve from 36.86192\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.7922 - root_mean_squared_error: 15.6458 - val_loss: 41.6382 - val_root_mean_squared_error: 6.4528 - lr: 5.4036e-04\n",
      "Epoch 453/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 22.6171 - root_mean_squared_error: 4.7557\n",
      "Epoch 453: val_loss did not improve from 36.86192\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.7237 - root_mean_squared_error: 15.6117 - val_loss: 38.6599 - val_root_mean_squared_error: 6.2177 - lr: 5.4036e-04\n",
      "Epoch 454/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 235.1522 - root_mean_squared_error: 15.3347\n",
      "Epoch 454: val_loss did not improve from 36.86192\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.0697 - root_mean_squared_error: 15.6227 - val_loss: 37.8631 - val_root_mean_squared_error: 6.1533 - lr: 5.4036e-04\n",
      "Epoch 455/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 415.7485 - root_mean_squared_error: 20.3899\n",
      "Epoch 455: val_loss did not improve from 36.86192\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.4891 - root_mean_squared_error: 15.6361 - val_loss: 38.5681 - val_root_mean_squared_error: 6.2103 - lr: 5.4036e-04\n",
      "Epoch 456/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 411.0729 - root_mean_squared_error: 20.2749\n",
      "Epoch 456: val_loss did not improve from 36.86192\n",
      "\n",
      "Epoch 456: ReduceLROnPlateau reducing learning rate to 0.0005133419937919825.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.2955 - root_mean_squared_error: 15.5979 - val_loss: 38.2657 - val_root_mean_squared_error: 6.1859 - lr: 5.4036e-04\n",
      "Epoch 457/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 50.6711 - root_mean_squared_error: 7.1184\n",
      "Epoch 457: val_loss did not improve from 36.86192\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.9708 - root_mean_squared_error: 15.6835 - val_loss: 37.6493 - val_root_mean_squared_error: 6.1359 - lr: 5.1334e-04\n",
      "Epoch 458/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 473.5804 - root_mean_squared_error: 21.7619\n",
      "Epoch 458: val_loss did not improve from 36.86192\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 245.8586 - root_mean_squared_error: 15.6799 - val_loss: 44.9700 - val_root_mean_squared_error: 6.7060 - lr: 5.1334e-04\n",
      "Epoch 459/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 177.9188 - root_mean_squared_error: 13.3386\n",
      "Epoch 459: val_loss improved from 36.86192 to 36.54569, saving model to Model\\459-243.6740-36.5457.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.6740 - root_mean_squared_error: 15.6101 - val_loss: 36.5457 - val_root_mean_squared_error: 6.0453 - lr: 5.1334e-04\n",
      "Epoch 460/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 62.2176 - root_mean_squared_error: 7.8878\n",
      "Epoch 460: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.1523 - root_mean_squared_error: 15.5933 - val_loss: 41.0037 - val_root_mean_squared_error: 6.4034 - lr: 5.1334e-04\n",
      "Epoch 461/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 67.6445 - root_mean_squared_error: 8.2246\n",
      "Epoch 461: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.1290 - root_mean_squared_error: 15.5926 - val_loss: 36.7952 - val_root_mean_squared_error: 6.0659 - lr: 5.1334e-04\n",
      "Epoch 462/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 64.6110 - root_mean_squared_error: 8.0381\n",
      "Epoch 462: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.3561 - root_mean_squared_error: 15.5999 - val_loss: 37.9782 - val_root_mean_squared_error: 6.1626 - lr: 5.1334e-04\n",
      "Epoch 463/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 90.1634 - root_mean_squared_error: 9.4954\n",
      "Epoch 463: val_loss did not improve from 36.54569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 242.9483 - root_mean_squared_error: 15.5868 - val_loss: 40.5385 - val_root_mean_squared_error: 6.3670 - lr: 5.1334e-04\n",
      "Epoch 464/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 640.6230 - root_mean_squared_error: 25.3105\n",
      "Epoch 464: val_loss did not improve from 36.54569\n",
      "\n",
      "Epoch 464: ReduceLROnPlateau reducing learning rate to 0.0004876748775132.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.7321 - root_mean_squared_error: 15.6119 - val_loss: 39.7629 - val_root_mean_squared_error: 6.3058 - lr: 5.1334e-04\n",
      "Epoch 465/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 54.6391 - root_mean_squared_error: 7.3918\n",
      "Epoch 465: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 244.1625 - root_mean_squared_error: 15.6257 - val_loss: 39.3584 - val_root_mean_squared_error: 6.2736 - lr: 4.8767e-04\n",
      "Epoch 466/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 405.1791 - root_mean_squared_error: 20.1291\n",
      "Epoch 466: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.8888 - root_mean_squared_error: 15.5849 - val_loss: 37.6406 - val_root_mean_squared_error: 6.1352 - lr: 4.8767e-04\n",
      "Epoch 467/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 52.7972 - root_mean_squared_error: 7.2662\n",
      "Epoch 467: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.5655 - root_mean_squared_error: 15.5745 - val_loss: 37.2860 - val_root_mean_squared_error: 6.1062 - lr: 4.8767e-04\n",
      "Epoch 468/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 260.0801 - root_mean_squared_error: 16.1270\n",
      "Epoch 468: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.3857 - root_mean_squared_error: 15.5687 - val_loss: 39.5673 - val_root_mean_squared_error: 6.2903 - lr: 4.8767e-04\n",
      "Epoch 469/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 258.2094 - root_mean_squared_error: 16.0689\n",
      "Epoch 469: val_loss did not improve from 36.54569\n",
      "\n",
      "Epoch 469: ReduceLROnPlateau reducing learning rate to 0.00046329112810781223.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.4009 - root_mean_squared_error: 15.5692 - val_loss: 37.6330 - val_root_mean_squared_error: 6.1346 - lr: 4.8767e-04\n",
      "Epoch 470/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 172.1015 - root_mean_squared_error: 13.1187\n",
      "Epoch 470: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.3871 - root_mean_squared_error: 15.6009 - val_loss: 36.8774 - val_root_mean_squared_error: 6.0727 - lr: 4.6329e-04\n",
      "Epoch 471/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 615.3830 - root_mean_squared_error: 24.8069\n",
      "Epoch 471: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 243.8304 - root_mean_squared_error: 15.6151 - val_loss: 39.4070 - val_root_mean_squared_error: 6.2775 - lr: 4.6329e-04\n",
      "Epoch 472/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 287.4224 - root_mean_squared_error: 16.9535\n",
      "Epoch 472: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.1385 - root_mean_squared_error: 15.5608 - val_loss: 36.8193 - val_root_mean_squared_error: 6.0679 - lr: 4.6329e-04\n",
      "Epoch 473/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 179.6325 - root_mean_squared_error: 13.4027\n",
      "Epoch 473: val_loss did not improve from 36.54569\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.5555 - root_mean_squared_error: 15.5421 - val_loss: 39.5838 - val_root_mean_squared_error: 6.2916 - lr: 4.6329e-04\n",
      "Epoch 474/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 359.5814 - root_mean_squared_error: 18.9626\n",
      "Epoch 474: val_loss did not improve from 36.54569\n",
      "\n",
      "Epoch 474: ReduceLROnPlateau reducing learning rate to 0.00044012657308485355.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.4098 - root_mean_squared_error: 15.5695 - val_loss: 39.1497 - val_root_mean_squared_error: 6.2570 - lr: 4.6329e-04\n",
      "Epoch 475/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 136.8790 - root_mean_squared_error: 11.6995\n",
      "Epoch 475: val_loss improved from 36.54569 to 36.11111, saving model to Model\\475-242.1946-36.1111.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.1946 - root_mean_squared_error: 15.5626 - val_loss: 36.1111 - val_root_mean_squared_error: 6.0093 - lr: 4.4013e-04\n",
      "Epoch 476/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 503.6412 - root_mean_squared_error: 22.4420\n",
      "Epoch 476: val_loss did not improve from 36.11111\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.7471 - root_mean_squared_error: 15.5482 - val_loss: 37.6553 - val_root_mean_squared_error: 6.1364 - lr: 4.4013e-04\n",
      "Epoch 477/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 245.3362 - root_mean_squared_error: 15.6632\n",
      "Epoch 477: val_loss did not improve from 36.11111\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.7109 - root_mean_squared_error: 15.5471 - val_loss: 38.1353 - val_root_mean_squared_error: 6.1754 - lr: 4.4013e-04\n",
      "Epoch 478/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 181.8859 - root_mean_squared_error: 13.4865\n",
      "Epoch 478: val_loss did not improve from 36.11111\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.0020 - root_mean_squared_error: 15.5564 - val_loss: 36.6625 - val_root_mean_squared_error: 6.0550 - lr: 4.4013e-04\n",
      "Epoch 479/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 61.8794 - root_mean_squared_error: 7.8663\n",
      "Epoch 479: val_loss did not improve from 36.11111\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.4922 - root_mean_squared_error: 15.5400 - val_loss: 36.7706 - val_root_mean_squared_error: 6.0639 - lr: 4.4013e-04\n",
      "Epoch 480/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 266.5054 - root_mean_squared_error: 16.3250\n",
      "Epoch 480: val_loss did not improve from 36.11111\n",
      "\n",
      "Epoch 480: ReduceLROnPlateau reducing learning rate to 0.00041812024719547477.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.0268 - root_mean_squared_error: 15.5572 - val_loss: 38.5766 - val_root_mean_squared_error: 6.2110 - lr: 4.4013e-04\n",
      "Epoch 481/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 308.0179 - root_mean_squared_error: 17.5504\n",
      "Epoch 481: val_loss improved from 36.11111 to 36.05552, saving model to Model\\481-241.3972-36.0555.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 241.3972 - root_mean_squared_error: 15.5370 - val_loss: 36.0555 - val_root_mean_squared_error: 6.0046 - lr: 4.1812e-04\n",
      "Epoch 482/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 273.4009 - root_mean_squared_error: 16.5348\n",
      "Epoch 482: val_loss did not improve from 36.05552\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.7610 - root_mean_squared_error: 15.5487 - val_loss: 36.5409 - val_root_mean_squared_error: 6.0449 - lr: 4.1812e-04\n",
      "Epoch 483/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 317.8014 - root_mean_squared_error: 17.8270\n",
      "Epoch 483: val_loss did not improve from 36.05552\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.1990 - root_mean_squared_error: 15.5306 - val_loss: 38.2923 - val_root_mean_squared_error: 6.1881 - lr: 4.1812e-04\n",
      "Epoch 484/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 251.0782 - root_mean_squared_error: 15.8454\n",
      "Epoch 484: val_loss did not improve from 36.05552\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.9019 - root_mean_squared_error: 15.5532 - val_loss: 37.8270 - val_root_mean_squared_error: 6.1504 - lr: 4.1812e-04\n",
      "Epoch 485/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 605.9820 - root_mean_squared_error: 24.6167\n",
      "Epoch 485: val_loss improved from 36.05552 to 34.10187, saving model to Model\\485-241.7971-34.1019.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.7971 - root_mean_squared_error: 15.5498 - val_loss: 34.1019 - val_root_mean_squared_error: 5.8397 - lr: 4.1812e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 177.3018 - root_mean_squared_error: 13.3155\n",
      "Epoch 486: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.9959 - root_mean_squared_error: 15.5240 - val_loss: 38.5807 - val_root_mean_squared_error: 6.2113 - lr: 4.1812e-04\n",
      "Epoch 487/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 506.3673 - root_mean_squared_error: 22.5026\n",
      "Epoch 487: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.8281 - root_mean_squared_error: 15.5508 - val_loss: 37.0207 - val_root_mean_squared_error: 6.0845 - lr: 4.1812e-04\n",
      "Epoch 488/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 293.4596 - root_mean_squared_error: 17.1307\n",
      "Epoch 488: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.2359 - root_mean_squared_error: 15.5318 - val_loss: 37.4376 - val_root_mean_squared_error: 6.1186 - lr: 4.1812e-04\n",
      "Epoch 489/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 145.2804 - root_mean_squared_error: 12.0532\n",
      "Epoch 489: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.6736 - root_mean_squared_error: 15.5780 - val_loss: 36.0900 - val_root_mean_squared_error: 6.0075 - lr: 4.1812e-04\n",
      "Epoch 490/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 254.3573 - root_mean_squared_error: 15.9486\n",
      "Epoch 490: val_loss did not improve from 34.10187\n",
      "\n",
      "Epoch 490: ReduceLROnPlateau reducing learning rate to 0.00039721422654110934.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.4412 - root_mean_squared_error: 15.5384 - val_loss: 38.4899 - val_root_mean_squared_error: 6.2040 - lr: 4.1812e-04\n",
      "Epoch 491/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 193.8840 - root_mean_squared_error: 13.9242\n",
      "Epoch 491: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.4477 - root_mean_squared_error: 15.5386 - val_loss: 34.3182 - val_root_mean_squared_error: 5.8582 - lr: 3.9721e-04\n",
      "Epoch 492/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 40.2325 - root_mean_squared_error: 6.3429\n",
      "Epoch 492: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.8251 - root_mean_squared_error: 15.5185 - val_loss: 38.2538 - val_root_mean_squared_error: 6.1850 - lr: 3.9721e-04\n",
      "Epoch 493/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 345.8217 - root_mean_squared_error: 18.5963\n",
      "Epoch 493: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.8852 - root_mean_squared_error: 15.5205 - val_loss: 35.6649 - val_root_mean_squared_error: 5.9720 - lr: 3.9721e-04\n",
      "Epoch 494/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 22.5137 - root_mean_squared_error: 4.7449\n",
      "Epoch 494: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.5559 - root_mean_squared_error: 15.5099 - val_loss: 36.5298 - val_root_mean_squared_error: 6.0440 - lr: 3.9721e-04\n",
      "Epoch 495/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 32.9235 - root_mean_squared_error: 5.7379\n",
      "Epoch 495: val_loss did not improve from 34.10187\n",
      "\n",
      "Epoch 495: ReduceLROnPlateau reducing learning rate to 0.00037735351797891776.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.9514 - root_mean_squared_error: 15.5226 - val_loss: 35.7941 - val_root_mean_squared_error: 5.9828 - lr: 3.9721e-04\n",
      "Epoch 496/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 93.1794 - root_mean_squared_error: 9.6529\n",
      "Epoch 496: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.9986 - root_mean_squared_error: 15.5241 - val_loss: 35.4280 - val_root_mean_squared_error: 5.9521 - lr: 3.7735e-04\n",
      "Epoch 497/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 124.2209 - root_mean_squared_error: 11.1454\n",
      "Epoch 497: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.0646 - root_mean_squared_error: 15.4940 - val_loss: 37.3737 - val_root_mean_squared_error: 6.1134 - lr: 3.7735e-04\n",
      "Epoch 498/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 136.7562 - root_mean_squared_error: 11.6943\n",
      "Epoch 498: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 242.3159 - root_mean_squared_error: 15.5665 - val_loss: 35.6965 - val_root_mean_squared_error: 5.9747 - lr: 3.7735e-04\n",
      "Epoch 499/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 197.4001 - root_mean_squared_error: 14.0499\n",
      "Epoch 499: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.2091 - root_mean_squared_error: 15.4987 - val_loss: 37.9160 - val_root_mean_squared_error: 6.1576 - lr: 3.7735e-04\n",
      "Epoch 500/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 45.0908 - root_mean_squared_error: 6.7150\n",
      "Epoch 500: val_loss did not improve from 34.10187\n",
      "\n",
      "Epoch 500: ReduceLROnPlateau reducing learning rate to 0.00035848583793267607.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.3041 - root_mean_squared_error: 15.5017 - val_loss: 37.5754 - val_root_mean_squared_error: 6.1299 - lr: 3.7735e-04\n",
      "Epoch 501/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 256.5517 - root_mean_squared_error: 16.0172\n",
      "Epoch 501: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.4146 - root_mean_squared_error: 15.5053 - val_loss: 36.6884 - val_root_mean_squared_error: 6.0571 - lr: 3.5849e-04\n",
      "Epoch 502/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 46.4529 - root_mean_squared_error: 6.8156\n",
      "Epoch 502: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 241.0038 - root_mean_squared_error: 15.5243 - val_loss: 34.9824 - val_root_mean_squared_error: 5.9146 - lr: 3.5849e-04\n",
      "Epoch 503/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 82.7425 - root_mean_squared_error: 9.0963\n",
      "Epoch 503: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.3311 - root_mean_squared_error: 15.5026 - val_loss: 37.5040 - val_root_mean_squared_error: 6.1241 - lr: 3.5849e-04\n",
      "Epoch 504/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 210.6040 - root_mean_squared_error: 14.5122\n",
      "Epoch 504: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.7665 - root_mean_squared_error: 15.4844 - val_loss: 35.2406 - val_root_mean_squared_error: 5.9364 - lr: 3.5849e-04\n",
      "Epoch 505/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 54.5900 - root_mean_squared_error: 7.3885\n",
      "Epoch 505: val_loss did not improve from 34.10187\n",
      "\n",
      "Epoch 505: ReduceLROnPlateau reducing learning rate to 0.00034056155709549785.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.7182 - root_mean_squared_error: 15.5151 - val_loss: 36.2999 - val_root_mean_squared_error: 6.0249 - lr: 3.5849e-04\n",
      "Epoch 506/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 62.9310 - root_mean_squared_error: 7.9329\n",
      "Epoch 506: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.7822 - root_mean_squared_error: 15.5172 - val_loss: 36.4880 - val_root_mean_squared_error: 6.0405 - lr: 3.4056e-04\n",
      "Epoch 507/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 91.7941 - root_mean_squared_error: 9.5809\n",
      "Epoch 507: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.1880 - root_mean_squared_error: 15.4980 - val_loss: 34.5678 - val_root_mean_squared_error: 5.8794 - lr: 3.4056e-04\n",
      "Epoch 508/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 43.7294 - root_mean_squared_error: 6.6128\n",
      "Epoch 508: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.1952 - root_mean_squared_error: 15.4982 - val_loss: 37.1977 - val_root_mean_squared_error: 6.0990 - lr: 3.4056e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 318.4417 - root_mean_squared_error: 17.8449\n",
      "Epoch 509: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.1982 - root_mean_squared_error: 15.4983 - val_loss: 34.6479 - val_root_mean_squared_error: 5.8862 - lr: 3.4056e-04\n",
      "Epoch 510/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 119.0496 - root_mean_squared_error: 10.9110\n",
      "Epoch 510: val_loss did not improve from 34.10187\n",
      "\n",
      "Epoch 510: ReduceLROnPlateau reducing learning rate to 0.00032353347924072293.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.0804 - root_mean_squared_error: 15.4945 - val_loss: 37.4786 - val_root_mean_squared_error: 6.1220 - lr: 3.4056e-04\n",
      "Epoch 511/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 121.7407 - root_mean_squared_error: 11.0336\n",
      "Epoch 511: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.2131 - root_mean_squared_error: 15.4988 - val_loss: 34.2250 - val_root_mean_squared_error: 5.8502 - lr: 3.2353e-04\n",
      "Epoch 512/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 323.4404 - root_mean_squared_error: 17.9844\n",
      "Epoch 512: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.8716 - root_mean_squared_error: 15.4878 - val_loss: 36.0084 - val_root_mean_squared_error: 6.0007 - lr: 3.2353e-04\n",
      "Epoch 513/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 32.7896 - root_mean_squared_error: 5.7262\n",
      "Epoch 513: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.4923 - root_mean_squared_error: 15.4755 - val_loss: 35.0635 - val_root_mean_squared_error: 5.9214 - lr: 3.2353e-04\n",
      "Epoch 514/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 330.4940 - root_mean_squared_error: 18.1795\n",
      "Epoch 514: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.7035 - root_mean_squared_error: 15.4824 - val_loss: 34.8725 - val_root_mean_squared_error: 5.9053 - lr: 3.2353e-04\n",
      "Epoch 515/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 84.4200 - root_mean_squared_error: 9.1880\n",
      "Epoch 515: val_loss did not improve from 34.10187\n",
      "\n",
      "Epoch 515: ReduceLROnPlateau reducing learning rate to 0.00030735681357327847.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.7146 - root_mean_squared_error: 15.4827 - val_loss: 35.7462 - val_root_mean_squared_error: 5.9788 - lr: 3.2353e-04\n",
      "Epoch 516/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 105.9836 - root_mean_squared_error: 10.2948\n",
      "Epoch 516: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.3683 - root_mean_squared_error: 15.4715 - val_loss: 36.1702 - val_root_mean_squared_error: 6.0142 - lr: 3.0736e-04\n",
      "Epoch 517/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 208.0970 - root_mean_squared_error: 14.4256\n",
      "Epoch 517: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.4090 - root_mean_squared_error: 15.4728 - val_loss: 34.9357 - val_root_mean_squared_error: 5.9106 - lr: 3.0736e-04\n",
      "Epoch 518/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 312.4747 - root_mean_squared_error: 17.6770\n",
      "Epoch 518: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.3391 - root_mean_squared_error: 15.4706 - val_loss: 34.3652 - val_root_mean_squared_error: 5.8622 - lr: 3.0736e-04\n",
      "Epoch 519/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 101.4806 - root_mean_squared_error: 10.0738\n",
      "Epoch 519: val_loss did not improve from 34.10187\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.8380 - root_mean_squared_error: 15.4867 - val_loss: 37.3906 - val_root_mean_squared_error: 6.1148 - lr: 3.0736e-04\n",
      "Epoch 520/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 103.5459 - root_mean_squared_error: 10.1758\n",
      "Epoch 520: val_loss improved from 34.10187 to 34.09942, saving model to Model\\520-240.0280-34.0994.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 240.0280 - root_mean_squared_error: 15.4928 - val_loss: 34.0994 - val_root_mean_squared_error: 5.8395 - lr: 3.0736e-04\n",
      "Epoch 521/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 64.7034 - root_mean_squared_error: 8.0438\n",
      "Epoch 521: val_loss did not improve from 34.09942\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.2989 - root_mean_squared_error: 15.4693 - val_loss: 36.0209 - val_root_mean_squared_error: 6.0017 - lr: 3.0736e-04\n",
      "Epoch 522/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 280.7530 - root_mean_squared_error: 16.7557\n",
      "Epoch 522: val_loss did not improve from 34.09942\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.7760 - root_mean_squared_error: 15.4847 - val_loss: 36.3821 - val_root_mean_squared_error: 6.0318 - lr: 3.0736e-04\n",
      "Epoch 523/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 608.9235 - root_mean_squared_error: 24.6764\n",
      "Epoch 523: val_loss improved from 34.09942 to 33.46628, saving model to Model\\523-239.0798-33.4663.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.0798 - root_mean_squared_error: 15.4622 - val_loss: 33.4663 - val_root_mean_squared_error: 5.7850 - lr: 3.0736e-04\n",
      "Epoch 524/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 449.6711 - root_mean_squared_error: 21.2054\n",
      "Epoch 524: val_loss did not improve from 33.46628\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.0079 - root_mean_squared_error: 15.4599 - val_loss: 35.6145 - val_root_mean_squared_error: 5.9678 - lr: 3.0736e-04\n",
      "Epoch 525/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 69.1612 - root_mean_squared_error: 8.3163\n",
      "Epoch 525: val_loss did not improve from 33.46628\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.0932 - root_mean_squared_error: 15.4626 - val_loss: 35.1546 - val_root_mean_squared_error: 5.9291 - lr: 3.0736e-04\n",
      "Epoch 526/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 277.9355 - root_mean_squared_error: 16.6714\n",
      "Epoch 526: val_loss did not improve from 33.46628\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.9183 - root_mean_squared_error: 15.4570 - val_loss: 34.7288 - val_root_mean_squared_error: 5.8931 - lr: 3.0736e-04\n",
      "Epoch 527/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 67.4465 - root_mean_squared_error: 8.2126\n",
      "Epoch 527: val_loss did not improve from 33.46628\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.2188 - root_mean_squared_error: 15.4667 - val_loss: 36.8090 - val_root_mean_squared_error: 6.0670 - lr: 3.0736e-04\n",
      "Epoch 528/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 32.1955 - root_mean_squared_error: 5.6741\n",
      "Epoch 528: val_loss did not improve from 33.46628\n",
      "\n",
      "Epoch 528: ReduceLROnPlateau reducing learning rate to 0.00029198898118920624.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.1245 - root_mean_squared_error: 15.4637 - val_loss: 34.2996 - val_root_mean_squared_error: 5.8566 - lr: 3.0736e-04\n",
      "Epoch 529/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 271.3600 - root_mean_squared_error: 16.4730\n",
      "Epoch 529: val_loss did not improve from 33.46628\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.7726 - root_mean_squared_error: 15.4523 - val_loss: 34.4132 - val_root_mean_squared_error: 5.8663 - lr: 2.9199e-04\n",
      "Epoch 530/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 33.1866 - root_mean_squared_error: 5.7608\n",
      "Epoch 530: val_loss did not improve from 33.46628\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.4895 - root_mean_squared_error: 15.4431 - val_loss: 36.4032 - val_root_mean_squared_error: 6.0335 - lr: 2.9199e-04\n",
      "Epoch 531/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 399.3744 - root_mean_squared_error: 19.9844\n",
      "Epoch 531: val_loss did not improve from 33.46628\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.3008 - root_mean_squared_error: 15.4693 - val_loss: 35.8171 - val_root_mean_squared_error: 5.9847 - lr: 2.9199e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 288.8285 - root_mean_squared_error: 16.9950\n",
      "Epoch 532: val_loss did not improve from 33.46628\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.4229 - root_mean_squared_error: 15.4409 - val_loss: 34.8038 - val_root_mean_squared_error: 5.8995 - lr: 2.9199e-04\n",
      "Epoch 533/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 448.8656 - root_mean_squared_error: 21.1864\n",
      "Epoch 533: val_loss did not improve from 33.46628\n",
      "\n",
      "Epoch 533: ReduceLROnPlateau reducing learning rate to 0.00027738953212974593.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.3204 - root_mean_squared_error: 15.4700 - val_loss: 34.4990 - val_root_mean_squared_error: 5.8736 - lr: 2.9199e-04\n",
      "Epoch 534/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 261.0112 - root_mean_squared_error: 16.1558\n",
      "Epoch 534: val_loss improved from 33.46628 to 32.21062, saving model to Model\\534-241.3095-32.2106.hdf5\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 241.3095 - root_mean_squared_error: 15.5341 - val_loss: 32.2106 - val_root_mean_squared_error: 5.6754 - lr: 2.7739e-04\n",
      "Epoch 535/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 258.7776 - root_mean_squared_error: 16.0866\n",
      "Epoch 535: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.4208 - root_mean_squared_error: 15.4732 - val_loss: 37.2996 - val_root_mean_squared_error: 6.1073 - lr: 2.7739e-04\n",
      "Epoch 536/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 425.7486 - root_mean_squared_error: 20.6337\n",
      "Epoch 536: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.5842 - root_mean_squared_error: 15.4462 - val_loss: 34.8294 - val_root_mean_squared_error: 5.9016 - lr: 2.7739e-04\n",
      "Epoch 537/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 391.7797 - root_mean_squared_error: 19.7934\n",
      "Epoch 537: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 239.1445 - root_mean_squared_error: 15.4643 - val_loss: 35.5500 - val_root_mean_squared_error: 5.9624 - lr: 2.7739e-04\n",
      "Epoch 538/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 501.9384 - root_mean_squared_error: 22.4040\n",
      "Epoch 538: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.7136 - root_mean_squared_error: 15.4504 - val_loss: 33.1367 - val_root_mean_squared_error: 5.7565 - lr: 2.7739e-04\n",
      "Epoch 539/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 84.7249 - root_mean_squared_error: 9.2046\n",
      "Epoch 539: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 539: ReduceLROnPlateau reducing learning rate to 0.0002635200624354184.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.8126 - root_mean_squared_error: 15.4536 - val_loss: 35.2897 - val_root_mean_squared_error: 5.9405 - lr: 2.7739e-04\n",
      "Epoch 540/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 353.2260 - root_mean_squared_error: 18.7943\n",
      "Epoch 540: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.7672 - root_mean_squared_error: 15.4521 - val_loss: 35.4067 - val_root_mean_squared_error: 5.9504 - lr: 2.6352e-04\n",
      "Epoch 541/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 66.2880 - root_mean_squared_error: 8.1417\n",
      "Epoch 541: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.4177 - root_mean_squared_error: 15.4408 - val_loss: 34.6166 - val_root_mean_squared_error: 5.8836 - lr: 2.6352e-04\n",
      "Epoch 542/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 384.8445 - root_mean_squared_error: 19.6175\n",
      "Epoch 542: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.4771 - root_mean_squared_error: 15.4427 - val_loss: 33.2970 - val_root_mean_squared_error: 5.7704 - lr: 2.6352e-04\n",
      "Epoch 543/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 250.1814 - root_mean_squared_error: 15.8171\n",
      "Epoch 543: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.2257 - root_mean_squared_error: 15.4346 - val_loss: 35.3903 - val_root_mean_squared_error: 5.9490 - lr: 2.6352e-04\n",
      "Epoch 544/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 386.2551 - root_mean_squared_error: 19.6534\n",
      "Epoch 544: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 544: ReduceLROnPlateau reducing learning rate to 0.0002503440482541919.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.4185 - root_mean_squared_error: 15.4408 - val_loss: 34.8701 - val_root_mean_squared_error: 5.9051 - lr: 2.6352e-04\n",
      "Epoch 545/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 272.7732 - root_mean_squared_error: 16.5158\n",
      "Epoch 545: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.0281 - root_mean_squared_error: 15.4282 - val_loss: 34.7608 - val_root_mean_squared_error: 5.8958 - lr: 2.5034e-04\n",
      "Epoch 546/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 273.0959 - root_mean_squared_error: 16.5256\n",
      "Epoch 546: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.2154 - root_mean_squared_error: 15.4342 - val_loss: 34.6337 - val_root_mean_squared_error: 5.8850 - lr: 2.5034e-04\n",
      "Epoch 547/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 142.5616 - root_mean_squared_error: 11.9399\n",
      "Epoch 547: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.8510 - root_mean_squared_error: 15.4548 - val_loss: 32.5648 - val_root_mean_squared_error: 5.7066 - lr: 2.5034e-04\n",
      "Epoch 548/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 79.3559 - root_mean_squared_error: 8.9082\n",
      "Epoch 548: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.2914 - root_mean_squared_error: 15.4367 - val_loss: 36.0768 - val_root_mean_squared_error: 6.0064 - lr: 2.5034e-04\n",
      "Epoch 549/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 265.8600 - root_mean_squared_error: 16.3052\n",
      "Epoch 549: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 549: ReduceLROnPlateau reducing learning rate to 0.00023782684584148226.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.9479 - root_mean_squared_error: 15.4256 - val_loss: 34.6857 - val_root_mean_squared_error: 5.8895 - lr: 2.5034e-04\n",
      "Epoch 550/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 42.8669 - root_mean_squared_error: 6.5473\n",
      "Epoch 550: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.9899 - root_mean_squared_error: 15.4269 - val_loss: 33.2808 - val_root_mean_squared_error: 5.7690 - lr: 2.3783e-04\n",
      "Epoch 551/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 67.4966 - root_mean_squared_error: 8.2156\n",
      "Epoch 551: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.9574 - root_mean_squared_error: 15.4259 - val_loss: 34.9669 - val_root_mean_squared_error: 5.9133 - lr: 2.3783e-04\n",
      "Epoch 552/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 261.6586 - root_mean_squared_error: 16.1759\n",
      "Epoch 552: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.8175 - root_mean_squared_error: 15.4213 - val_loss: 34.8642 - val_root_mean_squared_error: 5.9046 - lr: 2.3783e-04\n",
      "Epoch 553/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 170.8943 - root_mean_squared_error: 13.0727\n",
      "Epoch 553: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.9815 - root_mean_squared_error: 15.4266 - val_loss: 33.9381 - val_root_mean_squared_error: 5.8256 - lr: 2.3783e-04\n",
      "Epoch 554/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 72.7934 - root_mean_squared_error: 8.5319\n",
      "Epoch 554: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 554: ReduceLROnPlateau reducing learning rate to 0.00022593549801968037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 237.8793 - root_mean_squared_error: 15.4233 - val_loss: 33.2746 - val_root_mean_squared_error: 5.7684 - lr: 2.3783e-04\n",
      "Epoch 555/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 208.6790 - root_mean_squared_error: 14.4457\n",
      "Epoch 555: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.4386 - root_mean_squared_error: 15.4415 - val_loss: 36.2739 - val_root_mean_squared_error: 6.0228 - lr: 2.2594e-04\n",
      "Epoch 556/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 247.9715 - root_mean_squared_error: 15.7471\n",
      "Epoch 556: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.5618 - root_mean_squared_error: 15.4454 - val_loss: 36.0375 - val_root_mean_squared_error: 6.0031 - lr: 2.2594e-04\n",
      "Epoch 557/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 433.8960 - root_mean_squared_error: 20.8302\n",
      "Epoch 557: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.5046 - root_mean_squared_error: 15.4112 - val_loss: 32.9795 - val_root_mean_squared_error: 5.7428 - lr: 2.2594e-04\n",
      "Epoch 558/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 348.3523 - root_mean_squared_error: 18.6642\n",
      "Epoch 558: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.0120 - root_mean_squared_error: 15.4276 - val_loss: 33.2896 - val_root_mean_squared_error: 5.7697 - lr: 2.2594e-04\n",
      "Epoch 559/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 150.1921 - root_mean_squared_error: 12.2553\n",
      "Epoch 559: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 559: ReduceLROnPlateau reducing learning rate to 0.00021463872035383245.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.4483 - root_mean_squared_error: 15.4094 - val_loss: 35.5202 - val_root_mean_squared_error: 5.9599 - lr: 2.2594e-04\n",
      "Epoch 560/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 55.8866 - root_mean_squared_error: 7.4757\n",
      "Epoch 560: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.6442 - root_mean_squared_error: 15.4157 - val_loss: 35.2483 - val_root_mean_squared_error: 5.9370 - lr: 2.1464e-04\n",
      "Epoch 561/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 234.9548 - root_mean_squared_error: 15.3282\n",
      "Epoch 561: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.4977 - root_mean_squared_error: 15.4110 - val_loss: 34.4300 - val_root_mean_squared_error: 5.8677 - lr: 2.1464e-04\n",
      "Epoch 562/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 159.7513 - root_mean_squared_error: 12.6393\n",
      "Epoch 562: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.9003 - root_mean_squared_error: 15.4240 - val_loss: 34.2393 - val_root_mean_squared_error: 5.8514 - lr: 2.1464e-04\n",
      "Epoch 563/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 309.5810 - root_mean_squared_error: 17.5949\n",
      "Epoch 563: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.5871 - root_mean_squared_error: 15.4139 - val_loss: 33.8126 - val_root_mean_squared_error: 5.8149 - lr: 2.1464e-04\n",
      "Epoch 564/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 80.8985 - root_mean_squared_error: 8.9944\n",
      "Epoch 564: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 564: ReduceLROnPlateau reducing learning rate to 0.0002039067905570846.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.3996 - root_mean_squared_error: 15.4078 - val_loss: 34.0185 - val_root_mean_squared_error: 5.8325 - lr: 2.1464e-04\n",
      "Epoch 565/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 195.0964 - root_mean_squared_error: 13.9677\n",
      "Epoch 565: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.3023 - root_mean_squared_error: 15.4046 - val_loss: 34.5435 - val_root_mean_squared_error: 5.8774 - lr: 2.0391e-04\n",
      "Epoch 566/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 41.1682 - root_mean_squared_error: 6.4162\n",
      "Epoch 566: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.7896 - root_mean_squared_error: 15.4204 - val_loss: 34.3447 - val_root_mean_squared_error: 5.8604 - lr: 2.0391e-04\n",
      "Epoch 567/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 228.7288 - root_mean_squared_error: 15.1238\n",
      "Epoch 567: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.2008 - root_mean_squared_error: 15.4338 - val_loss: 32.8194 - val_root_mean_squared_error: 5.7288 - lr: 2.0391e-04\n",
      "Epoch 568/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 55.5621 - root_mean_squared_error: 7.4540\n",
      "Epoch 568: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.7133 - root_mean_squared_error: 15.4180 - val_loss: 36.3877 - val_root_mean_squared_error: 6.0322 - lr: 2.0391e-04\n",
      "Epoch 569/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 261.6860 - root_mean_squared_error: 16.1767\n",
      "Epoch 569: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 569: ReduceLROnPlateau reducing learning rate to 0.00019371145172044634.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 238.5948 - root_mean_squared_error: 15.4465 - val_loss: 32.5698 - val_root_mean_squared_error: 5.7070 - lr: 2.0391e-04\n",
      "Epoch 570/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 234.2589 - root_mean_squared_error: 15.3055\n",
      "Epoch 570: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.2126 - root_mean_squared_error: 15.4017 - val_loss: 33.6653 - val_root_mean_squared_error: 5.8022 - lr: 1.9371e-04\n",
      "Epoch 571/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 244.5084 - root_mean_squared_error: 15.6368\n",
      "Epoch 571: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.2807 - root_mean_squared_error: 15.4039 - val_loss: 35.3680 - val_root_mean_squared_error: 5.9471 - lr: 1.9371e-04\n",
      "Epoch 572/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 29.2242 - root_mean_squared_error: 5.4059\n",
      "Epoch 572: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.3404 - root_mean_squared_error: 15.4059 - val_loss: 33.9564 - val_root_mean_squared_error: 5.8272 - lr: 1.9371e-04\n",
      "Epoch 573/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 452.3654 - root_mean_squared_error: 21.2689\n",
      "Epoch 573: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.2410 - root_mean_squared_error: 15.4026 - val_loss: 34.5263 - val_root_mean_squared_error: 5.8759 - lr: 1.9371e-04\n",
      "Epoch 574/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 291.8446 - root_mean_squared_error: 17.0835\n",
      "Epoch 574: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 574: ReduceLROnPlateau reducing learning rate to 0.00018402588466415182.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.2266 - root_mean_squared_error: 15.4022 - val_loss: 32.9861 - val_root_mean_squared_error: 5.7434 - lr: 1.9371e-04\n",
      "Epoch 575/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 46.8778 - root_mean_squared_error: 6.8467\n",
      "Epoch 575: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.3720 - root_mean_squared_error: 15.4069 - val_loss: 35.2223 - val_root_mean_squared_error: 5.9348 - lr: 1.8403e-04\n",
      "Epoch 576/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 300.6085 - root_mean_squared_error: 17.3381\n",
      "Epoch 576: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.4708 - root_mean_squared_error: 15.4101 - val_loss: 33.6456 - val_root_mean_squared_error: 5.8005 - lr: 1.8403e-04\n",
      "Epoch 577/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 252.4757 - root_mean_squared_error: 15.8895\n",
      "Epoch 577: val_loss did not improve from 32.21062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 237.1796 - root_mean_squared_error: 15.4006 - val_loss: 34.3461 - val_root_mean_squared_error: 5.8606 - lr: 1.8403e-04\n",
      "Epoch 578/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 75.3613 - root_mean_squared_error: 8.6811\n",
      "Epoch 578: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.0493 - root_mean_squared_error: 15.3964 - val_loss: 33.5442 - val_root_mean_squared_error: 5.7917 - lr: 1.8403e-04\n",
      "Epoch 579/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 408.9608 - root_mean_squared_error: 20.2228\n",
      "Epoch 579: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 579: ReduceLROnPlateau reducing learning rate to 0.00017482458351878447.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.0124 - root_mean_squared_error: 15.3952 - val_loss: 34.2461 - val_root_mean_squared_error: 5.8520 - lr: 1.8403e-04\n",
      "Epoch 580/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 259.1325 - root_mean_squared_error: 16.0976\n",
      "Epoch 580: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.0336 - root_mean_squared_error: 15.3959 - val_loss: 33.4891 - val_root_mean_squared_error: 5.7870 - lr: 1.7482e-04\n",
      "Epoch 581/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 36.2692 - root_mean_squared_error: 6.0224\n",
      "Epoch 581: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.1298 - root_mean_squared_error: 15.3990 - val_loss: 33.7344 - val_root_mean_squared_error: 5.8081 - lr: 1.7482e-04\n",
      "Epoch 582/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 24.6412 - root_mean_squared_error: 4.9640\n",
      "Epoch 582: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.9761 - root_mean_squared_error: 15.3940 - val_loss: 33.9624 - val_root_mean_squared_error: 5.8277 - lr: 1.7482e-04\n",
      "Epoch 583/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 458.1942 - root_mean_squared_error: 21.4055\n",
      "Epoch 583: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.9931 - root_mean_squared_error: 15.3946 - val_loss: 33.5287 - val_root_mean_squared_error: 5.7904 - lr: 1.7482e-04\n",
      "Epoch 584/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 241.2425 - root_mean_squared_error: 15.5320\n",
      "Epoch 584: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 584: ReduceLROnPlateau reducing learning rate to 0.0001660833557252772.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.8148 - root_mean_squared_error: 15.3888 - val_loss: 34.1459 - val_root_mean_squared_error: 5.8434 - lr: 1.7482e-04\n",
      "Epoch 585/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 197.1609 - root_mean_squared_error: 14.0414\n",
      "Epoch 585: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.7182 - root_mean_squared_error: 15.3856 - val_loss: 33.4620 - val_root_mean_squared_error: 5.7846 - lr: 1.6608e-04\n",
      "Epoch 586/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 435.0930 - root_mean_squared_error: 20.8589\n",
      "Epoch 586: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.8303 - root_mean_squared_error: 15.3893 - val_loss: 33.5686 - val_root_mean_squared_error: 5.7938 - lr: 1.6608e-04\n",
      "Epoch 587/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 512.5560 - root_mean_squared_error: 22.6397\n",
      "Epoch 587: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.0682 - root_mean_squared_error: 15.3970 - val_loss: 34.2629 - val_root_mean_squared_error: 5.8535 - lr: 1.6608e-04\n",
      "Epoch 588/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 45.6879 - root_mean_squared_error: 6.7593\n",
      "Epoch 588: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.8123 - root_mean_squared_error: 15.3887 - val_loss: 33.0208 - val_root_mean_squared_error: 5.7464 - lr: 1.6608e-04\n",
      "Epoch 589/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 40.8639 - root_mean_squared_error: 6.3925\n",
      "Epoch 589: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 589: ReduceLROnPlateau reducing learning rate to 0.0001577791837917175.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.3380 - root_mean_squared_error: 15.4058 - val_loss: 35.0544 - val_root_mean_squared_error: 5.9207 - lr: 1.6608e-04\n",
      "Epoch 590/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 38.8543 - root_mean_squared_error: 6.2333\n",
      "Epoch 590: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.5754 - root_mean_squared_error: 15.3810 - val_loss: 33.7572 - val_root_mean_squared_error: 5.8101 - lr: 1.5778e-04\n",
      "Epoch 591/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 308.4132 - root_mean_squared_error: 17.5617\n",
      "Epoch 591: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.5877 - root_mean_squared_error: 15.3814 - val_loss: 33.1470 - val_root_mean_squared_error: 5.7573 - lr: 1.5778e-04\n",
      "Epoch 592/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 15.6308 - root_mean_squared_error: 3.9536\n",
      "Epoch 592: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.0544 - root_mean_squared_error: 15.3966 - val_loss: 33.2919 - val_root_mean_squared_error: 5.7699 - lr: 1.5778e-04\n",
      "Epoch 593/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 324.3042 - root_mean_squared_error: 18.0084\n",
      "Epoch 593: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.0491 - root_mean_squared_error: 15.3964 - val_loss: 34.5381 - val_root_mean_squared_error: 5.8769 - lr: 1.5778e-04\n",
      "Epoch 594/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 30.6754 - root_mean_squared_error: 5.5385\n",
      "Epoch 594: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 594: ReduceLROnPlateau reducing learning rate to 0.0001498902252933476.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.5388 - root_mean_squared_error: 15.3798 - val_loss: 32.6665 - val_root_mean_squared_error: 5.7155 - lr: 1.5778e-04\n",
      "Epoch 595/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 300.6396 - root_mean_squared_error: 17.3390\n",
      "Epoch 595: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.7651 - root_mean_squared_error: 15.3872 - val_loss: 32.7773 - val_root_mean_squared_error: 5.7251 - lr: 1.4989e-04\n",
      "Epoch 596/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 45.6702 - root_mean_squared_error: 6.7580\n",
      "Epoch 596: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.5951 - root_mean_squared_error: 15.3816 - val_loss: 33.2042 - val_root_mean_squared_error: 5.7623 - lr: 1.4989e-04\n",
      "Epoch 597/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 278.5569 - root_mean_squared_error: 16.6900\n",
      "Epoch 597: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.3900 - root_mean_squared_error: 15.3750 - val_loss: 35.0632 - val_root_mean_squared_error: 5.9214 - lr: 1.4989e-04\n",
      "Epoch 598/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 179.5267 - root_mean_squared_error: 13.3988\n",
      "Epoch 598: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.6053 - root_mean_squared_error: 15.3820 - val_loss: 35.0153 - val_root_mean_squared_error: 5.9174 - lr: 1.4989e-04\n",
      "Epoch 599/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 231.3380 - root_mean_squared_error: 15.2098\n",
      "Epoch 599: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 599: ReduceLROnPlateau reducing learning rate to 0.00014239571610232815.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.8248 - root_mean_squared_error: 15.3891 - val_loss: 34.8832 - val_root_mean_squared_error: 5.9062 - lr: 1.4989e-04\n",
      "Epoch 600/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/16 [>.............................] - ETA: 0s - loss: 237.3324 - root_mean_squared_error: 15.4056\n",
      "Epoch 600: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.5690 - root_mean_squared_error: 15.3808 - val_loss: 33.8165 - val_root_mean_squared_error: 5.8152 - lr: 1.4240e-04\n",
      "Epoch 601/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 107.0112 - root_mean_squared_error: 10.3446\n",
      "Epoch 601: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 237.2348 - root_mean_squared_error: 15.4024 - val_loss: 32.5889 - val_root_mean_squared_error: 5.7087 - lr: 1.4240e-04\n",
      "Epoch 602/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 305.6485 - root_mean_squared_error: 17.4828\n",
      "Epoch 602: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.9767 - root_mean_squared_error: 15.3940 - val_loss: 35.1645 - val_root_mean_squared_error: 5.9300 - lr: 1.4240e-04\n",
      "Epoch 603/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 637.1674 - root_mean_squared_error: 25.2422\n",
      "Epoch 603: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.5507 - root_mean_squared_error: 15.3802 - val_loss: 34.7913 - val_root_mean_squared_error: 5.8984 - lr: 1.4240e-04\n",
      "Epoch 604/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 296.3288 - root_mean_squared_error: 17.2142\n",
      "Epoch 604: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 604: ReduceLROnPlateau reducing learning rate to 0.00013527592891477978.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.5713 - root_mean_squared_error: 15.3809 - val_loss: 33.3639 - val_root_mean_squared_error: 5.7761 - lr: 1.4240e-04\n",
      "Epoch 605/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 17.0810 - root_mean_squared_error: 4.1329\n",
      "Epoch 605: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.3966 - root_mean_squared_error: 15.3752 - val_loss: 33.2444 - val_root_mean_squared_error: 5.7658 - lr: 1.3528e-04\n",
      "Epoch 606/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 169.2655 - root_mean_squared_error: 13.0102\n",
      "Epoch 606: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.3475 - root_mean_squared_error: 15.3736 - val_loss: 33.1563 - val_root_mean_squared_error: 5.7582 - lr: 1.3528e-04\n",
      "Epoch 607/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 278.5965 - root_mean_squared_error: 16.6912\n",
      "Epoch 607: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.4163 - root_mean_squared_error: 15.3758 - val_loss: 35.2110 - val_root_mean_squared_error: 5.9339 - lr: 1.3528e-04\n",
      "Epoch 608/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 513.1069 - root_mean_squared_error: 22.6519\n",
      "Epoch 608: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.5530 - root_mean_squared_error: 15.3803 - val_loss: 33.5801 - val_root_mean_squared_error: 5.7948 - lr: 1.3528e-04\n",
      "Epoch 609/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 708.9677 - root_mean_squared_error: 26.6264\n",
      "Epoch 609: val_loss did not improve from 32.21062\n",
      "\n",
      "Epoch 609: ReduceLROnPlateau reducing learning rate to 0.00012851213177782482.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.9734 - root_mean_squared_error: 15.3939 - val_loss: 35.1435 - val_root_mean_squared_error: 5.9282 - lr: 1.3528e-04\n",
      "Epoch 610/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 244.5541 - root_mean_squared_error: 15.6382\n",
      "Epoch 610: val_loss did not improve from 32.21062\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.2176 - root_mean_squared_error: 15.3694 - val_loss: 34.0233 - val_root_mean_squared_error: 5.8330 - lr: 1.2851e-04\n",
      "Epoch 611/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 271.5534 - root_mean_squared_error: 16.4789\n",
      "Epoch 611: val_loss improved from 32.21062 to 32.15142, saving model to Model\\611-236.7872-32.1514.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.7872 - root_mean_squared_error: 15.3879 - val_loss: 32.1514 - val_root_mean_squared_error: 5.6702 - lr: 1.2851e-04\n",
      "Epoch 612/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 55.3854 - root_mean_squared_error: 7.4421\n",
      "Epoch 612: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.4483 - root_mean_squared_error: 15.3769 - val_loss: 32.4168 - val_root_mean_squared_error: 5.6936 - lr: 1.2851e-04\n",
      "Epoch 613/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 320.8102 - root_mean_squared_error: 17.9112\n",
      "Epoch 613: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.3830 - root_mean_squared_error: 15.3748 - val_loss: 34.1326 - val_root_mean_squared_error: 5.8423 - lr: 1.2851e-04\n",
      "Epoch 614/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 65.2398 - root_mean_squared_error: 8.0771\n",
      "Epoch 614: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.3054 - root_mean_squared_error: 15.3722 - val_loss: 33.7007 - val_root_mean_squared_error: 5.8052 - lr: 1.2851e-04\n",
      "Epoch 615/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 291.2385 - root_mean_squared_error: 17.0657\n",
      "Epoch 615: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.1103 - root_mean_squared_error: 15.3659 - val_loss: 34.2141 - val_root_mean_squared_error: 5.8493 - lr: 1.2851e-04\n",
      "Epoch 616/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 69.3914 - root_mean_squared_error: 8.3302\n",
      "Epoch 616: val_loss did not improve from 32.15142\n",
      "\n",
      "Epoch 616: ReduceLROnPlateau reducing learning rate to 0.00012208651896798982.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.1987 - root_mean_squared_error: 15.3688 - val_loss: 33.8724 - val_root_mean_squared_error: 5.8200 - lr: 1.2851e-04\n",
      "Epoch 617/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 282.5594 - root_mean_squared_error: 16.8095\n",
      "Epoch 617: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.0898 - root_mean_squared_error: 15.3652 - val_loss: 33.2313 - val_root_mean_squared_error: 5.7647 - lr: 1.2209e-04\n",
      "Epoch 618/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 270.5497 - root_mean_squared_error: 16.4484\n",
      "Epoch 618: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.2897 - root_mean_squared_error: 15.3717 - val_loss: 33.5095 - val_root_mean_squared_error: 5.7887 - lr: 1.2209e-04\n",
      "Epoch 619/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 491.3556 - root_mean_squared_error: 22.1665\n",
      "Epoch 619: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.0831 - root_mean_squared_error: 15.3650 - val_loss: 33.7759 - val_root_mean_squared_error: 5.8117 - lr: 1.2209e-04\n",
      "Epoch 620/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 230.4603 - root_mean_squared_error: 15.1809\n",
      "Epoch 620: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.1468 - root_mean_squared_error: 15.3671 - val_loss: 34.2977 - val_root_mean_squared_error: 5.8564 - lr: 1.2209e-04\n",
      "Epoch 621/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 480.7951 - root_mean_squared_error: 21.9270\n",
      "Epoch 621: val_loss did not improve from 32.15142\n",
      "\n",
      "Epoch 621: ReduceLROnPlateau reducing learning rate to 0.00011598219716688617.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9291 - root_mean_squared_error: 15.3600 - val_loss: 33.2560 - val_root_mean_squared_error: 5.7668 - lr: 1.2209e-04\n",
      "Epoch 622/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 261.7396 - root_mean_squared_error: 16.1784\n",
      "Epoch 622: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9847 - root_mean_squared_error: 15.3618 - val_loss: 33.5721 - val_root_mean_squared_error: 5.7941 - lr: 1.1598e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 623/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 68.9655 - root_mean_squared_error: 8.3045\n",
      "Epoch 623: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9771 - root_mean_squared_error: 15.3615 - val_loss: 33.3721 - val_root_mean_squared_error: 5.7769 - lr: 1.1598e-04\n",
      "Epoch 624/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 46.2235 - root_mean_squared_error: 6.7988\n",
      "Epoch 624: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.0983 - root_mean_squared_error: 15.3655 - val_loss: 34.3251 - val_root_mean_squared_error: 5.8588 - lr: 1.1598e-04\n",
      "Epoch 625/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 295.6747 - root_mean_squared_error: 17.1952\n",
      "Epoch 625: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9691 - root_mean_squared_error: 15.3613 - val_loss: 33.4780 - val_root_mean_squared_error: 5.7860 - lr: 1.1598e-04\n",
      "Epoch 626/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 297.9234 - root_mean_squared_error: 17.2605\n",
      "Epoch 626: val_loss did not improve from 32.15142\n",
      "\n",
      "Epoch 626: ReduceLROnPlateau reducing learning rate to 0.00011018308869097381.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.1131 - root_mean_squared_error: 15.3660 - val_loss: 32.6603 - val_root_mean_squared_error: 5.7149 - lr: 1.1598e-04\n",
      "Epoch 627/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 42.6964 - root_mean_squared_error: 6.5342\n",
      "Epoch 627: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.8827 - root_mean_squared_error: 15.3585 - val_loss: 33.7514 - val_root_mean_squared_error: 5.8096 - lr: 1.1018e-04\n",
      "Epoch 628/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 421.8735 - root_mean_squared_error: 20.5396\n",
      "Epoch 628: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9386 - root_mean_squared_error: 15.3603 - val_loss: 34.1133 - val_root_mean_squared_error: 5.8407 - lr: 1.1018e-04\n",
      "Epoch 629/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 489.8053 - root_mean_squared_error: 22.1315\n",
      "Epoch 629: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.8530 - root_mean_squared_error: 15.3575 - val_loss: 33.3061 - val_root_mean_squared_error: 5.7711 - lr: 1.1018e-04\n",
      "Epoch 630/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 284.4012 - root_mean_squared_error: 16.8642\n",
      "Epoch 630: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.8550 - root_mean_squared_error: 15.3576 - val_loss: 33.4348 - val_root_mean_squared_error: 5.7823 - lr: 1.1018e-04\n",
      "Epoch 631/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 510.4069 - root_mean_squared_error: 22.5922\n",
      "Epoch 631: val_loss did not improve from 32.15142\n",
      "\n",
      "Epoch 631: ReduceLROnPlateau reducing learning rate to 0.00010467393149156123.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9847 - root_mean_squared_error: 15.3618 - val_loss: 33.5744 - val_root_mean_squared_error: 5.7943 - lr: 1.1018e-04\n",
      "Epoch 632/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 158.5644 - root_mean_squared_error: 12.5922\n",
      "Epoch 632: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.8100 - root_mean_squared_error: 15.3561 - val_loss: 33.2440 - val_root_mean_squared_error: 5.7658 - lr: 1.0467e-04\n",
      "Epoch 633/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 288.7088 - root_mean_squared_error: 16.9914\n",
      "Epoch 633: val_loss did not improve from 32.15142\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.7926 - root_mean_squared_error: 15.3555 - val_loss: 33.2968 - val_root_mean_squared_error: 5.7703 - lr: 1.0467e-04\n",
      "Epoch 634/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 46.3198 - root_mean_squared_error: 6.8059\n",
      "Epoch 634: val_loss improved from 32.15142 to 31.98944, saving model to Model\\634-236.5556-31.9894.hdf5\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.5556 - root_mean_squared_error: 15.3804 - val_loss: 31.9894 - val_root_mean_squared_error: 5.6559 - lr: 1.0467e-04\n",
      "Epoch 635/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 30.8046 - root_mean_squared_error: 5.5502\n",
      "Epoch 635: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.7436 - root_mean_squared_error: 15.3539 - val_loss: 34.1368 - val_root_mean_squared_error: 5.8427 - lr: 1.0467e-04\n",
      "Epoch 636/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 390.8103 - root_mean_squared_error: 19.7689\n",
      "Epoch 636: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.8101 - root_mean_squared_error: 15.3561 - val_loss: 33.8414 - val_root_mean_squared_error: 5.8173 - lr: 1.0467e-04\n",
      "Epoch 637/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 151.5190 - root_mean_squared_error: 12.3093\n",
      "Epoch 637: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9141 - root_mean_squared_error: 15.3595 - val_loss: 33.6248 - val_root_mean_squared_error: 5.7987 - lr: 1.0467e-04\n",
      "Epoch 638/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 69.2809 - root_mean_squared_error: 8.3235\n",
      "Epoch 638: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.8256 - root_mean_squared_error: 15.3566 - val_loss: 33.9744 - val_root_mean_squared_error: 5.8288 - lr: 1.0467e-04\n",
      "Epoch 639/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 259.1700 - root_mean_squared_error: 16.0988\n",
      "Epoch 639: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 639: ReduceLROnPlateau reducing learning rate to 9.944023768184706e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.7270 - root_mean_squared_error: 15.3534 - val_loss: 33.8352 - val_root_mean_squared_error: 5.8168 - lr: 1.0467e-04\n",
      "Epoch 640/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 41.7910 - root_mean_squared_error: 6.4646\n",
      "Epoch 640: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.6728 - root_mean_squared_error: 15.3516 - val_loss: 33.2036 - val_root_mean_squared_error: 5.7623 - lr: 9.9440e-05\n",
      "Epoch 641/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 484.1930 - root_mean_squared_error: 22.0044\n",
      "Epoch 641: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.6907 - root_mean_squared_error: 15.3522 - val_loss: 33.6051 - val_root_mean_squared_error: 5.7970 - lr: 9.9440e-05\n",
      "Epoch 642/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 72.3971 - root_mean_squared_error: 8.5087\n",
      "Epoch 642: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.7603 - root_mean_squared_error: 15.3545 - val_loss: 33.6202 - val_root_mean_squared_error: 5.7983 - lr: 9.9440e-05\n",
      "Epoch 643/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 37.6289 - root_mean_squared_error: 6.1342\n",
      "Epoch 643: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.6836 - root_mean_squared_error: 15.3520 - val_loss: 32.8254 - val_root_mean_squared_error: 5.7293 - lr: 9.9440e-05\n",
      "Epoch 644/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 99.7886 - root_mean_squared_error: 9.9894\n",
      "Epoch 644: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 644: ReduceLROnPlateau reducing learning rate to 9.446822441532275e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9120 - root_mean_squared_error: 15.3594 - val_loss: 32.5292 - val_root_mean_squared_error: 5.7034 - lr: 9.9440e-05\n",
      "Epoch 645/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 62.8608 - root_mean_squared_error: 7.9285\n",
      "Epoch 645: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 236.0774 - root_mean_squared_error: 15.3648 - val_loss: 33.9673 - val_root_mean_squared_error: 5.8281 - lr: 9.4468e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 646/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 74.9233 - root_mean_squared_error: 8.6558\n",
      "Epoch 646: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9875 - root_mean_squared_error: 15.3619 - val_loss: 32.9295 - val_root_mean_squared_error: 5.7384 - lr: 9.4468e-05\n",
      "Epoch 647/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 26.1612 - root_mean_squared_error: 5.1148\n",
      "Epoch 647: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.8052 - root_mean_squared_error: 15.3560 - val_loss: 33.7736 - val_root_mean_squared_error: 5.8115 - lr: 9.4468e-05\n",
      "Epoch 648/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 315.3544 - root_mean_squared_error: 17.7582\n",
      "Epoch 648: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.7565 - root_mean_squared_error: 15.3544 - val_loss: 33.0506 - val_root_mean_squared_error: 5.7490 - lr: 9.4468e-05\n",
      "Epoch 649/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 747.2513 - root_mean_squared_error: 27.3359\n",
      "Epoch 649: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 649: ReduceLROnPlateau reducing learning rate to 8.974481388577259e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.6609 - root_mean_squared_error: 15.3513 - val_loss: 33.5231 - val_root_mean_squared_error: 5.7899 - lr: 9.4468e-05\n",
      "Epoch 650/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 38.1100 - root_mean_squared_error: 6.1733\n",
      "Epoch 650: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.6013 - root_mean_squared_error: 15.3493 - val_loss: 33.5905 - val_root_mean_squared_error: 5.7957 - lr: 8.9745e-05\n",
      "Epoch 651/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 45.1758 - root_mean_squared_error: 6.7213\n",
      "Epoch 651: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.5691 - root_mean_squared_error: 15.3483 - val_loss: 33.4214 - val_root_mean_squared_error: 5.7811 - lr: 8.9745e-05\n",
      "Epoch 652/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 230.7306 - root_mean_squared_error: 15.1898\n",
      "Epoch 652: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.6629 - root_mean_squared_error: 15.3513 - val_loss: 33.9709 - val_root_mean_squared_error: 5.8285 - lr: 8.9745e-05\n",
      "Epoch 653/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 99.9946 - root_mean_squared_error: 9.9997\n",
      "Epoch 653: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.9096 - root_mean_squared_error: 15.3593 - val_loss: 32.8719 - val_root_mean_squared_error: 5.7334 - lr: 8.9745e-05\n",
      "Epoch 654/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 351.5418 - root_mean_squared_error: 18.7494\n",
      "Epoch 654: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 654: ReduceLROnPlateau reducing learning rate to 8.525757111783605e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.5251 - root_mean_squared_error: 15.3468 - val_loss: 33.0114 - val_root_mean_squared_error: 5.7456 - lr: 8.9745e-05\n",
      "Epoch 655/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 468.0751 - root_mean_squared_error: 21.6350\n",
      "Epoch 655: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.8011 - root_mean_squared_error: 15.3558 - val_loss: 34.3349 - val_root_mean_squared_error: 5.8596 - lr: 8.5258e-05\n",
      "Epoch 656/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 337.2476 - root_mean_squared_error: 18.3643\n",
      "Epoch 656: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4494 - root_mean_squared_error: 15.3444 - val_loss: 33.3976 - val_root_mean_squared_error: 5.7791 - lr: 8.5258e-05\n",
      "Epoch 657/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 252.9731 - root_mean_squared_error: 15.9051\n",
      "Epoch 657: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.5142 - root_mean_squared_error: 15.3465 - val_loss: 32.9492 - val_root_mean_squared_error: 5.7401 - lr: 8.5258e-05\n",
      "Epoch 658/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 41.9859 - root_mean_squared_error: 6.4796\n",
      "Epoch 658: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.5487 - root_mean_squared_error: 15.3476 - val_loss: 32.7252 - val_root_mean_squared_error: 5.7206 - lr: 8.5258e-05\n",
      "Epoch 659/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 63.3009 - root_mean_squared_error: 7.9562\n",
      "Epoch 659: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 659: ReduceLROnPlateau reducing learning rate to 8.099469014268834e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4509 - root_mean_squared_error: 15.3444 - val_loss: 33.1591 - val_root_mean_squared_error: 5.7584 - lr: 8.5258e-05\n",
      "Epoch 660/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 27.4784 - root_mean_squared_error: 5.2420\n",
      "Epoch 660: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4739 - root_mean_squared_error: 15.3452 - val_loss: 33.6001 - val_root_mean_squared_error: 5.7966 - lr: 8.0995e-05\n",
      "Epoch 661/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 109.3092 - root_mean_squared_error: 10.4551\n",
      "Epoch 661: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4831 - root_mean_squared_error: 15.3455 - val_loss: 33.7949 - val_root_mean_squared_error: 5.8133 - lr: 8.0995e-05\n",
      "Epoch 662/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 285.5377 - root_mean_squared_error: 16.8979\n",
      "Epoch 662: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.3734 - root_mean_squared_error: 15.3419 - val_loss: 33.2484 - val_root_mean_squared_error: 5.7661 - lr: 8.0995e-05\n",
      "Epoch 663/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 448.2711 - root_mean_squared_error: 21.1724\n",
      "Epoch 663: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4339 - root_mean_squared_error: 15.3439 - val_loss: 33.2230 - val_root_mean_squared_error: 5.7639 - lr: 8.0995e-05\n",
      "Epoch 664/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 70.1142 - root_mean_squared_error: 8.3734\n",
      "Epoch 664: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 664: ReduceLROnPlateau reducing learning rate to 7.694495252508204e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4431 - root_mean_squared_error: 15.3442 - val_loss: 32.6314 - val_root_mean_squared_error: 5.7124 - lr: 8.0995e-05\n",
      "Epoch 665/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 140.1841 - root_mean_squared_error: 11.8399\n",
      "Epoch 665: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4199 - root_mean_squared_error: 15.3434 - val_loss: 33.4019 - val_root_mean_squared_error: 5.7794 - lr: 7.6945e-05\n",
      "Epoch 666/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 611.0533 - root_mean_squared_error: 24.7195\n",
      "Epoch 666: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.5534 - root_mean_squared_error: 15.3478 - val_loss: 33.6493 - val_root_mean_squared_error: 5.8008 - lr: 7.6945e-05\n",
      "Epoch 667/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 162.1350 - root_mean_squared_error: 12.7332\n",
      "Epoch 667: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4180 - root_mean_squared_error: 15.3433 - val_loss: 32.9840 - val_root_mean_squared_error: 5.7432 - lr: 7.6945e-05\n",
      "Epoch 668/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 213.6148 - root_mean_squared_error: 14.6156\n",
      "Epoch 668: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.3436 - root_mean_squared_error: 15.3409 - val_loss: 32.5738 - val_root_mean_squared_error: 5.7073 - lr: 7.6945e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 46.5587 - root_mean_squared_error: 6.8234\n",
      "Epoch 669: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 669: ReduceLROnPlateau reducing learning rate to 7.309770662686787e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4535 - root_mean_squared_error: 15.3445 - val_loss: 32.2671 - val_root_mean_squared_error: 5.6804 - lr: 7.6945e-05\n",
      "Epoch 670/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 241.9692 - root_mean_squared_error: 15.5554\n",
      "Epoch 670: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.2694 - root_mean_squared_error: 15.3385 - val_loss: 33.2552 - val_root_mean_squared_error: 5.7667 - lr: 7.3098e-05\n",
      "Epoch 671/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 268.3336 - root_mean_squared_error: 16.3809\n",
      "Epoch 671: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.2795 - root_mean_squared_error: 15.3388 - val_loss: 33.6735 - val_root_mean_squared_error: 5.8029 - lr: 7.3098e-05\n",
      "Epoch 672/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 319.4874 - root_mean_squared_error: 17.8742\n",
      "Epoch 672: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.3871 - root_mean_squared_error: 15.3423 - val_loss: 33.6620 - val_root_mean_squared_error: 5.8019 - lr: 7.3098e-05\n",
      "Epoch 673/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 39.4714 - root_mean_squared_error: 6.2826\n",
      "Epoch 673: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.3347 - root_mean_squared_error: 15.3406 - val_loss: 33.7544 - val_root_mean_squared_error: 5.8099 - lr: 7.3098e-05\n",
      "Epoch 674/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 409.6396 - root_mean_squared_error: 20.2396\n",
      "Epoch 674: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 674: ReduceLROnPlateau reducing learning rate to 6.944281922187656e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4573 - root_mean_squared_error: 15.3446 - val_loss: 33.6141 - val_root_mean_squared_error: 5.7978 - lr: 7.3098e-05\n",
      "Epoch 675/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 61.0247 - root_mean_squared_error: 7.8118\n",
      "Epoch 675: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.2425 - root_mean_squared_error: 15.3376 - val_loss: 32.9691 - val_root_mean_squared_error: 5.7419 - lr: 6.9443e-05\n",
      "Epoch 676/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 53.9133 - root_mean_squared_error: 7.3426\n",
      "Epoch 676: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.6382 - root_mean_squared_error: 15.3505 - val_loss: 32.2035 - val_root_mean_squared_error: 5.6748 - lr: 6.9443e-05\n",
      "Epoch 677/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 146.0708 - root_mean_squared_error: 12.0860\n",
      "Epoch 677: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1791 - root_mean_squared_error: 15.3355 - val_loss: 33.2419 - val_root_mean_squared_error: 5.7656 - lr: 6.9443e-05\n",
      "Epoch 678/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 262.6689 - root_mean_squared_error: 16.2071\n",
      "Epoch 678: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.2028 - root_mean_squared_error: 15.3363 - val_loss: 33.3553 - val_root_mean_squared_error: 5.7754 - lr: 6.9443e-05\n",
      "Epoch 679/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 450.4597 - root_mean_squared_error: 21.2240\n",
      "Epoch 679: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 679: ReduceLROnPlateau reducing learning rate to 6.597067549591884e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.3553 - root_mean_squared_error: 15.3413 - val_loss: 33.5220 - val_root_mean_squared_error: 5.7898 - lr: 6.9443e-05\n",
      "Epoch 680/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 39.0135 - root_mean_squared_error: 6.2461\n",
      "Epoch 680: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.2251 - root_mean_squared_error: 15.3371 - val_loss: 32.8126 - val_root_mean_squared_error: 5.7282 - lr: 6.5971e-05\n",
      "Epoch 681/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 211.8603 - root_mean_squared_error: 14.5554\n",
      "Epoch 681: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.2707 - root_mean_squared_error: 15.3385 - val_loss: 32.9052 - val_root_mean_squared_error: 5.7363 - lr: 6.5971e-05\n",
      "Epoch 682/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 240.1629 - root_mean_squared_error: 15.4972\n",
      "Epoch 682: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1827 - root_mean_squared_error: 15.3357 - val_loss: 32.8683 - val_root_mean_squared_error: 5.7331 - lr: 6.5971e-05\n",
      "Epoch 683/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 438.7222 - root_mean_squared_error: 20.9457\n",
      "Epoch 683: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.2954 - root_mean_squared_error: 15.3393 - val_loss: 32.2550 - val_root_mean_squared_error: 5.6793 - lr: 6.5971e-05\n",
      "Epoch 684/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 274.1889 - root_mean_squared_error: 16.5587\n",
      "Epoch 684: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 684: ReduceLROnPlateau reducing learning rate to 6.267214448598679e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.3066 - root_mean_squared_error: 15.3397 - val_loss: 32.8759 - val_root_mean_squared_error: 5.7338 - lr: 6.5971e-05\n",
      "Epoch 685/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 329.6236 - root_mean_squared_error: 18.1555\n",
      "Epoch 685: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.3169 - root_mean_squared_error: 15.3400 - val_loss: 32.5905 - val_root_mean_squared_error: 5.7088 - lr: 6.2672e-05\n",
      "Epoch 686/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 284.7312 - root_mean_squared_error: 16.8740\n",
      "Epoch 686: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1521 - root_mean_squared_error: 15.3347 - val_loss: 32.6377 - val_root_mean_squared_error: 5.7129 - lr: 6.2672e-05\n",
      "Epoch 687/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 63.4031 - root_mean_squared_error: 7.9626\n",
      "Epoch 687: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1443 - root_mean_squared_error: 15.3344 - val_loss: 32.7498 - val_root_mean_squared_error: 5.7227 - lr: 6.2672e-05\n",
      "Epoch 688/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 373.2782 - root_mean_squared_error: 19.3204\n",
      "Epoch 688: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1532 - root_mean_squared_error: 15.3347 - val_loss: 32.6929 - val_root_mean_squared_error: 5.7178 - lr: 6.2672e-05\n",
      "Epoch 689/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 185.4620 - root_mean_squared_error: 13.6184\n",
      "Epoch 689: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 689: ReduceLROnPlateau reducing learning rate to 5.953853760729544e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4639 - root_mean_squared_error: 15.3448 - val_loss: 33.4203 - val_root_mean_squared_error: 5.7810 - lr: 6.2672e-05\n",
      "Epoch 690/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 512.9489 - root_mean_squared_error: 22.6484\n",
      "Epoch 690: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0868 - root_mean_squared_error: 15.3325 - val_loss: 32.9074 - val_root_mean_squared_error: 5.7365 - lr: 5.9539e-05\n",
      "Epoch 691/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 55.2688 - root_mean_squared_error: 7.4343\n",
      "Epoch 691: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.3813 - root_mean_squared_error: 15.3421 - val_loss: 32.3015 - val_root_mean_squared_error: 5.6834 - lr: 5.9539e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 205.9105 - root_mean_squared_error: 14.3496\n",
      "Epoch 692: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0622 - root_mean_squared_error: 15.3317 - val_loss: 32.7729 - val_root_mean_squared_error: 5.7248 - lr: 5.9539e-05\n",
      "Epoch 693/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 289.1479 - root_mean_squared_error: 17.0044\n",
      "Epoch 693: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1197 - root_mean_squared_error: 15.3336 - val_loss: 33.3208 - val_root_mean_squared_error: 5.7724 - lr: 5.9539e-05\n",
      "Epoch 694/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 760.4653 - root_mean_squared_error: 27.5765\n",
      "Epoch 694: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 694: ReduceLROnPlateau reducing learning rate to 5.656161210936261e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1630 - root_mean_squared_error: 15.3350 - val_loss: 33.0239 - val_root_mean_squared_error: 5.7466 - lr: 5.9539e-05\n",
      "Epoch 695/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 164.3763 - root_mean_squared_error: 12.8209\n",
      "Epoch 695: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1539 - root_mean_squared_error: 15.3347 - val_loss: 32.9202 - val_root_mean_squared_error: 5.7376 - lr: 5.6562e-05\n",
      "Epoch 696/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 311.4067 - root_mean_squared_error: 17.6467\n",
      "Epoch 696: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0541 - root_mean_squared_error: 15.3315 - val_loss: 32.9637 - val_root_mean_squared_error: 5.7414 - lr: 5.6562e-05\n",
      "Epoch 697/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 170.1813 - root_mean_squared_error: 13.0454\n",
      "Epoch 697: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0884 - root_mean_squared_error: 15.3326 - val_loss: 32.6661 - val_root_mean_squared_error: 5.7154 - lr: 5.6562e-05\n",
      "Epoch 698/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 59.7424 - root_mean_squared_error: 7.7293\n",
      "Epoch 698: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0127 - root_mean_squared_error: 15.3301 - val_loss: 33.1244 - val_root_mean_squared_error: 5.7554 - lr: 5.6562e-05\n",
      "Epoch 699/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 258.7570 - root_mean_squared_error: 16.0859\n",
      "Epoch 699: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 699: ReduceLROnPlateau reducing learning rate to 5.373353305913042e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0635 - root_mean_squared_error: 15.3318 - val_loss: 33.3934 - val_root_mean_squared_error: 5.7787 - lr: 5.6562e-05\n",
      "Epoch 700/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 165.3219 - root_mean_squared_error: 12.8578\n",
      "Epoch 700: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.2184 - root_mean_squared_error: 15.3368 - val_loss: 32.8948 - val_root_mean_squared_error: 5.7354 - lr: 5.3734e-05\n",
      "Epoch 701/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 37.1279 - root_mean_squared_error: 6.0933\n",
      "Epoch 701: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0056 - root_mean_squared_error: 15.3299 - val_loss: 33.2299 - val_root_mean_squared_error: 5.7645 - lr: 5.3734e-05\n",
      "Epoch 702/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 214.8970 - root_mean_squared_error: 14.6594\n",
      "Epoch 702: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0220 - root_mean_squared_error: 15.3304 - val_loss: 33.1793 - val_root_mean_squared_error: 5.7601 - lr: 5.3734e-05\n",
      "Epoch 703/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 51.2612 - root_mean_squared_error: 7.1597\n",
      "Epoch 703: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0010 - root_mean_squared_error: 15.3297 - val_loss: 32.8348 - val_root_mean_squared_error: 5.7302 - lr: 5.3734e-05\n",
      "Epoch 704/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 40.4973 - root_mean_squared_error: 6.3638\n",
      "Epoch 704: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 704: ReduceLROnPlateau reducing learning rate to 5.104685606056591e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1799 - root_mean_squared_error: 15.3356 - val_loss: 32.3014 - val_root_mean_squared_error: 5.6834 - lr: 5.3734e-05\n",
      "Epoch 705/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 43.1546 - root_mean_squared_error: 6.5692\n",
      "Epoch 705: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9375 - root_mean_squared_error: 15.3277 - val_loss: 32.8048 - val_root_mean_squared_error: 5.7275 - lr: 5.1047e-05\n",
      "Epoch 706/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 391.5651 - root_mean_squared_error: 19.7880\n",
      "Epoch 706: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.4249 - root_mean_squared_error: 15.3436 - val_loss: 34.0494 - val_root_mean_squared_error: 5.8352 - lr: 5.1047e-05\n",
      "Epoch 707/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 174.6407 - root_mean_squared_error: 13.2152\n",
      "Epoch 707: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9609 - root_mean_squared_error: 15.3284 - val_loss: 33.4582 - val_root_mean_squared_error: 5.7843 - lr: 5.1047e-05\n",
      "Epoch 708/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 54.1147 - root_mean_squared_error: 7.3563\n",
      "Epoch 708: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.3062 - root_mean_squared_error: 15.3397 - val_loss: 32.8013 - val_root_mean_squared_error: 5.7272 - lr: 5.1047e-05\n",
      "Epoch 709/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 182.7885 - root_mean_squared_error: 13.5199\n",
      "Epoch 709: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 709: ReduceLROnPlateau reducing learning rate to 4.849451343034161e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9490 - root_mean_squared_error: 15.3280 - val_loss: 32.8849 - val_root_mean_squared_error: 5.7345 - lr: 5.1047e-05\n",
      "Epoch 710/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 444.7322 - root_mean_squared_error: 21.0887\n",
      "Epoch 710: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9835 - root_mean_squared_error: 15.3292 - val_loss: 33.0186 - val_root_mean_squared_error: 5.7462 - lr: 4.8495e-05\n",
      "Epoch 711/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 93.0010 - root_mean_squared_error: 9.6437\n",
      "Epoch 711: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9986 - root_mean_squared_error: 15.3297 - val_loss: 32.9783 - val_root_mean_squared_error: 5.7427 - lr: 4.8495e-05\n",
      "Epoch 712/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 142.5629 - root_mean_squared_error: 11.9400\n",
      "Epoch 712: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0588 - root_mean_squared_error: 15.3316 - val_loss: 33.6021 - val_root_mean_squared_error: 5.7967 - lr: 4.8495e-05\n",
      "Epoch 713/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 278.7796 - root_mean_squared_error: 16.6967\n",
      "Epoch 713: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9411 - root_mean_squared_error: 15.3278 - val_loss: 33.4951 - val_root_mean_squared_error: 5.7875 - lr: 4.8495e-05\n",
      "Epoch 714/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 25.1606 - root_mean_squared_error: 5.0160\n",
      "Epoch 714: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 714: ReduceLROnPlateau reducing learning rate to 4.606978654919658e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9578 - root_mean_squared_error: 15.3283 - val_loss: 32.8997 - val_root_mean_squared_error: 5.7358 - lr: 4.8495e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 31.9194 - root_mean_squared_error: 5.6497\n",
      "Epoch 715: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9228 - root_mean_squared_error: 15.3272 - val_loss: 32.8064 - val_root_mean_squared_error: 5.7277 - lr: 4.6070e-05\n",
      "Epoch 716/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 283.3430 - root_mean_squared_error: 16.8328\n",
      "Epoch 716: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.1970 - root_mean_squared_error: 15.3361 - val_loss: 33.4196 - val_root_mean_squared_error: 5.7810 - lr: 4.6070e-05\n",
      "Epoch 717/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 243.0799 - root_mean_squared_error: 15.5910\n",
      "Epoch 717: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9132 - root_mean_squared_error: 15.3269 - val_loss: 32.9902 - val_root_mean_squared_error: 5.7437 - lr: 4.6070e-05\n",
      "Epoch 718/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 385.0156 - root_mean_squared_error: 19.6218\n",
      "Epoch 718: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9312 - root_mean_squared_error: 15.3275 - val_loss: 32.5391 - val_root_mean_squared_error: 5.7043 - lr: 4.6070e-05\n",
      "Epoch 719/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 117.2444 - root_mean_squared_error: 10.8279\n",
      "Epoch 719: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 719: ReduceLROnPlateau reducing learning rate to 4.3766295493696814e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0519 - root_mean_squared_error: 15.3314 - val_loss: 32.2999 - val_root_mean_squared_error: 5.6833 - lr: 4.6070e-05\n",
      "Epoch 720/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 289.9161 - root_mean_squared_error: 17.0269\n",
      "Epoch 720: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9047 - root_mean_squared_error: 15.3266 - val_loss: 32.8242 - val_root_mean_squared_error: 5.7292 - lr: 4.3766e-05\n",
      "Epoch 721/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 91.5960 - root_mean_squared_error: 9.5706\n",
      "Epoch 721: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9713 - root_mean_squared_error: 15.3288 - val_loss: 32.4453 - val_root_mean_squared_error: 5.6961 - lr: 4.3766e-05\n",
      "Epoch 722/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 32.6874 - root_mean_squared_error: 5.7173\n",
      "Epoch 722: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9233 - root_mean_squared_error: 15.3272 - val_loss: 32.9388 - val_root_mean_squared_error: 5.7392 - lr: 4.3766e-05\n",
      "Epoch 723/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 189.2618 - root_mean_squared_error: 13.7572\n",
      "Epoch 723: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9857 - root_mean_squared_error: 15.3292 - val_loss: 33.3992 - val_root_mean_squared_error: 5.7792 - lr: 4.3766e-05\n",
      "Epoch 724/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 105.3890 - root_mean_squared_error: 10.2659\n",
      "Epoch 724: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 724: ReduceLROnPlateau reducing learning rate to 4.1577981755835934e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9100 - root_mean_squared_error: 15.3268 - val_loss: 33.0333 - val_root_mean_squared_error: 5.7475 - lr: 4.3766e-05\n",
      "Epoch 725/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 573.8760 - root_mean_squared_error: 23.9557\n",
      "Epoch 725: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.8877 - root_mean_squared_error: 15.3260 - val_loss: 32.8694 - val_root_mean_squared_error: 5.7332 - lr: 4.1578e-05\n",
      "Epoch 726/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 174.5087 - root_mean_squared_error: 13.2102\n",
      "Epoch 726: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.9838 - root_mean_squared_error: 15.3292 - val_loss: 33.2471 - val_root_mean_squared_error: 5.7660 - lr: 4.1578e-05\n",
      "Epoch 727/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 96.5129 - root_mean_squared_error: 9.8241\n",
      "Epoch 727: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.8710 - root_mean_squared_error: 15.3255 - val_loss: 32.6845 - val_root_mean_squared_error: 5.7170 - lr: 4.1578e-05\n",
      "Epoch 728/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 297.9814 - root_mean_squared_error: 17.2621\n",
      "Epoch 728: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.8723 - root_mean_squared_error: 15.3255 - val_loss: 33.0419 - val_root_mean_squared_error: 5.7482 - lr: 4.1578e-05\n",
      "Epoch 729/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 389.3424 - root_mean_squared_error: 19.7318\n",
      "Epoch 729: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 729: ReduceLROnPlateau reducing learning rate to 3.949908405047608e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.8631 - root_mean_squared_error: 15.3252 - val_loss: 33.1321 - val_root_mean_squared_error: 5.7561 - lr: 4.1578e-05\n",
      "Epoch 730/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 228.9106 - root_mean_squared_error: 15.1298\n",
      "Epoch 730: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7962 - root_mean_squared_error: 15.3231 - val_loss: 33.0381 - val_root_mean_squared_error: 5.7479 - lr: 3.9499e-05\n",
      "Epoch 731/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 51.3048 - root_mean_squared_error: 7.1627\n",
      "Epoch 731: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.8636 - root_mean_squared_error: 15.3253 - val_loss: 33.1276 - val_root_mean_squared_error: 5.7557 - lr: 3.9499e-05\n",
      "Epoch 732/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 244.4580 - root_mean_squared_error: 15.6352\n",
      "Epoch 732: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0701 - root_mean_squared_error: 15.3320 - val_loss: 32.3823 - val_root_mean_squared_error: 5.6905 - lr: 3.9499e-05\n",
      "Epoch 733/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 126.6015 - root_mean_squared_error: 11.2517\n",
      "Epoch 733: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7440 - root_mean_squared_error: 15.3214 - val_loss: 32.8680 - val_root_mean_squared_error: 5.7331 - lr: 3.9499e-05\n",
      "Epoch 734/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 46.8768 - root_mean_squared_error: 6.8467\n",
      "Epoch 734: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 734: ReduceLROnPlateau reducing learning rate to 3.752413140318822e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.8519 - root_mean_squared_error: 15.3249 - val_loss: 32.9636 - val_root_mean_squared_error: 5.7414 - lr: 3.9499e-05\n",
      "Epoch 735/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 272.8064 - root_mean_squared_error: 16.5169\n",
      "Epoch 735: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7636 - root_mean_squared_error: 15.3220 - val_loss: 33.0075 - val_root_mean_squared_error: 5.7452 - lr: 3.7524e-05\n",
      "Epoch 736/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 90.3658 - root_mean_squared_error: 9.5061\n",
      "Epoch 736: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.8009 - root_mean_squared_error: 15.3232 - val_loss: 33.0791 - val_root_mean_squared_error: 5.7514 - lr: 3.7524e-05\n",
      "Epoch 737/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 193.5822 - root_mean_squared_error: 13.9134\n",
      "Epoch 737: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.8650 - root_mean_squared_error: 15.3253 - val_loss: 33.1491 - val_root_mean_squared_error: 5.7575 - lr: 3.7524e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 738/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 283.4096 - root_mean_squared_error: 16.8348\n",
      "Epoch 738: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7754 - root_mean_squared_error: 15.3224 - val_loss: 33.0720 - val_root_mean_squared_error: 5.7508 - lr: 3.7524e-05\n",
      "Epoch 739/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 60.2710 - root_mean_squared_error: 7.7634\n",
      "Epoch 739: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 739: ReduceLROnPlateau reducing learning rate to 3.564792586985277e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7805 - root_mean_squared_error: 15.3225 - val_loss: 32.9509 - val_root_mean_squared_error: 5.7403 - lr: 3.7524e-05\n",
      "Epoch 740/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 149.8938 - root_mean_squared_error: 12.2431\n",
      "Epoch 740: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7771 - root_mean_squared_error: 15.3224 - val_loss: 32.6432 - val_root_mean_squared_error: 5.7134 - lr: 3.5648e-05\n",
      "Epoch 741/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 437.7207 - root_mean_squared_error: 20.9218\n",
      "Epoch 741: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 235.0285 - root_mean_squared_error: 15.3306 - val_loss: 33.3260 - val_root_mean_squared_error: 5.7729 - lr: 3.5648e-05\n",
      "Epoch 742/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 414.7348 - root_mean_squared_error: 20.3650\n",
      "Epoch 742: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7432 - root_mean_squared_error: 15.3213 - val_loss: 33.1551 - val_root_mean_squared_error: 5.7580 - lr: 3.5648e-05\n",
      "Epoch 743/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 502.4168 - root_mean_squared_error: 22.4147\n",
      "Epoch 743: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7358 - root_mean_squared_error: 15.3211 - val_loss: 32.9818 - val_root_mean_squared_error: 5.7430 - lr: 3.5648e-05\n",
      "Epoch 744/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 52.8032 - root_mean_squared_error: 7.2666\n",
      "Epoch 744: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 744: ReduceLROnPlateau reducing learning rate to 3.3865528712340166e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7602 - root_mean_squared_error: 15.3219 - val_loss: 32.7721 - val_root_mean_squared_error: 5.7247 - lr: 3.5648e-05\n",
      "Epoch 745/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 28.5551 - root_mean_squared_error: 5.3437\n",
      "Epoch 745: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7211 - root_mean_squared_error: 15.3206 - val_loss: 32.7533 - val_root_mean_squared_error: 5.7230 - lr: 3.3866e-05\n",
      "Epoch 746/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 125.2871 - root_mean_squared_error: 11.1932\n",
      "Epoch 746: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7365 - root_mean_squared_error: 15.3211 - val_loss: 32.5733 - val_root_mean_squared_error: 5.7073 - lr: 3.3866e-05\n",
      "Epoch 747/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 18.0691 - root_mean_squared_error: 4.2508\n",
      "Epoch 747: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7116 - root_mean_squared_error: 15.3203 - val_loss: 32.7347 - val_root_mean_squared_error: 5.7214 - lr: 3.3866e-05\n",
      "Epoch 748/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 291.9386 - root_mean_squared_error: 17.0862\n",
      "Epoch 748: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7480 - root_mean_squared_error: 15.3215 - val_loss: 33.0526 - val_root_mean_squared_error: 5.7491 - lr: 3.3866e-05\n",
      "Epoch 749/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 125.6034 - root_mean_squared_error: 11.2073\n",
      "Epoch 749: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 749: ReduceLROnPlateau reducing learning rate to 3.217225348635111e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7190 - root_mean_squared_error: 15.3205 - val_loss: 33.0309 - val_root_mean_squared_error: 5.7473 - lr: 3.3866e-05\n",
      "Epoch 750/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 273.5775 - root_mean_squared_error: 16.5402\n",
      "Epoch 750: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7436 - root_mean_squared_error: 15.3213 - val_loss: 32.8013 - val_root_mean_squared_error: 5.7272 - lr: 3.2172e-05\n",
      "Epoch 751/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 53.6745 - root_mean_squared_error: 7.3263\n",
      "Epoch 751: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7130 - root_mean_squared_error: 15.3203 - val_loss: 32.8733 - val_root_mean_squared_error: 5.7335 - lr: 3.2172e-05\n",
      "Epoch 752/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 483.6768 - root_mean_squared_error: 21.9927\n",
      "Epoch 752: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7352 - root_mean_squared_error: 15.3211 - val_loss: 33.0534 - val_root_mean_squared_error: 5.7492 - lr: 3.2172e-05\n",
      "Epoch 753/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 292.5535 - root_mean_squared_error: 17.1042\n",
      "Epoch 753: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7136 - root_mean_squared_error: 15.3204 - val_loss: 32.7724 - val_root_mean_squared_error: 5.7247 - lr: 3.2172e-05\n",
      "Epoch 754/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 57.8540 - root_mean_squared_error: 7.6062\n",
      "Epoch 754: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 754: ReduceLROnPlateau reducing learning rate to 3.0563641848857516e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6730 - root_mean_squared_error: 15.3190 - val_loss: 32.9611 - val_root_mean_squared_error: 5.7412 - lr: 3.2172e-05\n",
      "Epoch 755/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 55.0680 - root_mean_squared_error: 7.4208\n",
      "Epoch 755: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7069 - root_mean_squared_error: 15.3201 - val_loss: 32.9844 - val_root_mean_squared_error: 5.7432 - lr: 3.0564e-05\n",
      "Epoch 756/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 63.6897 - root_mean_squared_error: 7.9806\n",
      "Epoch 756: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7001 - root_mean_squared_error: 15.3199 - val_loss: 32.9373 - val_root_mean_squared_error: 5.7391 - lr: 3.0564e-05\n",
      "Epoch 757/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 652.8446 - root_mean_squared_error: 25.5508\n",
      "Epoch 757: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7342 - root_mean_squared_error: 15.3210 - val_loss: 32.9304 - val_root_mean_squared_error: 5.7385 - lr: 3.0564e-05\n",
      "Epoch 758/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 52.9719 - root_mean_squared_error: 7.2782\n",
      "Epoch 758: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6695 - root_mean_squared_error: 15.3189 - val_loss: 32.9840 - val_root_mean_squared_error: 5.7432 - lr: 3.0564e-05\n",
      "Epoch 759/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 442.7445 - root_mean_squared_error: 21.0415\n",
      "Epoch 759: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 759: ReduceLROnPlateau reducing learning rate to 2.9035460102022626e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6810 - root_mean_squared_error: 15.3193 - val_loss: 32.8211 - val_root_mean_squared_error: 5.7290 - lr: 3.0564e-05\n",
      "Epoch 760/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 144.1821 - root_mean_squared_error: 12.0076\n",
      "Epoch 760: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6817 - root_mean_squared_error: 15.3193 - val_loss: 32.7041 - val_root_mean_squared_error: 5.7187 - lr: 2.9035e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 285.7916 - root_mean_squared_error: 16.9054\n",
      "Epoch 761: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6490 - root_mean_squared_error: 15.3183 - val_loss: 32.9526 - val_root_mean_squared_error: 5.7404 - lr: 2.9035e-05\n",
      "Epoch 762/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 517.9129 - root_mean_squared_error: 22.7577\n",
      "Epoch 762: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6899 - root_mean_squared_error: 15.3196 - val_loss: 33.1532 - val_root_mean_squared_error: 5.7579 - lr: 2.9035e-05\n",
      "Epoch 763/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 21.2791 - root_mean_squared_error: 4.6129\n",
      "Epoch 763: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6475 - root_mean_squared_error: 15.3182 - val_loss: 32.9344 - val_root_mean_squared_error: 5.7389 - lr: 2.9035e-05\n",
      "Epoch 764/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 275.2992 - root_mean_squared_error: 16.5921\n",
      "Epoch 764: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 764: ReduceLROnPlateau reducing learning rate to 2.7583687096921494e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6650 - root_mean_squared_error: 15.3188 - val_loss: 33.0637 - val_root_mean_squared_error: 5.7501 - lr: 2.9035e-05\n",
      "Epoch 765/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 461.4778 - root_mean_squared_error: 21.4820\n",
      "Epoch 765: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6466 - root_mean_squared_error: 15.3182 - val_loss: 32.9193 - val_root_mean_squared_error: 5.7375 - lr: 2.7584e-05\n",
      "Epoch 766/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 385.4588 - root_mean_squared_error: 19.6331\n",
      "Epoch 766: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7189 - root_mean_squared_error: 15.3205 - val_loss: 33.2331 - val_root_mean_squared_error: 5.7648 - lr: 2.7584e-05\n",
      "Epoch 767/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 265.9462 - root_mean_squared_error: 16.3079\n",
      "Epoch 767: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6069 - root_mean_squared_error: 15.3169 - val_loss: 33.0043 - val_root_mean_squared_error: 5.7449 - lr: 2.7584e-05\n",
      "Epoch 768/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 308.2307 - root_mean_squared_error: 17.5565\n",
      "Epoch 768: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6431 - root_mean_squared_error: 15.3181 - val_loss: 32.9691 - val_root_mean_squared_error: 5.7419 - lr: 2.7584e-05\n",
      "Epoch 769/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 202.9625 - root_mean_squared_error: 14.2465\n",
      "Epoch 769: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 769: ReduceLROnPlateau reducing learning rate to 2.620450213726144e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6088 - root_mean_squared_error: 15.3169 - val_loss: 32.8104 - val_root_mean_squared_error: 5.7280 - lr: 2.7584e-05\n",
      "Epoch 770/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 149.9920 - root_mean_squared_error: 12.2471\n",
      "Epoch 770: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6393 - root_mean_squared_error: 15.3179 - val_loss: 32.7452 - val_root_mean_squared_error: 5.7223 - lr: 2.6205e-05\n",
      "Epoch 771/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 315.1966 - root_mean_squared_error: 17.7538\n",
      "Epoch 771: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6536 - root_mean_squared_error: 15.3184 - val_loss: 32.6162 - val_root_mean_squared_error: 5.7111 - lr: 2.6205e-05\n",
      "Epoch 772/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 71.9357 - root_mean_squared_error: 8.4815\n",
      "Epoch 772: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6352 - root_mean_squared_error: 15.3178 - val_loss: 32.8071 - val_root_mean_squared_error: 5.7277 - lr: 2.6205e-05\n",
      "Epoch 773/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 53.8236 - root_mean_squared_error: 7.3365\n",
      "Epoch 773: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6275 - root_mean_squared_error: 15.3176 - val_loss: 32.6325 - val_root_mean_squared_error: 5.7125 - lr: 2.6205e-05\n",
      "Epoch 774/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 64.5152 - root_mean_squared_error: 8.0321\n",
      "Epoch 774: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 774: ReduceLROnPlateau reducing learning rate to 2.4894276339182395e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5948 - root_mean_squared_error: 15.3165 - val_loss: 32.8260 - val_root_mean_squared_error: 5.7294 - lr: 2.6205e-05\n",
      "Epoch 775/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 400.4648 - root_mean_squared_error: 20.0116\n",
      "Epoch 775: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5915 - root_mean_squared_error: 15.3164 - val_loss: 32.8400 - val_root_mean_squared_error: 5.7306 - lr: 2.4894e-05\n",
      "Epoch 776/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 78.6994 - root_mean_squared_error: 8.8713\n",
      "Epoch 776: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5936 - root_mean_squared_error: 15.3165 - val_loss: 32.8383 - val_root_mean_squared_error: 5.7305 - lr: 2.4894e-05\n",
      "Epoch 777/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 33.2080 - root_mean_squared_error: 5.7626\n",
      "Epoch 777: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6578 - root_mean_squared_error: 15.3185 - val_loss: 32.9845 - val_root_mean_squared_error: 5.7432 - lr: 2.4894e-05\n",
      "Epoch 778/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 258.9295 - root_mean_squared_error: 16.0913\n",
      "Epoch 778: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5757 - root_mean_squared_error: 15.3159 - val_loss: 32.8600 - val_root_mean_squared_error: 5.7324 - lr: 2.4894e-05\n",
      "Epoch 779/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 479.7526 - root_mean_squared_error: 21.9033\n",
      "Epoch 779: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 779: ReduceLROnPlateau reducing learning rate to 2.3649562263017287e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6805 - root_mean_squared_error: 15.3193 - val_loss: 33.0743 - val_root_mean_squared_error: 5.7510 - lr: 2.4894e-05\n",
      "Epoch 780/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 52.1883 - root_mean_squared_error: 7.2241\n",
      "Epoch 780: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5936 - root_mean_squared_error: 15.3165 - val_loss: 32.7122 - val_root_mean_squared_error: 5.7195 - lr: 2.3650e-05\n",
      "Epoch 781/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 307.6155 - root_mean_squared_error: 17.5390\n",
      "Epoch 781: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5907 - root_mean_squared_error: 15.3164 - val_loss: 32.7527 - val_root_mean_squared_error: 5.7230 - lr: 2.3650e-05\n",
      "Epoch 782/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 269.8233 - root_mean_squared_error: 16.4263\n",
      "Epoch 782: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5730 - root_mean_squared_error: 15.3158 - val_loss: 32.5930 - val_root_mean_squared_error: 5.7090 - lr: 2.3650e-05\n",
      "Epoch 783/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 89.1026 - root_mean_squared_error: 9.4394\n",
      "Epoch 783: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6267 - root_mean_squared_error: 15.3175 - val_loss: 32.4892 - val_root_mean_squared_error: 5.6999 - lr: 2.3650e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 362.2687 - root_mean_squared_error: 19.0334\n",
      "Epoch 784: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 784: ReduceLROnPlateau reducing learning rate to 2.2467083545052444e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5952 - root_mean_squared_error: 15.3165 - val_loss: 32.7458 - val_root_mean_squared_error: 5.7224 - lr: 2.3650e-05\n",
      "Epoch 785/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 305.8759 - root_mean_squared_error: 17.4893\n",
      "Epoch 785: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.7673 - root_mean_squared_error: 15.3221 - val_loss: 33.0683 - val_root_mean_squared_error: 5.7505 - lr: 2.2467e-05\n",
      "Epoch 786/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 230.9772 - root_mean_squared_error: 15.1979\n",
      "Epoch 786: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5933 - root_mean_squared_error: 15.3164 - val_loss: 32.6385 - val_root_mean_squared_error: 5.7130 - lr: 2.2467e-05\n",
      "Epoch 787/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 36.3268 - root_mean_squared_error: 6.0272\n",
      "Epoch 787: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5683 - root_mean_squared_error: 15.3156 - val_loss: 32.7750 - val_root_mean_squared_error: 5.7249 - lr: 2.2467e-05\n",
      "Epoch 788/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 850.8091 - root_mean_squared_error: 29.1686\n",
      "Epoch 788: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.6266 - root_mean_squared_error: 15.3175 - val_loss: 32.8951 - val_root_mean_squared_error: 5.7354 - lr: 2.2467e-05\n",
      "Epoch 789/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 76.8110 - root_mean_squared_error: 8.7642\n",
      "Epoch 789: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 789: ReduceLROnPlateau reducing learning rate to 2.134372971340781e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5845 - root_mean_squared_error: 15.3162 - val_loss: 32.8270 - val_root_mean_squared_error: 5.7295 - lr: 2.2467e-05\n",
      "Epoch 790/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 78.6422 - root_mean_squared_error: 8.8680\n",
      "Epoch 790: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5434 - root_mean_squared_error: 15.3148 - val_loss: 33.1003 - val_root_mean_squared_error: 5.7533 - lr: 2.1344e-05\n",
      "Epoch 791/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 473.3109 - root_mean_squared_error: 21.7557\n",
      "Epoch 791: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5516 - root_mean_squared_error: 15.3151 - val_loss: 33.0722 - val_root_mean_squared_error: 5.7508 - lr: 2.1344e-05\n",
      "Epoch 792/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 235.4944 - root_mean_squared_error: 15.3458\n",
      "Epoch 792: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5427 - root_mean_squared_error: 15.3148 - val_loss: 32.9024 - val_root_mean_squared_error: 5.7361 - lr: 2.1344e-05\n",
      "Epoch 793/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 58.3101 - root_mean_squared_error: 7.6361\n",
      "Epoch 793: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5492 - root_mean_squared_error: 15.3150 - val_loss: 32.8722 - val_root_mean_squared_error: 5.7334 - lr: 2.1344e-05\n",
      "Epoch 794/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 244.7753 - root_mean_squared_error: 15.6453\n",
      "Epoch 794: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 794: ReduceLROnPlateau reducing learning rate to 2.0276544091757387e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5444 - root_mean_squared_error: 15.3148 - val_loss: 33.0460 - val_root_mean_squared_error: 5.7486 - lr: 2.1344e-05\n",
      "Epoch 795/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 506.0563 - root_mean_squared_error: 22.4957\n",
      "Epoch 795: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5262 - root_mean_squared_error: 15.3142 - val_loss: 33.0964 - val_root_mean_squared_error: 5.7529 - lr: 2.0277e-05\n",
      "Epoch 796/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 315.2137 - root_mean_squared_error: 17.7543\n",
      "Epoch 796: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5545 - root_mean_squared_error: 15.3152 - val_loss: 32.8878 - val_root_mean_squared_error: 5.7348 - lr: 2.0277e-05\n",
      "Epoch 797/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 188.1343 - root_mean_squared_error: 13.7162\n",
      "Epoch 797: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5771 - root_mean_squared_error: 15.3159 - val_loss: 32.7932 - val_root_mean_squared_error: 5.7265 - lr: 2.0277e-05\n",
      "Epoch 798/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 441.1855 - root_mean_squared_error: 21.0044\n",
      "Epoch 798: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5572 - root_mean_squared_error: 15.3153 - val_loss: 32.9332 - val_root_mean_squared_error: 5.7387 - lr: 2.0277e-05\n",
      "Epoch 799/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 336.1822 - root_mean_squared_error: 18.3353\n",
      "Epoch 799: val_loss did not improve from 31.98944\n",
      "\n",
      "Epoch 799: ReduceLROnPlateau reducing learning rate to 1.9262716887169517e-05.\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5303 - root_mean_squared_error: 15.3144 - val_loss: 32.7330 - val_root_mean_squared_error: 5.7213 - lr: 2.0277e-05\n",
      "Epoch 800/800\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 45.9164 - root_mean_squared_error: 6.7762\n",
      "Epoch 800: val_loss did not improve from 31.98944\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 234.5109 - root_mean_squared_error: 15.3138 - val_loss: 32.8264 - val_root_mean_squared_error: 5.7294 - lr: 1.9263e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f83d28ca60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=TrainX, y=TrainY, epochs=800, shuffle=True,\n",
    "          batch_size=48, callbacks=CALLBACK, validation_data = (ValidX, ValidY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28688770",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = model.predict(ValidX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40b9858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcg0lEQVR4nO3dfYxV953f8ffHk1kyedLAmkQwQHGRTWVCCqsRJqKqXCctrp3E2FUakEldNYrzhyPFXZcENqg2qWnYJX74Y7WRIInWu/bawQm9wU5WFNuJVokMaMgA4zGZhhQv5oLs2cQ08XqWjIdv/5hz8WW4D+c+zH2Y+3lJo7n3d885+c4J/n3v7+H8fooIzMys81zV7ADMzKw5nADMzDqUE4CZWYdyAjAz61BOAGZmHepdzQ4A4Oqrr47Fixc3Owwzs7Zy5MiRf4iIudWe3xIJYPHixQwMDDQ7DDOztiLp72s5311AZmYdygnAzKxDOQGYmXUoJwAzsw7lBGBm1qFaYhaQmVmnyQxm2bl/hLPnx5jf28OmtUtZt7KvoTE4AZiZNVhmMMuWvUOMjU8AkD0/xpa9QwANTQLuAjIza7Cd+0cuVf45Y+MT7Nw/0tA4nADMzBrs7PmxisqnixOAmVmDze/tqah8ujgBmJk12Ka1S+np7rqsrKe7i01rlzY0Dg8Cm5k1WG6g17OAzMw60LqVfQ2v8KdK3QUkqUvSoKRnk/cPSMpKOpr83JJ37BZJJyWNSFo7HYGbmVltKmkBfAk4AXwgr+yRiPhG/kGSrgfWA8uA+cBzkq6LiMvnPJmZWVOlagFIWgDcCnwrxeG3AU9FxIWIOAWcBFZVH6KZmU2HtF1AjwJfBi5OKf+ipOOSviNpdlLWB7yad8yZpMzMzFpI2QQg6RPA6xFxZMpH3wSWACuAc8BDuVMKXCYKXPduSQOSBkZHRysK2szMapemBbAG+JSkV4CngJskPR4Rr0XERERcBHbzTjfPGWBh3vkLgLNTLxoRuyKiPyL6586tektLMzOrUtkEEBFbImJBRCxmcnD3hYjYKGle3mG3Ay8lr/cB6yXNknQNcC1wuM5xm5lZjWp5DuDPJK1gsnvnFeALABExLGkP8DLwNnCPZwCZmbUeRVzRPd9w/f39MTAw0OwwzMzaiqQjEdFf7fleC8jMrEM5AZiZdSgnADOzDuUEYGbWoZwAzMw6lBOAmVmHcgIwM+tQTgBmZh3KCcDMrEM5AZiZdSgnADOzDuUEYGbWoZwAzMw6lBOAmVmHcgIwM+tQTgBmZh3KCcDMrEM5AZiZdSgnADOzDpU6AUjqkjQo6dnk/RxJByT9Mvk9O+/YLZJOShqRtHY6Ajczs9pU0gL4EnAi7/1m4PmIuBZ4PnmPpOuB9cAy4GbgLyR11SdcMzOrl1QJQNIC4FbgW3nFtwGPJa8fA9bllT8VERci4hRwElhVl2jNzKxu0rYAHgW+DFzMK/tQRJwDSH5/MCnvA17NO+5MUnYZSXdLGpA0MDo6WmncZmZWo7IJQNIngNcj4kjKa6pAWVxRELErIvojon/u3LkpL21mZvXyrhTHrAE+JekW4N3AByQ9DrwmaV5EnJM0D3g9Of4MsDDv/AXA2XoGbWZmtSvbAoiILRGxICIWMzm4+0JEbAT2AXclh90F/CB5vQ9YL2mWpGuAa4HDdY/czMxqkqYFUMwOYI+kzwGngU8DRMSwpD3Ay8DbwD0RMVFzpGZmVbhz94v87Fe/ufR+zZI5PPH5jzYxotahiCu65xuuv78/BgYGmh2GmTVRZjDLzv0jnD0/xvzeHjatXcq6lVfMH0lla2aIJw+9ykSR+m2mJAFJRyKiv9rza2kBmJnVRWYwy5a9Q4yNT3YWZM+PsWXvEEDFSWBrZojHD54ueUx+i6CTOQGYWdPt3D9yqfLPGRufYOf+kVQJoNw3fivMCcDMmu7s+bGKyvOl+cZvhXkxODNruvm9PRWV53vy0Ktlj5lqzZI5FZ8zEzkBmFnTbVq7lJ7uy5cM6+nuYtPapWXPrbTbZ6YMANeDu4DMrOly/fzVzALqkkomgS6JDTcs5MF1y+sW70zhBGBmLWHdyr6qpn1uuGFhwTGAjasXudIvwwnAzNparpLPzQLyN/70/CCYmVmbqvVBMA8Cm5l1KCcAM7MO5QRgZtahnADMzDqUE4CZWYdyAjAz61BOAGZmHcoPgpnZFfKXV/aDVTOXE4CZXWbq8soTEZfeOwnMLGW7gCS9W9JhScckDUvalpQ/ICkr6Wjyc0veOVsknZQ0ImntdP4BZlZfxZZXrmbZZWttaVoAF4CbIuJNSd3ATyX9bfLZIxHxjfyDJV0PrAeWAfOB5yRd543hzdpDsZU1vdvWzFO2BRCT3kzedic/pf4l3AY8FREXIuIUcBJYVXOkZtYQXVJF5da+Us0CktQl6SjwOnAgIg4lH31R0nFJ35E0OynrA/LbimeSMjNrAxtuWFiwfPU/n12w3NpXqgQQERMRsQJYAKyS9GHgm8ASYAVwDngoObzQ14QrWgyS7pY0IGlgdHS0itDNbDo8uG55wS0TD7/yBpnBbBMisulS0XMAEXEe+Alwc0S8liSGi8Bu3unmOQPkf4VYAJwtcK1dEdEfEf1z586tJnYzmyYvn/vdFWXjE8G2Z4abEI1NlzSzgOZK6k1e9wAfB34haV7eYbcDLyWv9wHrJc2SdA1wLXC4rlGb2bR6463xisqtPaWZBTQPeExSF5MJY09EPCvpryWtYLJ75xXgCwARMSxpD/Ay8DZwj2cAmZm1nrIJICKOAysLlH+2xDnbge21hWZmzdLb0835sSu/7ff2dDchGpsufhLYbAbKDGbZuX+E7PkxuiQmIujr7WHT2qWpNl5/4FPL2PT0McYvvjN/o/sq8cCnlk1n2NZgTgBmM0xmMMuWvUOMjU/2vOYe4MqeH2PL3iGAskkg9/nO/SOcPT/G/AqSh7UPbwpvNsOs2fEC2fNjRT/v7enmvbPe5Yp9Bqh1U3i3AMxmmLMlKn+A82Pjl/r3K2kV2Mzj/QDMZojMYJY1O14ouU5LIWPjE+zcPzItMVlrcwvArM3duftFfvar39R0jXKtBpuZnADM2lBmMMu2Z4br9mDW/N6eulzH2osTgFmbyQxm2fS9Y4xP1GcCR093F5vWLq3Ltay9OAGYtZGpu3XVqqf7Kr5+x3IPAHcoJwCzNlHvyn/j6kXe4rHDOQGYtYl6bcko4JHPrPC3fvM0ULN2UY8tGQXcuXqRK38D3AIwaxu5NX0qsWbJHF759Zif+rWCnADM2sSGGxamHgPo6e7y4K6V5S4gszbx4LrlbFy96IrN2ft6e9i4ehF9vT0oee/K39LwYnBmTZBbrtldM1aLWheDcwvArMFyyzVnz48RTC7Idu93j7Lya//bm65bQzkBmDXYzv0jl9bqz/fGW+Ns2TvkJGAN4wRg1mClFl7zypzWSGUTgKR3Szos6ZikYUnbkvI5kg5I+mXye3beOVsknZQ0ImntdP4BZu2m3MJrXpnTGiXNNNALwE0R8aakbuCnkv4WuAN4PiJ2SNoMbAa+Iul6YD2wDJgPPCfpuoi4ss1r1iHyB317ukt/7/LKnNYoZVsAMenN5G138hPAbcBjSfljwLrk9W3AUxFxISJOASeBVfUM2qydZAaz3Pf0sUuDvm+NXyx6rFfmtEZKNQYgqUvSUeB14EBEHAI+FBHnAJLfH0wO7wPyFy05k5RNvebdkgYkDYyOjtbwJ5i1rsxglv/63aNMXEw33drz962RUiWAiJiIiBXAAmCVpA+XOFwFyq741x8RuyKiPyL6586dmypYs3aSm+6Z9kmbvt4eV/7WUBUtBRER5yX9BLgZeE3SvIg4J2kek60DmPzGvzDvtAXA2XoEa9aKtmaGePLQq0xE0CWx4YaFPLhuedHpnoW468eaIc0soLmSepPXPcDHgV8A+4C7ksPuAn6QvN4HrJc0S9I1wLXA4TrHbdYS7tz9Io8fPH1pkbaJCB4/eJrFm39INsVsHi/dYM2UpgUwD3hMUheTCWNPRDwr6UVgj6TPAaeBTwNExLCkPcDLwNvAPZ4BZDNRZjBb02bs3pDFmq1sAoiI48DKAuW/Bj5W5JztwPaaozNrYQ/sG67qvNya/K78rdm8HLRZlc6PjVd0/Oz3dHP/J5e5q8dahpeCMGuQfyox/9+sGdwCMKtA7oneNAO8U+XW+XELwFqFE4BZCpnBLNueGeaNtyrr9pnK6/xYK3ECMEsU26QlM5hl09PHGE/5NG8pXufHWokTgBnvPLWbe3Art0nLvd89WtX11iyZw89P/7/LHgTzw17WajwIbEbxTVqqsWbJHJ74/Ef5+h3LvU+vtTS3AMyob9/8K7+evNa6lX2u8K2luQVgRn375j3Qa+3CCcAM2LR2KT3dXXW5lgd6rV04AZgx2V3z9TuWM/s93RWdd9WUxc890GvtxGMANqNMncq5+A97OPh/37hiqeZi551/a5zenu6yyzx8YFYXx7fdXHTqqFk7UETtc5tr1d/fHwMDA80Ow9rc1KmcxUxdhbPQeV1XqeAuXl7IzVqJpCMR0V/t+W4BWMup9lt12qmcTxw8zanRN0su5TxxMXjvH3TxT+MXy7YezNqVE4C1lEIPZG3ZOwRQNgmknX0TkGod/7d+P8GpHbemuqZZO/IgsLWUQt/ic4uolVPv2TeezWMznVsA1lKKfYsvVl7L6pyleDaPdQK3AKylFPvWXag8111UrPLvUoGyqfM2p/CyDdZJ0mwKv1DSjyWdkDQs6UtJ+QOSspKOJj+35J2zRdJJSSOS1k7nH2AzS6EHsgp9G88MZrlvz7GSg74TUybxCNiwaiFrlswpePyaJXM4teNWfrb5Jlf+1hHSdAG9DdwXET+X9H7giKQDyWePRMQ38g+WdD2wHlgGzAeek3SdN4a3NHIVb6lZQFszQzxx8DSVTmAO4Me/GOVnm2/izt0vXjYQnFvAzayTpNkU/hxwLnn9O0kngFJfj24DnoqIC8ApSSeBVcCLdYjXOkCxRdQyg1ke2Ddc8V68+XJjCa7szSocA5C0GFgJHEqKvijpuKTvSJqdlPUBr+addobSCcOsrMxglnu/e7Smyh88s8csX+oEIOl9wPeBeyPit8A3gSXACiZbCA/lDi1w+hWtdUl3SxqQNDA6Olpp3NbCMoNZ1ux4gWs2/5A1O14gM5it+ZqVbsyyZsmcVGMJZp0sVQKQ1M1k5f9EROwFiIjXImIiIi4Cu5ns5oHJb/wL805fAJydes2I2BUR/RHRP3fu3Fr+Bmsh+TNzgnce5KpHEkhDwKOfWeENWcxSKDsGIEnAt4ETEfFwXvm8ZHwA4HbgpeT1PuBvJD3M5CDwtcDhukZtLavUg1yNqHyDdwaSvSGLWWlpZgGtAT4LDEk6mpT9CbBB0gom/5t7BfgCQEQMS9oDvMzkDKJ7PAOoM2QGs0Xn5Ddqk5Q+9/GbpZZmFtBPKdyv/6MS52wHttcQl7WZXNdPMWkGX6dOzYTJCn3T2qV8YFYXv71Q+nuE+/jNKuMnga0uSq3EWa5izgxmue6rPyq4QFtuDOFr65bzgVmld+xyH79ZZZwArC5KdfGUqpgzg1nue/oYv5/62G6e3BjC8W03F+3i6evtceVvViEnAKuLYl08pSrmrZkh7v3u0YIbr0yVSzBpl4ows/KcAKwuKq2Y79z9Io8fPJ36+rkEk9u719M7zWrn5aCtLtKs4ZOTGcym2pAlZ2oi8fROs/pwArC6SVsxp9ncJafPG62bTRsnAJtW1W7YMnXjdjOrPycAmxaZwSzbnhnmjbcqX7zNlb9ZYzgBWN1lBrNs+t4xxktM7SzEa/KbNZZnAVndbXtmuOLKf+PqRa78zRrMCcDqKjOYrarb59lj58ofZGZ15QRgdVNuPaBSat3oxcwq5zEAq8nWzBBPHnqViah0h14zazYnAKtaodU7qzX7Pd11uY6ZpecuIKtKpU/zltLdJe7/5LK6XMvM0nMLwKry1f9VXV9/TpfExYiSS0aY2fRyArCCck/wFlvX5x9/X3pzFjG5gNu/+Rdz+f6R7GV7BfR0d3kBN7MW4ARgV8jN5slV2rlNWYBUlfZ7/6CL4a/dfOl9/z+bk2qRODNrLCcAu0Kajd3F5GbQhWy//fJlHLx6p1lrKjsILGmhpB9LOiFpWNKXkvI5kg5I+mXye3beOVsknZQ0ImntdP4BVh9bM0Ms2fIjFm/+YaqN3e9cvajgMWuWzHFlb9Ym0rQA3gbui4ifS3o/cETSAeA/A89HxA5Jm4HNwFckXQ+sB5YB84HnJF0XEaU7ja0pJrt7jjM2frHssfm7fuUWa8s9A9AlseGGhV7EzayNlE0AEXEOOJe8/p2kE0AfcBtwY3LYY8BPgK8k5U9FxAXglKSTwCrgxXoHb7XZmhniiYOni3bl5Cu0u9eD65a7wjdrYxU9ByBpMbASOAR8KEkOuSTxweSwPuDVvNPOJGVTr3W3pAFJA6Ojo1WEbrXIDGZ5PEXl720XzWau1IPAkt4HfB+4NyJ+K6nooQXKrqhnImIXsAugv7/f6wg02LZnhlMdd2rHrdMciZk1S6oWgKRuJiv/JyJib1L8mqR5yefzgNeT8jPAwrzTFwBn6xOu1cOdu19MtWLne7r9oLjZTJZmFpCAbwMnIuLhvI/2AXclr+8CfpBXvl7SLEnXANcCh+sXstUi7fo9Vwn+5x0faUBEZtYsabqA1gCfBYYkHU3K/gTYAeyR9DngNPBpgIgYlrQHeJnJGUT3eAZQc1WzYufD/3GF+/zNZrg0s4B+SuF+fYCPFTlnO7C9hrisDiqZ5ZNv4+pFrvzNOoCfBJ6BKpnbP9WaJXM8tdOsQzgBzDCZwSybnj7G+MXKJ1Y9+hl3+5h1EieANjd11c7f/OOFiit/AY+48jfrOE4AbeyG7Qd47Xe/v/S+2Bo+heQGdbw6p1nncgJoU//24Z9cVvlXousq8dCn/6UrfbMO5wTQRuqxAfusd13Fn/6Hj7jyNzMngHaxNTPE4wdP13SNNUvm8MTnP1qniMys3TkBtIHcwm1pbVy9iB//YtQ7cJlZSU4ALS4zmGXT946lPv5D7/8Dz+M3s1ScAFpQ/tROCdLO6rz2g+/lwB/fOK2xmdnM4QTQYjKDWe57+hgTSa2fZrz3FS/ZbGZVcAJoIdUM9PblbdNoZlYJL/jeIqqp/Att02hmlpZbAC2g0lk+ALPf0839n1zm2T1mVjUngCap5hu/8NINZlY/TgBNUE3lv3H1Ik/vNLO68hhAg1XT3ePK38ymg1sADTS5UctQ6uNd8ZvZdHICaKCd+0cYGy+/PXJPdxdfv2O5+/nNbFqV7QKS9B1Jr0t6Ka/sAUlZSUeTn1vyPtsi6aSkEUlrpyvwdnQ2xXr9s951lSt/M2uINC2AvwT+HPirKeWPRMQ38gskXQ+sB5YB84HnJF0XEeW/9naA+b09JTdt8VIOZtZIZVsAEfF3wG9SXu824KmIuBARp4CTwKoa4ptRNq1dSk931xXlvT3dPPqZFa78zayhahkD+KKk/wQMAPdFxBtAH3Aw75gzSdkVJN0N3A2waNGiGsJoH7lunfw9fD2n38yapdoE8E3gfwCR/H4I+C+8s9VsvoLLmUXELmAXQH9/f/VbXDXR1A3Z01Tm61b2ucI3s5ZQVQKIiNdyryXtBp5N3p4BFuYdugA4W3V0LWxrZognDp6+lN2y58cuTfF0BW9m7aCqB8Ekzct7ezuQmyG0D1gvaZaka4BrgcO1hdh6MoPZyyr/nLHxCXbuH2lKTGZmlSrbApD0JHAjcLWkM8D9wI2SVjDZvfMK8AWAiBiWtAd4GXgbuGcmzgDauX+kcL8W6aZ6mpm1grIJICI2FCj+donjtwPbawmq1ZWq5Od7fX4zaxNeC6gKxSp5gdfnN7O24QRQhULz+QXcuXqRB4DNrG14LaAqeD6/mc0ETgBV8nx+M2t37gIyM+tQTgBmZh3KCcDMrEN1zBhANev2mJnNZB2RAHJbMeZ24/K6PWZmHdIFVGgrRq/bY2adriMSQLGlG7xuj5l1shnbBZTf53+VxERcuXyb1+0xs0424xJAZjDLtmeGeeOt8UtlhSr/nu4ur9tjZh1tRiWAqYO9U3VJXIzwLCAzM2ZYAig02JvvYgSndtzawIjMzFpXWyeArZkhnjz0KhMRdBXp58/nPn8zs3e0bQLYmhni8YOnL70vV/m7z9/M7HJtOw30yUOvpj62t6ebr9+x3H3+ZmZ5yiYASd+R9Lqkl/LK5kg6IOmXye/ZeZ9tkXRS0oiktdMVeKlv/H29PSj5/ehnVnD0/n/nyt/MbIo0XUB/Cfw58Fd5ZZuB5yNih6TNyfuvSLoeWA8sA+YDz0m6bjo2hi/W598l8bPNN9X7f87MbMYp2wKIiL8DfjOl+DbgseT1Y8C6vPKnIuJCRJwCTgKr6hPq5TbcsLCicjMzu1y1YwAfiohzAMnvDyblfUB+5/yZpOwKku6WNCBpYHR0tOIAHly3nI2rF9ElAZPf/DeuXsSD65ZXfC0zs05U71lAKlBWsLM+InYBuwD6+/tLT+Ep4sF1y13hm5lVqdoWwGuS5gEkv19Pys8A+X0wC4Cz1YdnZmbTpdoEsA+4K3l9F/CDvPL1kmZJuga4FjhcW4hmZjYdynYBSXoSuBG4WtIZ4H5gB7BH0ueA08CnASJiWNIe4GXgbeCe6ZgBZGZmtSubACJiQ5GPPlbk+O3A9lqCMjOz6de2TwKbmVltFGXW0GlIENIo8PcFProa+IcGh1Mvjr05HHtzOPbmWBoR76/25JZYDC4i5hYqlzQQEf2NjqceHHtzOPbmcOzNIWmglvPdBWRm1qGcAMzMOlSrJ4BdzQ6gBo69ORx7czj25qgp9pYYBDYzs8Zr9RaAmZlNEycAM7MO1dQE0Kq7jaVRJPYHJGUlHU1+bsn7rCVil7RQ0o8lnZA0LOlLSXnL3/cSsbfDfX+3pMOSjiWxb0vK2+G+F4u95e97XjxdkgYlPZu8b/n7nhfP1Njrd98jomk/wL8G/gh4Ka/sz4DNyevNwJ8mr68HjgGzgGuAXwFdLRb7A8B/K3Bsy8QOzAP+KHn9fuD/JPG1/H0vEXs73HcB70tedwOHgNVtct+Lxd7y9z0vpj8G/gZ4Nnnf8ve9ROx1u+9NbQFEi+42lkaR2Itpmdgj4lxE/Dx5/TvgBJOb9rT8fS8RezGtFHtExJvJ2+7kJ2iP+14s9mJaJnYASQuAW4Fv5RW3/H2HorEXU3HsrTgGUPNuY032RUnHky6iXLOyJWOXtBhYyeQ3ura671Nihza470lT/iiT+2cciIi2ue9FYoc2uO/Ao8CXgYt5ZW1x3ykcO9TpvrdiAigm9W5jTfRNYAmwAjgHPJSUt1zskt4HfB+4NyJ+W+rQAmWtFntb3PeImIiIFUxulLRK0odLHN4Osbf8fZf0CeD1iDiS9pQCZa0We93ueysmgLbdbSwiXkv+Q7kI7Oad5ldLxS6pm8kK9ImI2JsUt8V9LxR7u9z3nIg4D/wEuJk2ue85+bG3yX1fA3xK0ivAU8BNkh6nPe57wdjred9bMQG07W5juX9QiduB3AyhloldkoBvAyci4uG8j1r+vheLvU3u+1xJvcnrHuDjwC9oj/teMPZ2uO8RsSUiFkTEYmA98EJEbKQN7nux2Ot635s8uv0kk02YcSaz1+eAPwSeB36Z/J6Td/xXmRzZHgH+fQvG/tfAEHA8+T9jXqvFDvwrJpuFx4Gjyc8t7XDfS8TeDvf9I8BgEuNLwH9PytvhvheLveXv+5S/40bemUnT8ve9ROx1u+9eCsLMrEO1YheQmZk1gBOAmVmHcgIwM+tQTgBmZh3KCcDMrEM5AZiZdSgnADOzDvX/AUMEsbxdAMWZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Pred, ValidY, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd626c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
