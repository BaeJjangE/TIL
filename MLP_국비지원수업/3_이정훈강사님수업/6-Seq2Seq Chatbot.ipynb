{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 출처: https://github.com/deepseasw/seq2seq_chatbot<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq에서의 임베딩이 이전 예제와 다른 점은 아래와 같이 태그를 사용한다는 것입니다.<br>\n",
    "임베딩의 0~3번째에 각각 PADDING, START, END, OOV 태그를 넣습니다.<br>\n",
    "사실 그냥 똑같은 단어라고 보시면 됩니다. 다만 이 단어들이 Seq2Seq의 동작을 제어합니다. <br>\n",
    "<br>\n",
    "예를 들어, 디코더 입력에 START가 들어가면 디코딩의 시작을 의미합니다. 반대로 디코더 출력에 END가 나오면 디코딩을 종료합니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그 단어\n",
    "PAD = \"<PADDING>\"   # 패딩\n",
    "STA = \"<START>\"     # 시작\n",
    "END = \"<END>\"       # 끝\n",
    "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
    "\n",
    "# 태그 인덱스\n",
    "PAD_INDEX = 0\n",
    "STA_INDEX = 1\n",
    "END_INDEX = 2\n",
    "OOV_INDEX = 3\n",
    "\n",
    "# 데이터 타입\n",
    "ENCODER_INPUT  = 0\n",
    "DECODER_INPUT  = 1\n",
    "DECODER_TARGET = 2\n",
    "\n",
    "# 한 문장에서 단어 시퀀스의 최대 개수\n",
    "max_sequences = 30\n",
    "\n",
    "# 임베딩 벡터 차원\n",
    "embedding_dim = 100\n",
    "\n",
    "# LSTM 히든레이어 차원\n",
    "lstm_hidden_dim = 128\n",
    "\n",
    "# 정규 표현식 필터\n",
    "RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")\n",
    "\n",
    "# 챗봇 데이터 로드\n",
    "chatbot_data = pd.read_csv('ChatbotData.csv', encoding='utf-8')\n",
    "question, answer = list(chatbot_data['Q']), list(chatbot_data['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "챗봇의 훈련을 위해서 송영숙님이 공개한 한글 데이터셋을 로드합니다.<br>\n",
    "질문과 대답, 감정 등 총 3개의 항목으로 구성되어 있습니다.<br>\n",
    "감정 분류는 Seq2Seq에 필요가 없기 때문에 사용하지 않습니다.<br>\n",
    "https://github.com/songys/Chatbot_data<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11824"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 개수\n",
    "len(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 12시 땡!\n",
      "A : 하루가 또 가네요.\n",
      "\n",
      "Q : 1지망 학교 떨어졌어\n",
      "A : 위로해 드립니다.\n",
      "\n",
      "Q : 3박4일 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : 3박4일 정도 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : PPL 심하네\n",
      "A : 눈살이 찌푸려지죠.\n",
      "\n",
      "Q : SD카드 망가졌어\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SD카드 안돼\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SNS 맞팔 왜 안하지ㅠㅠ\n",
      "A : 잘 모르고 있을 수도 있어요.\n",
      "\n",
      "Q : SNS 시간낭비인 거 아는데 매일 하는 중\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n",
      "Q : SNS 시간낭비인데 자꾸 보게됨\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 일부만 학습에 사용\n",
    "question = question[:100]\n",
    "answer = answer[:100]\n",
    "\n",
    "# 챗봇 데이터 출력\n",
    "for i in range(10):\n",
    "    print('Q : ' + question[i])\n",
    "    print('A : ' + answer[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 단어 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소분석 함수\n",
    "def pos_tag(sentences):\n",
    "    \n",
    "    # KoNLPy 형태소분석기 설정\n",
    "    tagger = Okt()\n",
    "    \n",
    "    # 문장 품사 변수 초기화\n",
    "    sentences_pos = []\n",
    "    \n",
    "    # 모든 문장 반복\n",
    "    for sentence in sentences:\n",
    "        # 특수기호 제거\n",
    "        # RE_FILTER에 해당되는 정규표현식 char에 대하여 \"\" ()로 바꾸어라\n",
    "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
    "        \n",
    "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
    "        sentence = \" \".join(tagger.morphs(sentence))\n",
    "        sentences_pos.append(sentence)\n",
    "        \n",
    "    return sentences_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 12시 땡\n",
      "A : 하루 가 또 가네요\n",
      "\n",
      "Q : 1 지망 학교 떨어졌어\n",
      "A : 위로 해 드립니다\n",
      "\n",
      "Q : 3 박 4일 놀러 가고 싶다\n",
      "A : 여행 은 언제나 좋죠\n",
      "\n",
      "Q : 3 박 4일 정도 놀러 가고 싶다\n",
      "A : 여행 은 언제나 좋죠\n",
      "\n",
      "Q : PPL 심하네\n",
      "A : 눈살 이 찌푸려지죠\n",
      "\n",
      "Q : SD 카드 망가졌어\n",
      "A : 다시 새로 사는 게 마음 편해요\n",
      "\n",
      "Q : SD 카드 안 돼\n",
      "A : 다시 새로 사는 게 마음 편해요\n",
      "\n",
      "Q : SNS 맞팔 왜 안 하지 ㅠㅠ\n",
      "A : 잘 모르고 있을 수도 있어요\n",
      "\n",
      "Q : SNS 시간 낭비 인 거 아는데 매일 하는 중\n",
      "A : 시간 을 정 하고 해보세요\n",
      "\n",
      "Q : SNS 시간 낭비 인데 자꾸 보게 됨\n",
      "A : 시간 을 정 하고 해보세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 형태소분석 수행\n",
    "question = pos_tag(question)\n",
    "answer = pos_tag(answer)\n",
    "\n",
    "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
    "for i in range(10):\n",
    "    print('Q : ' + question[i])\n",
    "    print('A : ' + answer[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 대답 문장들을 하나로 합침\n",
    "sentences = []\n",
    "sentences.extend(question)\n",
    "sentences.extend(answer)\n",
    "\n",
    "words = []\n",
    "\n",
    "# 단어들의 배열 생성\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        words.append(word)\n",
    "\n",
    "# 길이가 0인 단어는 삭제\n",
    "words = [word for word in words if len(word) > 0]\n",
    "\n",
    "# 중복된 단어 삭제\n",
    "words = list(set(words))\n",
    "\n",
    "# 제일 앞에 태그 단어 삽입\n",
    "words[:0] = [PAD, STA, END, OOV]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문과 대답 문장들을 합쳐서 전체 단어 사전을 만듭니다.<br>\n",
    "자연어처리에서는 항상 이렇게 단어를 인덱스에 따라 정리를 해야 합니다.<br>\n",
    "<br>\n",
    "그래야지 문장을 인덱스 배열로 바꿔서 임베딩 레이어에 넣을 수 있습니다.<br>\n",
    "또한 모델의 출력에서 나온 인덱스를 다시 단어로 변환하는데도 필요합니다.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 개수\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PADDING>',\n",
       " '<START>',\n",
       " '<END>',\n",
       " '<OOV>',\n",
       " '있어도',\n",
       " '정',\n",
       " '은',\n",
       " '가지',\n",
       " '식혀주세요',\n",
       " '다음',\n",
       " '단',\n",
       " '낮잠',\n",
       " '놓고',\n",
       " '알',\n",
       " '하루',\n",
       " '하',\n",
       " '위로',\n",
       " '정말',\n",
       " '함께',\n",
       " 'PPL',\n",
       " '갈',\n",
       " '이에요',\n",
       " '이다',\n",
       " '없죠',\n",
       " '부터',\n",
       " '관리',\n",
       " '처럼',\n",
       " '시켜야지',\n",
       " '약',\n",
       " '먹었는데',\n",
       " '싫어요',\n",
       " '일',\n",
       " '있어',\n",
       " '간장',\n",
       " '요',\n",
       " '가난한',\n",
       " '4일',\n",
       " '사랑',\n",
       " '했잖아',\n",
       " '개인',\n",
       " '곧',\n",
       " '입어볼까',\n",
       " '간다',\n",
       " '때',\n",
       " '새로',\n",
       " '습관',\n",
       " '여행',\n",
       " '집',\n",
       " '끄고',\n",
       " '물어보세요',\n",
       " '인거',\n",
       " '싫어하지',\n",
       " '사이',\n",
       " '엉망',\n",
       " '그런거니',\n",
       " '걔',\n",
       " '수도',\n",
       " '비싼데',\n",
       " '싫어',\n",
       " '옴',\n",
       " '나왔다',\n",
       " '가야',\n",
       " '맞팔',\n",
       " '막',\n",
       " '비',\n",
       " '되나',\n",
       " '당신',\n",
       " '켜놓고',\n",
       " '끼리',\n",
       " '확실한',\n",
       " '눈살',\n",
       " '살까',\n",
       " '간식',\n",
       " '그게',\n",
       " '했길',\n",
       " '잊고',\n",
       " '나쁜',\n",
       " '하는',\n",
       " '집어서',\n",
       " '예쁘게',\n",
       " '3',\n",
       " '결정',\n",
       " '지망',\n",
       " '뭐',\n",
       " '갑자기',\n",
       " '사는게',\n",
       " '연인',\n",
       " '해볼까',\n",
       " '가장',\n",
       " '자꾸',\n",
       " '누구',\n",
       " '어디',\n",
       " '의',\n",
       " '같은',\n",
       " '이야',\n",
       " '이나',\n",
       " '서먹해졌어',\n",
       " '하지',\n",
       " '개학',\n",
       " '떨리는',\n",
       " '말랭이',\n",
       " '까',\n",
       " '야',\n",
       " '좋아',\n",
       " '세수',\n",
       " '개념',\n",
       " '사는',\n",
       " '중',\n",
       " '하면',\n",
       " '살쪄도',\n",
       " '먹고',\n",
       " '마음',\n",
       " '키우고',\n",
       " '있을',\n",
       " '첫인상',\n",
       " '먹어야지',\n",
       " '닮아서',\n",
       " '따뜻하게',\n",
       " '간접흡연',\n",
       " '설움',\n",
       " '추천',\n",
       " '패턴',\n",
       " '혼자',\n",
       " '즐거운',\n",
       " '찌푸려지죠',\n",
       " '이야기',\n",
       " '취미',\n",
       " '땡',\n",
       " '가네요',\n",
       " '이럴',\n",
       " '이랑',\n",
       " '돈',\n",
       " '낭비',\n",
       " 'ㅠㅠ',\n",
       " '키울까',\n",
       " '살찐',\n",
       " '싫다',\n",
       " '건데',\n",
       " '서로',\n",
       " '감미로운',\n",
       " '알려',\n",
       " '매일',\n",
       " '서먹해',\n",
       " '하느라',\n",
       " '가끔',\n",
       " '정도',\n",
       " '거',\n",
       " '불편한',\n",
       " '짧죠',\n",
       " '괜찮아요',\n",
       " '맛있게',\n",
       " '또',\n",
       " '에요',\n",
       " '무모한',\n",
       " '들어올',\n",
       " '가보세요',\n",
       " '부족했나',\n",
       " '업무',\n",
       " '궁금해',\n",
       " '목소리',\n",
       " '지',\n",
       " '피',\n",
       " '만들어',\n",
       " '붙잡고',\n",
       " '켜고',\n",
       " '떨리니까',\n",
       " '기름',\n",
       " '예요',\n",
       " '시켜',\n",
       " '아님',\n",
       " '진리',\n",
       " '을',\n",
       " '보세요',\n",
       " '입어',\n",
       " '좋겠다',\n",
       " '수',\n",
       " '해봐요',\n",
       " '해주세요',\n",
       " '더',\n",
       " '개시',\n",
       " '룩',\n",
       " '키워',\n",
       " '두',\n",
       " '되도록',\n",
       " '쇼핑',\n",
       " '는',\n",
       " '않을',\n",
       " '고민',\n",
       " '옷',\n",
       " '상황',\n",
       " '만나지',\n",
       " '떨어졌어',\n",
       " '봐요',\n",
       " '자의',\n",
       " '해',\n",
       " '감기',\n",
       " '빼고',\n",
       " '그',\n",
       " '힘든데',\n",
       " '도',\n",
       " '부터는',\n",
       " '내일',\n",
       " '생각',\n",
       " '자도',\n",
       " '박',\n",
       " '남겨야',\n",
       " '니까',\n",
       " '어제',\n",
       " '끌',\n",
       " '반',\n",
       " '인데',\n",
       " '가기',\n",
       " '진창',\n",
       " '되',\n",
       " '리지',\n",
       " '할까',\n",
       " '됐으면',\n",
       " '못',\n",
       " '하자고',\n",
       " '후회',\n",
       " '오세요',\n",
       " '줘',\n",
       " '데',\n",
       " '해보여',\n",
       " '하겠어',\n",
       " '나를',\n",
       " '병원',\n",
       " '너무',\n",
       " '좋은',\n",
       " '스트레스',\n",
       " '가자고',\n",
       " '마세요',\n",
       " '싶네요',\n",
       " '들',\n",
       " '싶어',\n",
       " '애가',\n",
       " '짠으로',\n",
       " '자랑',\n",
       " '에는',\n",
       " '주는',\n",
       " '이라니',\n",
       " '카드',\n",
       " '것',\n",
       " '수영장',\n",
       " '기운',\n",
       " '화폐',\n",
       " '준',\n",
       " '드립니다',\n",
       " '봅니다',\n",
       " '된',\n",
       " '가려고',\n",
       " '모르고',\n",
       " '행복',\n",
       " '안',\n",
       " '왜',\n",
       " '말',\n",
       " '같이',\n",
       " '들더라',\n",
       " '좋더라',\n",
       " '책임질',\n",
       " '매력',\n",
       " '먼저',\n",
       " '달',\n",
       " '누굴',\n",
       " '말까',\n",
       " '나갔어',\n",
       " '망함',\n",
       " '싶다',\n",
       " '좋다',\n",
       " '땀',\n",
       " '언제나',\n",
       " '강아지',\n",
       " '자신',\n",
       " 'SNS',\n",
       " '쓰레기통',\n",
       " '바라요',\n",
       " '심하네',\n",
       " '자리',\n",
       " '잘',\n",
       " '했어',\n",
       " '운',\n",
       " '돼겠지',\n",
       " '좋겠네요',\n",
       " '어서',\n",
       " '저',\n",
       " '친구',\n",
       " '새',\n",
       " '사람',\n",
       " '편해요',\n",
       " '감히',\n",
       " '같아',\n",
       " '와',\n",
       " '있으면',\n",
       " '질질',\n",
       " '가상',\n",
       " '온',\n",
       " '최고',\n",
       " '게임',\n",
       " '아는데',\n",
       " '게',\n",
       " '애',\n",
       " '나',\n",
       " '어필',\n",
       " '됨',\n",
       " '건',\n",
       " '개강',\n",
       " '물어',\n",
       " '왔나',\n",
       " '물어봐서',\n",
       " '졸려',\n",
       " '오늘이',\n",
       " '필요하죠',\n",
       " '방학',\n",
       " '보면',\n",
       " '할',\n",
       " '죠',\n",
       " '학교',\n",
       " '싶은데',\n",
       " '보고',\n",
       " '사세요',\n",
       " '쉬는',\n",
       " '강렬한',\n",
       " '낭비하지',\n",
       " '바빠서',\n",
       " '처음',\n",
       " '듣고',\n",
       " '뭘',\n",
       " '내',\n",
       " '선생님',\n",
       " '걸린',\n",
       " '그럴',\n",
       " '랑',\n",
       " '하는지',\n",
       " '를',\n",
       " '보게',\n",
       " '모두',\n",
       " '드세요',\n",
       " '가세',\n",
       " '참',\n",
       " '당황',\n",
       " '나온거',\n",
       " '가족',\n",
       " '있는',\n",
       " '1',\n",
       " '갑작스러웠나',\n",
       " '연락',\n",
       " '해도',\n",
       " '득템',\n",
       " '있어요',\n",
       " '볼까',\n",
       " '같아요',\n",
       " '관계',\n",
       " '버렸어',\n",
       " '돌아가서',\n",
       " '아픈가요',\n",
       " '데이터',\n",
       " '갈까',\n",
       " '제일',\n",
       " '감정',\n",
       " '절약',\n",
       " '봐서',\n",
       " '가출',\n",
       " '중요한',\n",
       " '오려나',\n",
       " '간만',\n",
       " '치킨',\n",
       " '어떤것',\n",
       " '하는데',\n",
       " '개',\n",
       " '역시',\n",
       " '3초',\n",
       " '갈거야',\n",
       " '아세요',\n",
       " '출발',\n",
       " '씨방',\n",
       " '드는',\n",
       " '쫄딱',\n",
       " '살펴',\n",
       " '알아차리지',\n",
       " '보고싶었나',\n",
       " '소중해요',\n",
       " '나오세요',\n",
       " '무시',\n",
       " '하고',\n",
       " '적',\n",
       " '즐기세요',\n",
       " '꼈어',\n",
       " '믿어',\n",
       " '그건',\n",
       " '많이',\n",
       " '생활',\n",
       " '하세요',\n",
       " '기관',\n",
       " '인',\n",
       " '불',\n",
       " '되겠네요',\n",
       " '걸리겠어',\n",
       " '난다',\n",
       " '가만',\n",
       " '좋아해주세요',\n",
       " '부모님',\n",
       " '강원도',\n",
       " '에',\n",
       " '중요해요',\n",
       " '으로',\n",
       " '될',\n",
       " '컨트롤',\n",
       " '고고',\n",
       " '보내고',\n",
       " '가스',\n",
       " '풀었어',\n",
       " '곳',\n",
       " '망가졌어',\n",
       " '다시',\n",
       " '빨리',\n",
       " '콕',\n",
       " '있을까',\n",
       " '12시',\n",
       " '공적',\n",
       " '다',\n",
       " '변화',\n",
       " '강의',\n",
       " '인게',\n",
       " '이',\n",
       " '까지',\n",
       " '해보세요',\n",
       " '돼',\n",
       " '한테',\n",
       " '가서',\n",
       " '장난',\n",
       " '키울',\n",
       " '눈물',\n",
       " '만',\n",
       " '감',\n",
       " '기회',\n",
       " 'SD',\n",
       " '가',\n",
       " '알아차려도',\n",
       " '로',\n",
       " '없어',\n",
       " '잠깐',\n",
       " '놀러',\n",
       " '일도',\n",
       " '벗어나는',\n",
       " '좋죠',\n",
       " '좋아요',\n",
       " '휴식',\n",
       " '먹을까',\n",
       " '시간',\n",
       " '가까워질',\n",
       " '아름다운',\n",
       " '같',\n",
       " '가고',\n",
       " '자체']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 출력\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어와 인덱스의 딕셔너리 생성, Series.count_values()도 가능\n",
    "word_to_index = {word: index for index, word in enumerate(words)}\n",
    "index_to_word = {index: word for index, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PADDING>': 0,\n",
       " '<START>': 1,\n",
       " '<END>': 2,\n",
       " '<OOV>': 3,\n",
       " '있어도': 4,\n",
       " '정': 5,\n",
       " '은': 6,\n",
       " '가지': 7,\n",
       " '식혀주세요': 8,\n",
       " '다음': 9,\n",
       " '단': 10,\n",
       " '낮잠': 11,\n",
       " '놓고': 12,\n",
       " '알': 13,\n",
       " '하루': 14,\n",
       " '하': 15,\n",
       " '위로': 16,\n",
       " '정말': 17,\n",
       " '함께': 18,\n",
       " 'PPL': 19,\n",
       " '갈': 20,\n",
       " '이에요': 21,\n",
       " '이다': 22,\n",
       " '없죠': 23,\n",
       " '부터': 24,\n",
       " '관리': 25,\n",
       " '처럼': 26,\n",
       " '시켜야지': 27,\n",
       " '약': 28,\n",
       " '먹었는데': 29,\n",
       " '싫어요': 30,\n",
       " '일': 31,\n",
       " '있어': 32,\n",
       " '간장': 33,\n",
       " '요': 34,\n",
       " '가난한': 35,\n",
       " '4일': 36,\n",
       " '사랑': 37,\n",
       " '했잖아': 38,\n",
       " '개인': 39,\n",
       " '곧': 40,\n",
       " '입어볼까': 41,\n",
       " '간다': 42,\n",
       " '때': 43,\n",
       " '새로': 44,\n",
       " '습관': 45,\n",
       " '여행': 46,\n",
       " '집': 47,\n",
       " '끄고': 48,\n",
       " '물어보세요': 49,\n",
       " '인거': 50,\n",
       " '싫어하지': 51,\n",
       " '사이': 52,\n",
       " '엉망': 53,\n",
       " '그런거니': 54,\n",
       " '걔': 55,\n",
       " '수도': 56,\n",
       " '비싼데': 57,\n",
       " '싫어': 58,\n",
       " '옴': 59,\n",
       " '나왔다': 60,\n",
       " '가야': 61,\n",
       " '맞팔': 62,\n",
       " '막': 63,\n",
       " '비': 64,\n",
       " '되나': 65,\n",
       " '당신': 66,\n",
       " '켜놓고': 67,\n",
       " '끼리': 68,\n",
       " '확실한': 69,\n",
       " '눈살': 70,\n",
       " '살까': 71,\n",
       " '간식': 72,\n",
       " '그게': 73,\n",
       " '했길': 74,\n",
       " '잊고': 75,\n",
       " '나쁜': 76,\n",
       " '하는': 77,\n",
       " '집어서': 78,\n",
       " '예쁘게': 79,\n",
       " '3': 80,\n",
       " '결정': 81,\n",
       " '지망': 82,\n",
       " '뭐': 83,\n",
       " '갑자기': 84,\n",
       " '사는게': 85,\n",
       " '연인': 86,\n",
       " '해볼까': 87,\n",
       " '가장': 88,\n",
       " '자꾸': 89,\n",
       " '누구': 90,\n",
       " '어디': 91,\n",
       " '의': 92,\n",
       " '같은': 93,\n",
       " '이야': 94,\n",
       " '이나': 95,\n",
       " '서먹해졌어': 96,\n",
       " '하지': 97,\n",
       " '개학': 98,\n",
       " '떨리는': 99,\n",
       " '말랭이': 100,\n",
       " '까': 101,\n",
       " '야': 102,\n",
       " '좋아': 103,\n",
       " '세수': 104,\n",
       " '개념': 105,\n",
       " '사는': 106,\n",
       " '중': 107,\n",
       " '하면': 108,\n",
       " '살쪄도': 109,\n",
       " '먹고': 110,\n",
       " '마음': 111,\n",
       " '키우고': 112,\n",
       " '있을': 113,\n",
       " '첫인상': 114,\n",
       " '먹어야지': 115,\n",
       " '닮아서': 116,\n",
       " '따뜻하게': 117,\n",
       " '간접흡연': 118,\n",
       " '설움': 119,\n",
       " '추천': 120,\n",
       " '패턴': 121,\n",
       " '혼자': 122,\n",
       " '즐거운': 123,\n",
       " '찌푸려지죠': 124,\n",
       " '이야기': 125,\n",
       " '취미': 126,\n",
       " '땡': 127,\n",
       " '가네요': 128,\n",
       " '이럴': 129,\n",
       " '이랑': 130,\n",
       " '돈': 131,\n",
       " '낭비': 132,\n",
       " 'ㅠㅠ': 133,\n",
       " '키울까': 134,\n",
       " '살찐': 135,\n",
       " '싫다': 136,\n",
       " '건데': 137,\n",
       " '서로': 138,\n",
       " '감미로운': 139,\n",
       " '알려': 140,\n",
       " '매일': 141,\n",
       " '서먹해': 142,\n",
       " '하느라': 143,\n",
       " '가끔': 144,\n",
       " '정도': 145,\n",
       " '거': 146,\n",
       " '불편한': 147,\n",
       " '짧죠': 148,\n",
       " '괜찮아요': 149,\n",
       " '맛있게': 150,\n",
       " '또': 151,\n",
       " '에요': 152,\n",
       " '무모한': 153,\n",
       " '들어올': 154,\n",
       " '가보세요': 155,\n",
       " '부족했나': 156,\n",
       " '업무': 157,\n",
       " '궁금해': 158,\n",
       " '목소리': 159,\n",
       " '지': 160,\n",
       " '피': 161,\n",
       " '만들어': 162,\n",
       " '붙잡고': 163,\n",
       " '켜고': 164,\n",
       " '떨리니까': 165,\n",
       " '기름': 166,\n",
       " '예요': 167,\n",
       " '시켜': 168,\n",
       " '아님': 169,\n",
       " '진리': 170,\n",
       " '을': 171,\n",
       " '보세요': 172,\n",
       " '입어': 173,\n",
       " '좋겠다': 174,\n",
       " '수': 175,\n",
       " '해봐요': 176,\n",
       " '해주세요': 177,\n",
       " '더': 178,\n",
       " '개시': 179,\n",
       " '룩': 180,\n",
       " '키워': 181,\n",
       " '두': 182,\n",
       " '되도록': 183,\n",
       " '쇼핑': 184,\n",
       " '는': 185,\n",
       " '않을': 186,\n",
       " '고민': 187,\n",
       " '옷': 188,\n",
       " '상황': 189,\n",
       " '만나지': 190,\n",
       " '떨어졌어': 191,\n",
       " '봐요': 192,\n",
       " '자의': 193,\n",
       " '해': 194,\n",
       " '감기': 195,\n",
       " '빼고': 196,\n",
       " '그': 197,\n",
       " '힘든데': 198,\n",
       " '도': 199,\n",
       " '부터는': 200,\n",
       " '내일': 201,\n",
       " '생각': 202,\n",
       " '자도': 203,\n",
       " '박': 204,\n",
       " '남겨야': 205,\n",
       " '니까': 206,\n",
       " '어제': 207,\n",
       " '끌': 208,\n",
       " '반': 209,\n",
       " '인데': 210,\n",
       " '가기': 211,\n",
       " '진창': 212,\n",
       " '되': 213,\n",
       " '리지': 214,\n",
       " '할까': 215,\n",
       " '됐으면': 216,\n",
       " '못': 217,\n",
       " '하자고': 218,\n",
       " '후회': 219,\n",
       " '오세요': 220,\n",
       " '줘': 221,\n",
       " '데': 222,\n",
       " '해보여': 223,\n",
       " '하겠어': 224,\n",
       " '나를': 225,\n",
       " '병원': 226,\n",
       " '너무': 227,\n",
       " '좋은': 228,\n",
       " '스트레스': 229,\n",
       " '가자고': 230,\n",
       " '마세요': 231,\n",
       " '싶네요': 232,\n",
       " '들': 233,\n",
       " '싶어': 234,\n",
       " '애가': 235,\n",
       " '짠으로': 236,\n",
       " '자랑': 237,\n",
       " '에는': 238,\n",
       " '주는': 239,\n",
       " '이라니': 240,\n",
       " '카드': 241,\n",
       " '것': 242,\n",
       " '수영장': 243,\n",
       " '기운': 244,\n",
       " '화폐': 245,\n",
       " '준': 246,\n",
       " '드립니다': 247,\n",
       " '봅니다': 248,\n",
       " '된': 249,\n",
       " '가려고': 250,\n",
       " '모르고': 251,\n",
       " '행복': 252,\n",
       " '안': 253,\n",
       " '왜': 254,\n",
       " '말': 255,\n",
       " '같이': 256,\n",
       " '들더라': 257,\n",
       " '좋더라': 258,\n",
       " '책임질': 259,\n",
       " '매력': 260,\n",
       " '먼저': 261,\n",
       " '달': 262,\n",
       " '누굴': 263,\n",
       " '말까': 264,\n",
       " '나갔어': 265,\n",
       " '망함': 266,\n",
       " '싶다': 267,\n",
       " '좋다': 268,\n",
       " '땀': 269,\n",
       " '언제나': 270,\n",
       " '강아지': 271,\n",
       " '자신': 272,\n",
       " 'SNS': 273,\n",
       " '쓰레기통': 274,\n",
       " '바라요': 275,\n",
       " '심하네': 276,\n",
       " '자리': 277,\n",
       " '잘': 278,\n",
       " '했어': 279,\n",
       " '운': 280,\n",
       " '돼겠지': 281,\n",
       " '좋겠네요': 282,\n",
       " '어서': 283,\n",
       " '저': 284,\n",
       " '친구': 285,\n",
       " '새': 286,\n",
       " '사람': 287,\n",
       " '편해요': 288,\n",
       " '감히': 289,\n",
       " '같아': 290,\n",
       " '와': 291,\n",
       " '있으면': 292,\n",
       " '질질': 293,\n",
       " '가상': 294,\n",
       " '온': 295,\n",
       " '최고': 296,\n",
       " '게임': 297,\n",
       " '아는데': 298,\n",
       " '게': 299,\n",
       " '애': 300,\n",
       " '나': 301,\n",
       " '어필': 302,\n",
       " '됨': 303,\n",
       " '건': 304,\n",
       " '개강': 305,\n",
       " '물어': 306,\n",
       " '왔나': 307,\n",
       " '물어봐서': 308,\n",
       " '졸려': 309,\n",
       " '오늘이': 310,\n",
       " '필요하죠': 311,\n",
       " '방학': 312,\n",
       " '보면': 313,\n",
       " '할': 314,\n",
       " '죠': 315,\n",
       " '학교': 316,\n",
       " '싶은데': 317,\n",
       " '보고': 318,\n",
       " '사세요': 319,\n",
       " '쉬는': 320,\n",
       " '강렬한': 321,\n",
       " '낭비하지': 322,\n",
       " '바빠서': 323,\n",
       " '처음': 324,\n",
       " '듣고': 325,\n",
       " '뭘': 326,\n",
       " '내': 327,\n",
       " '선생님': 328,\n",
       " '걸린': 329,\n",
       " '그럴': 330,\n",
       " '랑': 331,\n",
       " '하는지': 332,\n",
       " '를': 333,\n",
       " '보게': 334,\n",
       " '모두': 335,\n",
       " '드세요': 336,\n",
       " '가세': 337,\n",
       " '참': 338,\n",
       " '당황': 339,\n",
       " '나온거': 340,\n",
       " '가족': 341,\n",
       " '있는': 342,\n",
       " '1': 343,\n",
       " '갑작스러웠나': 344,\n",
       " '연락': 345,\n",
       " '해도': 346,\n",
       " '득템': 347,\n",
       " '있어요': 348,\n",
       " '볼까': 349,\n",
       " '같아요': 350,\n",
       " '관계': 351,\n",
       " '버렸어': 352,\n",
       " '돌아가서': 353,\n",
       " '아픈가요': 354,\n",
       " '데이터': 355,\n",
       " '갈까': 356,\n",
       " '제일': 357,\n",
       " '감정': 358,\n",
       " '절약': 359,\n",
       " '봐서': 360,\n",
       " '가출': 361,\n",
       " '중요한': 362,\n",
       " '오려나': 363,\n",
       " '간만': 364,\n",
       " '치킨': 365,\n",
       " '어떤것': 366,\n",
       " '하는데': 367,\n",
       " '개': 368,\n",
       " '역시': 369,\n",
       " '3초': 370,\n",
       " '갈거야': 371,\n",
       " '아세요': 372,\n",
       " '출발': 373,\n",
       " '씨방': 374,\n",
       " '드는': 375,\n",
       " '쫄딱': 376,\n",
       " '살펴': 377,\n",
       " '알아차리지': 378,\n",
       " '보고싶었나': 379,\n",
       " '소중해요': 380,\n",
       " '나오세요': 381,\n",
       " '무시': 382,\n",
       " '하고': 383,\n",
       " '적': 384,\n",
       " '즐기세요': 385,\n",
       " '꼈어': 386,\n",
       " '믿어': 387,\n",
       " '그건': 388,\n",
       " '많이': 389,\n",
       " '생활': 390,\n",
       " '하세요': 391,\n",
       " '기관': 392,\n",
       " '인': 393,\n",
       " '불': 394,\n",
       " '되겠네요': 395,\n",
       " '걸리겠어': 396,\n",
       " '난다': 397,\n",
       " '가만': 398,\n",
       " '좋아해주세요': 399,\n",
       " '부모님': 400,\n",
       " '강원도': 401,\n",
       " '에': 402,\n",
       " '중요해요': 403,\n",
       " '으로': 404,\n",
       " '될': 405,\n",
       " '컨트롤': 406,\n",
       " '고고': 407,\n",
       " '보내고': 408,\n",
       " '가스': 409,\n",
       " '풀었어': 410,\n",
       " '곳': 411,\n",
       " '망가졌어': 412,\n",
       " '다시': 413,\n",
       " '빨리': 414,\n",
       " '콕': 415,\n",
       " '있을까': 416,\n",
       " '12시': 417,\n",
       " '공적': 418,\n",
       " '다': 419,\n",
       " '변화': 420,\n",
       " '강의': 421,\n",
       " '인게': 422,\n",
       " '이': 423,\n",
       " '까지': 424,\n",
       " '해보세요': 425,\n",
       " '돼': 426,\n",
       " '한테': 427,\n",
       " '가서': 428,\n",
       " '장난': 429,\n",
       " '키울': 430,\n",
       " '눈물': 431,\n",
       " '만': 432,\n",
       " '감': 433,\n",
       " '기회': 434,\n",
       " 'SD': 435,\n",
       " '가': 436,\n",
       " '알아차려도': 437,\n",
       " '로': 438,\n",
       " '없어': 439,\n",
       " '잠깐': 440,\n",
       " '놀러': 441,\n",
       " '일도': 442,\n",
       " '벗어나는': 443,\n",
       " '좋죠': 444,\n",
       " '좋아요': 445,\n",
       " '휴식': 446,\n",
       " '먹을까': 447,\n",
       " '시간': 448,\n",
       " '가까워질': 449,\n",
       " '아름다운': 450,\n",
       " '같': 451,\n",
       " '가고': 452,\n",
       " '자체': 453}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 -> 인덱스\n",
    "# 문장을 인덱스로 변환하여 모델 입력으로 사용\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PADDING>',\n",
       " 1: '<START>',\n",
       " 2: '<END>',\n",
       " 3: '<OOV>',\n",
       " 4: '있어도',\n",
       " 5: '정',\n",
       " 6: '은',\n",
       " 7: '가지',\n",
       " 8: '식혀주세요',\n",
       " 9: '다음',\n",
       " 10: '단',\n",
       " 11: '낮잠',\n",
       " 12: '놓고',\n",
       " 13: '알',\n",
       " 14: '하루',\n",
       " 15: '하',\n",
       " 16: '위로',\n",
       " 17: '정말',\n",
       " 18: '함께',\n",
       " 19: 'PPL',\n",
       " 20: '갈',\n",
       " 21: '이에요',\n",
       " 22: '이다',\n",
       " 23: '없죠',\n",
       " 24: '부터',\n",
       " 25: '관리',\n",
       " 26: '처럼',\n",
       " 27: '시켜야지',\n",
       " 28: '약',\n",
       " 29: '먹었는데',\n",
       " 30: '싫어요',\n",
       " 31: '일',\n",
       " 32: '있어',\n",
       " 33: '간장',\n",
       " 34: '요',\n",
       " 35: '가난한',\n",
       " 36: '4일',\n",
       " 37: '사랑',\n",
       " 38: '했잖아',\n",
       " 39: '개인',\n",
       " 40: '곧',\n",
       " 41: '입어볼까',\n",
       " 42: '간다',\n",
       " 43: '때',\n",
       " 44: '새로',\n",
       " 45: '습관',\n",
       " 46: '여행',\n",
       " 47: '집',\n",
       " 48: '끄고',\n",
       " 49: '물어보세요',\n",
       " 50: '인거',\n",
       " 51: '싫어하지',\n",
       " 52: '사이',\n",
       " 53: '엉망',\n",
       " 54: '그런거니',\n",
       " 55: '걔',\n",
       " 56: '수도',\n",
       " 57: '비싼데',\n",
       " 58: '싫어',\n",
       " 59: '옴',\n",
       " 60: '나왔다',\n",
       " 61: '가야',\n",
       " 62: '맞팔',\n",
       " 63: '막',\n",
       " 64: '비',\n",
       " 65: '되나',\n",
       " 66: '당신',\n",
       " 67: '켜놓고',\n",
       " 68: '끼리',\n",
       " 69: '확실한',\n",
       " 70: '눈살',\n",
       " 71: '살까',\n",
       " 72: '간식',\n",
       " 73: '그게',\n",
       " 74: '했길',\n",
       " 75: '잊고',\n",
       " 76: '나쁜',\n",
       " 77: '하는',\n",
       " 78: '집어서',\n",
       " 79: '예쁘게',\n",
       " 80: '3',\n",
       " 81: '결정',\n",
       " 82: '지망',\n",
       " 83: '뭐',\n",
       " 84: '갑자기',\n",
       " 85: '사는게',\n",
       " 86: '연인',\n",
       " 87: '해볼까',\n",
       " 88: '가장',\n",
       " 89: '자꾸',\n",
       " 90: '누구',\n",
       " 91: '어디',\n",
       " 92: '의',\n",
       " 93: '같은',\n",
       " 94: '이야',\n",
       " 95: '이나',\n",
       " 96: '서먹해졌어',\n",
       " 97: '하지',\n",
       " 98: '개학',\n",
       " 99: '떨리는',\n",
       " 100: '말랭이',\n",
       " 101: '까',\n",
       " 102: '야',\n",
       " 103: '좋아',\n",
       " 104: '세수',\n",
       " 105: '개념',\n",
       " 106: '사는',\n",
       " 107: '중',\n",
       " 108: '하면',\n",
       " 109: '살쪄도',\n",
       " 110: '먹고',\n",
       " 111: '마음',\n",
       " 112: '키우고',\n",
       " 113: '있을',\n",
       " 114: '첫인상',\n",
       " 115: '먹어야지',\n",
       " 116: '닮아서',\n",
       " 117: '따뜻하게',\n",
       " 118: '간접흡연',\n",
       " 119: '설움',\n",
       " 120: '추천',\n",
       " 121: '패턴',\n",
       " 122: '혼자',\n",
       " 123: '즐거운',\n",
       " 124: '찌푸려지죠',\n",
       " 125: '이야기',\n",
       " 126: '취미',\n",
       " 127: '땡',\n",
       " 128: '가네요',\n",
       " 129: '이럴',\n",
       " 130: '이랑',\n",
       " 131: '돈',\n",
       " 132: '낭비',\n",
       " 133: 'ㅠㅠ',\n",
       " 134: '키울까',\n",
       " 135: '살찐',\n",
       " 136: '싫다',\n",
       " 137: '건데',\n",
       " 138: '서로',\n",
       " 139: '감미로운',\n",
       " 140: '알려',\n",
       " 141: '매일',\n",
       " 142: '서먹해',\n",
       " 143: '하느라',\n",
       " 144: '가끔',\n",
       " 145: '정도',\n",
       " 146: '거',\n",
       " 147: '불편한',\n",
       " 148: '짧죠',\n",
       " 149: '괜찮아요',\n",
       " 150: '맛있게',\n",
       " 151: '또',\n",
       " 152: '에요',\n",
       " 153: '무모한',\n",
       " 154: '들어올',\n",
       " 155: '가보세요',\n",
       " 156: '부족했나',\n",
       " 157: '업무',\n",
       " 158: '궁금해',\n",
       " 159: '목소리',\n",
       " 160: '지',\n",
       " 161: '피',\n",
       " 162: '만들어',\n",
       " 163: '붙잡고',\n",
       " 164: '켜고',\n",
       " 165: '떨리니까',\n",
       " 166: '기름',\n",
       " 167: '예요',\n",
       " 168: '시켜',\n",
       " 169: '아님',\n",
       " 170: '진리',\n",
       " 171: '을',\n",
       " 172: '보세요',\n",
       " 173: '입어',\n",
       " 174: '좋겠다',\n",
       " 175: '수',\n",
       " 176: '해봐요',\n",
       " 177: '해주세요',\n",
       " 178: '더',\n",
       " 179: '개시',\n",
       " 180: '룩',\n",
       " 181: '키워',\n",
       " 182: '두',\n",
       " 183: '되도록',\n",
       " 184: '쇼핑',\n",
       " 185: '는',\n",
       " 186: '않을',\n",
       " 187: '고민',\n",
       " 188: '옷',\n",
       " 189: '상황',\n",
       " 190: '만나지',\n",
       " 191: '떨어졌어',\n",
       " 192: '봐요',\n",
       " 193: '자의',\n",
       " 194: '해',\n",
       " 195: '감기',\n",
       " 196: '빼고',\n",
       " 197: '그',\n",
       " 198: '힘든데',\n",
       " 199: '도',\n",
       " 200: '부터는',\n",
       " 201: '내일',\n",
       " 202: '생각',\n",
       " 203: '자도',\n",
       " 204: '박',\n",
       " 205: '남겨야',\n",
       " 206: '니까',\n",
       " 207: '어제',\n",
       " 208: '끌',\n",
       " 209: '반',\n",
       " 210: '인데',\n",
       " 211: '가기',\n",
       " 212: '진창',\n",
       " 213: '되',\n",
       " 214: '리지',\n",
       " 215: '할까',\n",
       " 216: '됐으면',\n",
       " 217: '못',\n",
       " 218: '하자고',\n",
       " 219: '후회',\n",
       " 220: '오세요',\n",
       " 221: '줘',\n",
       " 222: '데',\n",
       " 223: '해보여',\n",
       " 224: '하겠어',\n",
       " 225: '나를',\n",
       " 226: '병원',\n",
       " 227: '너무',\n",
       " 228: '좋은',\n",
       " 229: '스트레스',\n",
       " 230: '가자고',\n",
       " 231: '마세요',\n",
       " 232: '싶네요',\n",
       " 233: '들',\n",
       " 234: '싶어',\n",
       " 235: '애가',\n",
       " 236: '짠으로',\n",
       " 237: '자랑',\n",
       " 238: '에는',\n",
       " 239: '주는',\n",
       " 240: '이라니',\n",
       " 241: '카드',\n",
       " 242: '것',\n",
       " 243: '수영장',\n",
       " 244: '기운',\n",
       " 245: '화폐',\n",
       " 246: '준',\n",
       " 247: '드립니다',\n",
       " 248: '봅니다',\n",
       " 249: '된',\n",
       " 250: '가려고',\n",
       " 251: '모르고',\n",
       " 252: '행복',\n",
       " 253: '안',\n",
       " 254: '왜',\n",
       " 255: '말',\n",
       " 256: '같이',\n",
       " 257: '들더라',\n",
       " 258: '좋더라',\n",
       " 259: '책임질',\n",
       " 260: '매력',\n",
       " 261: '먼저',\n",
       " 262: '달',\n",
       " 263: '누굴',\n",
       " 264: '말까',\n",
       " 265: '나갔어',\n",
       " 266: '망함',\n",
       " 267: '싶다',\n",
       " 268: '좋다',\n",
       " 269: '땀',\n",
       " 270: '언제나',\n",
       " 271: '강아지',\n",
       " 272: '자신',\n",
       " 273: 'SNS',\n",
       " 274: '쓰레기통',\n",
       " 275: '바라요',\n",
       " 276: '심하네',\n",
       " 277: '자리',\n",
       " 278: '잘',\n",
       " 279: '했어',\n",
       " 280: '운',\n",
       " 281: '돼겠지',\n",
       " 282: '좋겠네요',\n",
       " 283: '어서',\n",
       " 284: '저',\n",
       " 285: '친구',\n",
       " 286: '새',\n",
       " 287: '사람',\n",
       " 288: '편해요',\n",
       " 289: '감히',\n",
       " 290: '같아',\n",
       " 291: '와',\n",
       " 292: '있으면',\n",
       " 293: '질질',\n",
       " 294: '가상',\n",
       " 295: '온',\n",
       " 296: '최고',\n",
       " 297: '게임',\n",
       " 298: '아는데',\n",
       " 299: '게',\n",
       " 300: '애',\n",
       " 301: '나',\n",
       " 302: '어필',\n",
       " 303: '됨',\n",
       " 304: '건',\n",
       " 305: '개강',\n",
       " 306: '물어',\n",
       " 307: '왔나',\n",
       " 308: '물어봐서',\n",
       " 309: '졸려',\n",
       " 310: '오늘이',\n",
       " 311: '필요하죠',\n",
       " 312: '방학',\n",
       " 313: '보면',\n",
       " 314: '할',\n",
       " 315: '죠',\n",
       " 316: '학교',\n",
       " 317: '싶은데',\n",
       " 318: '보고',\n",
       " 319: '사세요',\n",
       " 320: '쉬는',\n",
       " 321: '강렬한',\n",
       " 322: '낭비하지',\n",
       " 323: '바빠서',\n",
       " 324: '처음',\n",
       " 325: '듣고',\n",
       " 326: '뭘',\n",
       " 327: '내',\n",
       " 328: '선생님',\n",
       " 329: '걸린',\n",
       " 330: '그럴',\n",
       " 331: '랑',\n",
       " 332: '하는지',\n",
       " 333: '를',\n",
       " 334: '보게',\n",
       " 335: '모두',\n",
       " 336: '드세요',\n",
       " 337: '가세',\n",
       " 338: '참',\n",
       " 339: '당황',\n",
       " 340: '나온거',\n",
       " 341: '가족',\n",
       " 342: '있는',\n",
       " 343: '1',\n",
       " 344: '갑작스러웠나',\n",
       " 345: '연락',\n",
       " 346: '해도',\n",
       " 347: '득템',\n",
       " 348: '있어요',\n",
       " 349: '볼까',\n",
       " 350: '같아요',\n",
       " 351: '관계',\n",
       " 352: '버렸어',\n",
       " 353: '돌아가서',\n",
       " 354: '아픈가요',\n",
       " 355: '데이터',\n",
       " 356: '갈까',\n",
       " 357: '제일',\n",
       " 358: '감정',\n",
       " 359: '절약',\n",
       " 360: '봐서',\n",
       " 361: '가출',\n",
       " 362: '중요한',\n",
       " 363: '오려나',\n",
       " 364: '간만',\n",
       " 365: '치킨',\n",
       " 366: '어떤것',\n",
       " 367: '하는데',\n",
       " 368: '개',\n",
       " 369: '역시',\n",
       " 370: '3초',\n",
       " 371: '갈거야',\n",
       " 372: '아세요',\n",
       " 373: '출발',\n",
       " 374: '씨방',\n",
       " 375: '드는',\n",
       " 376: '쫄딱',\n",
       " 377: '살펴',\n",
       " 378: '알아차리지',\n",
       " 379: '보고싶었나',\n",
       " 380: '소중해요',\n",
       " 381: '나오세요',\n",
       " 382: '무시',\n",
       " 383: '하고',\n",
       " 384: '적',\n",
       " 385: '즐기세요',\n",
       " 386: '꼈어',\n",
       " 387: '믿어',\n",
       " 388: '그건',\n",
       " 389: '많이',\n",
       " 390: '생활',\n",
       " 391: '하세요',\n",
       " 392: '기관',\n",
       " 393: '인',\n",
       " 394: '불',\n",
       " 395: '되겠네요',\n",
       " 396: '걸리겠어',\n",
       " 397: '난다',\n",
       " 398: '가만',\n",
       " 399: '좋아해주세요',\n",
       " 400: '부모님',\n",
       " 401: '강원도',\n",
       " 402: '에',\n",
       " 403: '중요해요',\n",
       " 404: '으로',\n",
       " 405: '될',\n",
       " 406: '컨트롤',\n",
       " 407: '고고',\n",
       " 408: '보내고',\n",
       " 409: '가스',\n",
       " 410: '풀었어',\n",
       " 411: '곳',\n",
       " 412: '망가졌어',\n",
       " 413: '다시',\n",
       " 414: '빨리',\n",
       " 415: '콕',\n",
       " 416: '있을까',\n",
       " 417: '12시',\n",
       " 418: '공적',\n",
       " 419: '다',\n",
       " 420: '변화',\n",
       " 421: '강의',\n",
       " 422: '인게',\n",
       " 423: '이',\n",
       " 424: '까지',\n",
       " 425: '해보세요',\n",
       " 426: '돼',\n",
       " 427: '한테',\n",
       " 428: '가서',\n",
       " 429: '장난',\n",
       " 430: '키울',\n",
       " 431: '눈물',\n",
       " 432: '만',\n",
       " 433: '감',\n",
       " 434: '기회',\n",
       " 435: 'SD',\n",
       " 436: '가',\n",
       " 437: '알아차려도',\n",
       " 438: '로',\n",
       " 439: '없어',\n",
       " 440: '잠깐',\n",
       " 441: '놀러',\n",
       " 442: '일도',\n",
       " 443: '벗어나는',\n",
       " 444: '좋죠',\n",
       " 445: '좋아요',\n",
       " 446: '휴식',\n",
       " 447: '먹을까',\n",
       " 448: '시간',\n",
       " 449: '가까워질',\n",
       " 450: '아름다운',\n",
       " 451: '같',\n",
       " 452: '가고',\n",
       " 453: '자체'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 -> 단어\n",
    "# 모델의 예측 결과인 인덱스를 문장으로 변환시 사용\n",
    "index_to_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "def convert_text_to_index(sentences, vocabulary, type): \n",
    "    \n",
    "    sentences_index = []\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for sentence in sentences:\n",
    "        sentence_index = []\n",
    "        \n",
    "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
    "        if type == DECODER_INPUT:\n",
    "            sentence_index.extend([vocabulary[STA]])\n",
    "        \n",
    "        # 문장의 단어들을 띄어쓰기로 분리\n",
    "        for word in sentence.split():\n",
    "            if vocabulary.get(word) is not None:\n",
    "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[word]])\n",
    "            else:\n",
    "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[OOV]])\n",
    "\n",
    "        # 최대 길이 검사\n",
    "        if type == DECODER_TARGET:\n",
    "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
    "            if len(sentence_index) >= max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
    "            else:\n",
    "                sentence_index += [vocabulary[END]]\n",
    "        else:\n",
    "            if len(sentence_index) > max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences]\n",
    "            \n",
    "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
    "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
    "        \n",
    "        # 문장의 인덱스 배열을 추가\n",
    "        sentences_index.append(sentence_index)\n",
    "\n",
    "    return np.asarray(sentences_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq에서는 학습시 다음과 같이 총 3개의 데이터가 필요합니다.\n",
    "\n",
    "인코더 입력 : 12시 땡<br>\n",
    "디코더 입력 : START 하루 가 또 가네요<br>\n",
    "디코더 출력 : 하루 가 또 가네요 END\n",
    "<br>\n",
    "원래 Seq2Seq는 디코더의 현재 출력이 디코더의 다음 입력으로 들어갑니다.<br>\n",
    "다만 학습에서는 굳이 이렇게 하지 않고 디코더 입력과 디코더 출력의 데이터를 각각 만듭니다. <br>\n",
    "<br>\n",
    "그러나 예측시에는 이런 방식이 불가능합니다.<br>\n",
    "출력값을 미리 알지 못하기 때문에, 디코더 입력을 사전에 생성할 수가 없습니다.<br>\n",
    "이런 문제를 해결하기 위해 훈련 모델과 예측 모델을 따로 구성해야 합니다.<br>\n",
    "모델 생성 부분에서 다시 자세히 설명을 드리겠습니다.<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 question: 12시 땡\n",
      "첫번째 Encoder 입력: [417 127   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "index_to_word[ 125 ]: 이야기\n",
      "index_to_word[ 308 ]: 물어봐서\n"
     ]
    }
   ],
   "source": [
    "# 인코더 입력 인덱스 변환\n",
    "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
    "\n",
    "print('첫번째 question:', question[0])\n",
    "# 첫 번째 인코더 입력 출력 (12시 땡)\n",
    "print('첫번째 Encoder 입력:',x_encoder[0])\n",
    "print()\n",
    "\n",
    "# 출력된 125, 308은 word의 index\n",
    "print('index_to_word[ 125 ]:', index_to_word[ 125 ])\n",
    "print('index_to_word[ 308 ]:', index_to_word[ 308 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 answer: 하루 가 또 가네요\n",
      "첫번째 Decoder input: [  1  14 436 151 128   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "index_to_word[   1 ]: <START>\n",
      "index_to_word[ 259 ]: 책임질\n",
      "index_to_word[ 223 ]: 해보여\n",
      "index_to_word[ 114 ]: 첫인상\n",
      "index_to_word[  74 ]: 했길\n"
     ]
    }
   ],
   "source": [
    "# 디코더 입력 인덱스 변환\n",
    "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
    "\n",
    "print('첫번째 answer:', answer[0])\n",
    "print('첫번째 Decoder input:', x_decoder[0])\n",
    "print()\n",
    "\n",
    "# 출력된 1, 259, 223, 114, 74는 word의 index\n",
    "print('index_to_word[   1 ]:', index_to_word[   1 ])\n",
    "print('index_to_word[ 259 ]:', index_to_word[ 259 ])\n",
    "print('index_to_word[ 223 ]:', index_to_word[ 223 ])\n",
    "print('index_to_word[ 114 ]:', index_to_word[ 114 ])\n",
    "print('index_to_word[  74 ]:', index_to_word[  74 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 answer: 하루 가 또 가네요\n",
      "첫번쨰 Decoder onput: [ 14 436 151 128   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "index_to_word[ 259 ]: 책임질\n",
      "index_to_word[ 223 ]: 해보여\n",
      "index_to_word[ 114 ]: 첫인상\n",
      "index_to_word[  74 ]: 했길\n",
      "index_to_word[   2 ]: <END>\n"
     ]
    }
   ],
   "source": [
    "# 디코더 목표 인덱스 변환\n",
    "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
    "\n",
    "# 첫 번째 디코더 목표 출력 (하루 가 또 가네요 END)\n",
    "y_decoder[0]\n",
    "\n",
    "print('첫번째 answer:', answer[0])\n",
    "print('첫번쨰 Decoder onput:', y_decoder[0])\n",
    "print()\n",
    "\n",
    "# 출력된 1, 259, 223, 114, 74는 word의 index\n",
    "print('index_to_word[ 259 ]:', index_to_word[ 259 ])\n",
    "print('index_to_word[ 223 ]:', index_to_word[ 223 ])\n",
    "print('index_to_word[ 114 ]:', index_to_word[ 114 ])\n",
    "print('index_to_word[  74 ]:', index_to_word[  74 ])\n",
    "print('index_to_word[   2 ]:', index_to_word[   2 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫인코딩 초기화\n",
    "one_hot_data = np.zeros((len(y_decoder), max_sequences, len(words)))\n",
    "one_hot_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14, 436, 151, 128,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one_hot_data의 첫 row에 259번째 column에 '하루'\n",
    "#one_hot_data의 첫 row에 223번째 column에 '가'\n",
    "#one_hot_data의 첫 row에 114번째 column에 '또'.... 를 1로 변경\n",
    "y_decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디코더 목표를 원핫인코딩으로 변환\n",
    "# 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
    "for i, sequence in enumerate(y_decoder):\n",
    "    for j, index in enumerate(sequence):\n",
    "        one_hot_data[i, j, index] = 1\n",
    "\n",
    "# 디코더 목표 설정\n",
    "y_decoder = one_hot_data\n",
    "\n",
    "# 첫 번째 디코더 목표 출력\n",
    "y_decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 259번째 index (하루) 가 1임\n",
    "y_decoder[0][0][112]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더 입력과 디코더 입력은 임베딩 레이어에 들어가는 인덱스 배열입니다.<br>\n",
    "반면에 디코더 출력은 원핫인코딩 형식이 되어야 합니다.<br>\n",
    "디코더의 마지막 Dense 레이어에서 softmax로 나오기 때문입니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "encoder_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "encoder_outputs = layers.Embedding(len(words), embedding_dim)(encoder_inputs)\n",
    "\n",
    "# return_state가 True면 상태값 리턴\n",
    "# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n",
    "encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_dim,\n",
    "                                                dropout=0.1,\n",
    "                                                recurrent_dropout=0.5,\n",
    "                                                return_state=True)(encoder_outputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "# Decoder의 initial state에 넣어주기 위함\n",
    "# 즉, input sentence의 모든 정보를 통해 Decoding 하기 위함\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm')>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm')>,\n",
       " <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm')>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "decoder_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_embedding = layers.Embedding(len(words), embedding_dim)\n",
    "decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n",
    "# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n",
    "decoder_lstm = layers.LSTM(lstm_hidden_dim,\n",
    "                           dropout=0.1,\n",
    "                           recurrent_dropout=0.5,\n",
    "                           return_state=True,\n",
    "                           return_sequences=True)\n",
    "\n",
    "# initial_state를 인코더의 상태로 초기화\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_dense = layers.Dense(len(words), activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지의 예제는 Sequential 방식의 모델이었습니다.<br>\n",
    "하지만 이번에는 함수형 API 모델을 사용했습니다.<br>\n",
    "인코더와 디코더가 따로 분리되어야 하는데, 단순히 레이어를 추가하여 붙이는 순차형으로는 구현이 불가능하기 때문입니다. <br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력과 출력으로 함수형 API 모델 생성\n",
    "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# 학습 방법 설정\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model() 함수로 입력과 출력을 따로 설정하여 모델을 만듭니다.<br>\n",
    "그다음 compile과 fit은 이전과 동일하게 적용하시면 됩니다.<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "#  예측 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
    "encoder_model = models.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "#--------------------------------------------\n",
    "# 예측 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n",
    "# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n",
    "decoder_state_input_h = layers.Input(shape=(lstm_hidden_dim,))\n",
    "decoder_state_input_c = layers.Input(shape=(lstm_hidden_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# LSTM 레이어\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n",
    "                                                 initial_state=decoder_states_inputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 예측 모델 디코더 설정\n",
    "decoder_model = models.Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 모델은 이미 학습된 훈련 모델의 레이어들을 그대로 재사용합니다. 예측 모델 인코더는 훈련 모델 인코더과 동일합니다. 그러나 예측 모델 디코더는 매번 LSTM 상태값을 입력으로 받습니다. 또한 디코더의 LSTM 상태를 출력값과 같이 내보내서, 다음 번 입력에 넣습니다. \n",
    "\n",
    "이렇게 하는 이유는 LSTM을 딱 한번의 타임 스텝만 실행하기 때문입니다. 그래서 매번 상태값을 새로 초기화 해야 합니다. 이와 반대로 훈련할때는 문장 전체를 계속 LSTM으로 돌리기 때문에 자동으로 상태값이 전달됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 100)    45400       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    45400       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 128),        117248      ['embedding[0][0]']              \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 128),  117248      ['embedding_1[0][0]',            \n",
      "                                 (None, 128),                     'lstm[0][1]',                   \n",
      "                                 (None, 128)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 454)    58566       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 383,862\n",
      "Trainable params: 383,862\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         45400     \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 128),             117248    \n",
      "                              (None, 128),                       \n",
      "                              (None, 128)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 162,648\n",
      "Trainable params: 162,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    45400       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 128),  117248      ['embedding_1[1][0]',            \n",
      "                                 (None, 128),                     'input_3[0][0]',                \n",
      "                                 (None, 128)]                     'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 454)    58566       ['lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 221,214\n",
      "Trainable params: 221,214\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder_model에는 \n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 문장으로 변환\n",
    "def convert_index_to_text(indexs, vocabulary): \n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for index in indexs:\n",
    "        if index == END_INDEX:\n",
    "            # 종료 인덱스면 중지\n",
    "            break;\n",
    "        elif vocabulary.get(index) is not None:\n",
    "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
    "            sentence += vocabulary[index]\n",
    "        else:\n",
    "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
    "            sentence += vocabulary[OOV_INDEX]\n",
    "            \n",
    "        # 빈칸 추가\n",
    "        sentence += ' '\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Epoch : 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9704/1801670847.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# 훈련 시작\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     history = model.fit([x_encoder, x_decoder],\n\u001b[0m\u001b[0;32m      7\u001b[0m                         \u001b[0my_decoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 에폭 반복\n",
    "for epoch in range(20):\n",
    "    print('Total Epoch :', epoch + 1)\n",
    "\n",
    "    # 훈련 시작\n",
    "    history = model.fit([x_encoder, x_decoder],\n",
    "                        y_decoder,\n",
    "                        epochs=100,\n",
    "                        batch_size=64,\n",
    "                        verbose=0)\n",
    "    \n",
    "    # 정확도와 손실 출력\n",
    "    print('accuracy :', history.history['acc'][-1])\n",
    "    print('loss :', history.history['loss'][-1])\n",
    "    \n",
    "    # 문장 예측 테스트\n",
    "    # (3 박 4일 놀러 가고 싶다) -> (여행 은 언제나 좋죠)\n",
    "    input_encoder = x_encoder[2].reshape(1, x_encoder[2].shape[0])\n",
    "    input_decoder = x_decoder[2].reshape(1, x_decoder[2].shape[0])\n",
    "    results = model.predict([input_encoder, input_decoder])\n",
    "    \n",
    "    # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "    # 1축을 기준으로 가장 높은 값의 위치를 구함\n",
    "    indexs = np.argmax(results[0], 1) \n",
    "    \n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "    print(sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 진행될수록 예측 문장이 제대로 생성되는 것을 볼 수 있습니다. 다만 여기서의 예측은 단순히 테스트를 위한 것이라, 인코더 입력과 디코더 입력 데이터가 동시에 사용됩니다. 아래 문장 생성에서는 예측 모델을 적용하기 때문에, 오직 인코더 입력 데이터만 집어 넣습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "encoder_model.save('./model/seq2seq_chatbot_encoder_model.h5')\n",
    "decoder_model.save('./model/seq2seq_chatbot_decoder_model.h5')\n",
    "\n",
    "# 인덱스 저장\n",
    "with open('./model/word_to_index.pkl', 'wb') as f:\n",
    "    pickle.dump(word_to_index, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model/index_to_word.pkl', 'wb') as f:\n",
    "    pickle.dump(index_to_word, f, pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 모델 파일 로드\n",
    "encoder_model = models.load_model('./model/seq2seq_chatbot_encoder_model.h5')\n",
    "decoder_model = models.load_model('./model/seq2seq_chatbot_decoder_model.h5')\n",
    "\n",
    "# 인덱스 파일 로드\n",
    "with open('./model/word_to_index.pkl', 'rb') as f:\n",
    "    word_to_index = pickle.load(f)\n",
    "with open('./model/index_to_word.pkl', 'rb') as f:\n",
    "    index_to_word = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측을 위한 입력 생성\n",
    "def make_predict_input(sentence):\n",
    "\n",
    "    sentences = []\n",
    "    sentences.append(sentence)\n",
    "    sentences = pos_tag(sentences)\n",
    "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
    "    \n",
    "    return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성\n",
    "def generate_text(input_seq):\n",
    "    \n",
    "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
    "    states = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 목표 시퀀스 초기화\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
    "    target_seq[0, 0] = STA_INDEX\n",
    "    \n",
    "    # 인덱스 초기화\n",
    "    indexs = []\n",
    "    \n",
    "    # 디코더 타임 스텝 반복\n",
    "    while 1:\n",
    "        # 디코더로 현재 타임 스텝 출력 구함\n",
    "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
    "        decoder_outputs, state_h, state_c = decoder_model.predict(\n",
    "                                                [target_seq] + states)\n",
    "\n",
    "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "        index = np.argmax(decoder_outputs[0, 0, :])\n",
    "        indexs.append(index)\n",
    "        \n",
    "        # 종료 검사\n",
    "        if index == END_INDEX or len(indexs) >= max_sequences:\n",
    "            break\n",
    "\n",
    "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = index\n",
    "        \n",
    "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제일 첫 단어는 START로 시작합니다. 그리고 출력으로 나온 인덱스를 디코더 입력으로 넣고 다시 예측을 반복합니다. 상태값을 받아 다시 입력으로 같이 넣는 것에 주의하시기 바랍니다. END 태그가 나오면 문장 생성을 종료합니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3, 423, 445,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('휴강이 좋아요')\n",
    "input_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저 도 '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋에 있는 문장과 똑같은 입력을 넣으니, 역시 정확히 일치하는 답변이 출력되었습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('')\n",
    "input_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저 도 '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최고의 강의입니다\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3, 204,   3,   3, 438,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('4박5일 욜로가려고요')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저 도 '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 데이터셋에 없던 '4박5일, 욜로'로 입력을 수정하니, 전혀 다른 문장이 출력되었습니다.<br>\n",
    "이는 우리가 데이터의 일부인 100개 문장만 학습했기 때문입니다.<br>\n",
    "데이터의 개수를 늘려서 훈련할수록 일반화 능력이 더욱 높아집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
