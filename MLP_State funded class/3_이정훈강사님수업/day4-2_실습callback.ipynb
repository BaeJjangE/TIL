{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b103a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ae9b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Train.csv\")\n",
    "valid = pd.read_csv(\"Valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "756f74bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relapse</th>\n",
       "      <th>CEA_Post</th>\n",
       "      <th>Lymphatic</th>\n",
       "      <th>Vascular</th>\n",
       "      <th>pStage</th>\n",
       "      <th>pT</th>\n",
       "      <th>pN</th>\n",
       "      <th>Perineural</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Relapse  CEA_Post  Lymphatic  Vascular  pStage  pT  pN  Perineural  Age\n",
       "0        0       0.0          0         0       4   2   2           0   73\n",
       "1        0       1.2          1         0       4   2   2           1   73"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09a521da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['pN'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "176e28e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relapse</th>\n",
       "      <th>CEA_Post</th>\n",
       "      <th>Lymphatic</th>\n",
       "      <th>Vascular</th>\n",
       "      <th>pStage</th>\n",
       "      <th>pT</th>\n",
       "      <th>pN</th>\n",
       "      <th>Perineural</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Relapse</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEA_Post</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lymphatic</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vascular</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pStage</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pT</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pN</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perineural</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Relapse  CEA_Post  Lymphatic  Vascular  pStage     pT     pN  \\\n",
       "Relapse        True     False      False     False   False  False  False   \n",
       "CEA_Post      False      True      False     False   False  False  False   \n",
       "Lymphatic     False     False       True     False   False  False  False   \n",
       "Vascular      False     False      False      True   False  False  False   \n",
       "pStage        False     False      False     False    True  False   True   \n",
       "pT            False     False      False     False   False   True  False   \n",
       "pN            False     False      False     False    True  False   True   \n",
       "Perineural    False     False      False     False   False  False  False   \n",
       "Age           False     False      False     False   False  False  False   \n",
       "\n",
       "            Perineural    Age  \n",
       "Relapse          False  False  \n",
       "CEA_Post         False  False  \n",
       "Lymphatic        False  False  \n",
       "Vascular         False  False  \n",
       "pStage           False  False  \n",
       "pT               False  False  \n",
       "pN               False  False  \n",
       "Perineural        True  False  \n",
       "Age              False   True  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.corr() > 0.7) # 다중공선성 비교 pStage랑 pN 중 pN 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed38bf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relapse</th>\n",
       "      <th>CEA_Post</th>\n",
       "      <th>Lymphatic</th>\n",
       "      <th>Vascular</th>\n",
       "      <th>pStage</th>\n",
       "      <th>pT</th>\n",
       "      <th>pN</th>\n",
       "      <th>Perineural</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Relapse</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163411</td>\n",
       "      <td>0.206385</td>\n",
       "      <td>0.208355</td>\n",
       "      <td>0.180064</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.204281</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>-0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEA_Post</th>\n",
       "      <td>0.163411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069175</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.121155</td>\n",
       "      <td>-0.050621</td>\n",
       "      <td>0.165132</td>\n",
       "      <td>0.201012</td>\n",
       "      <td>-0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lymphatic</th>\n",
       "      <td>0.206385</td>\n",
       "      <td>0.069175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228239</td>\n",
       "      <td>0.199909</td>\n",
       "      <td>-0.093983</td>\n",
       "      <td>0.319781</td>\n",
       "      <td>0.160543</td>\n",
       "      <td>-0.076858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vascular</th>\n",
       "      <td>0.208355</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.228239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129301</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>0.182302</td>\n",
       "      <td>0.250198</td>\n",
       "      <td>0.103310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pStage</th>\n",
       "      <td>0.180064</td>\n",
       "      <td>0.121155</td>\n",
       "      <td>0.199909</td>\n",
       "      <td>0.129301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.370512</td>\n",
       "      <td>0.770096</td>\n",
       "      <td>0.023054</td>\n",
       "      <td>0.099237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pT</th>\n",
       "      <td>0.056499</td>\n",
       "      <td>-0.050621</td>\n",
       "      <td>-0.093983</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>0.370512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.172943</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.166362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pN</th>\n",
       "      <td>0.204281</td>\n",
       "      <td>0.165132</td>\n",
       "      <td>0.319781</td>\n",
       "      <td>0.182302</td>\n",
       "      <td>0.770096</td>\n",
       "      <td>-0.172943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055978</td>\n",
       "      <td>-0.029191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perineural</th>\n",
       "      <td>0.130624</td>\n",
       "      <td>0.201012</td>\n",
       "      <td>0.160543</td>\n",
       "      <td>0.250198</td>\n",
       "      <td>0.023054</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.055978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.001398</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>-0.076858</td>\n",
       "      <td>0.103310</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>0.166362</td>\n",
       "      <td>-0.029191</td>\n",
       "      <td>0.040122</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Relapse  CEA_Post  Lymphatic  Vascular    pStage        pT  \\\n",
       "Relapse     1.000000  0.163411   0.206385  0.208355  0.180064  0.056499   \n",
       "CEA_Post    0.163411  1.000000   0.069175  0.056759  0.121155 -0.050621   \n",
       "Lymphatic   0.206385  0.069175   1.000000  0.228239  0.199909 -0.093983   \n",
       "Vascular    0.208355  0.056759   0.228239  1.000000  0.129301  0.042075   \n",
       "pStage      0.180064  0.121155   0.199909  0.129301  1.000000  0.370512   \n",
       "pT          0.056499 -0.050621  -0.093983  0.042075  0.370512  1.000000   \n",
       "pN          0.204281  0.165132   0.319781  0.182302  0.770096 -0.172943   \n",
       "Perineural  0.130624  0.201012   0.160543  0.250198  0.023054  0.014330   \n",
       "Age        -0.001398 -0.000181  -0.076858  0.103310  0.099237  0.166362   \n",
       "\n",
       "                  pN  Perineural       Age  \n",
       "Relapse     0.204281    0.130624 -0.001398  \n",
       "CEA_Post    0.165132    0.201012 -0.000181  \n",
       "Lymphatic   0.319781    0.160543 -0.076858  \n",
       "Vascular    0.182302    0.250198  0.103310  \n",
       "pStage      0.770096    0.023054  0.099237  \n",
       "pT         -0.172943    0.014330  0.166362  \n",
       "pN          1.000000    0.055978 -0.029191  \n",
       "Perineural  0.055978    1.000000  0.040122  \n",
       "Age        -0.029191    0.040122  1.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr() # Lymphatic, Vascular, pN 독립변수로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5238a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.loc[:, ['Lymphatic', 'Vascular', 'pN']]\n",
    "y_train = train.loc[:, 'Relapse']\n",
    "x_valid = valid.loc[:, ['Lymphatic', 'Vascular', 'pN']]\n",
    "y_valid = valid.loc[:, 'Relapse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e433ff21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lymphatic</th>\n",
       "      <th>Vascular</th>\n",
       "      <th>pN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lymphatic  Vascular  pN\n",
       "0          0         0   2\n",
       "1          1         0   2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "87fb7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af2d65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation=\"linear\", input_shape=(3,)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db6322f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 10)                40        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51\n",
      "Trainable params: 51\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "02735b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback\n",
    "# CheckPoint: Epoch 마다 validation 성능을 검증하여, best performance 일 경우 저장\n",
    "CP = ModelCheckpoint(filepath='./4-1_model/-{epoch:03d}-{loss:.4f}-{accuracy:.4f}.hdf5',\n",
    "            monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# \n",
    "# Learning Rate 줄여나가기\n",
    "# patience=3 loss값이 3번연속 떨어질시? factor=0.8 러닝레이트에 0.8을 곱해서 더 느리게 적용하게\n",
    "LR = ReduceLROnPlateau(monitor='loss',factor=0.8,patience=3, verbose=1, min_lr=1e-8)\n",
    "\n",
    "CALLBACK = [CP, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "01a142e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/13 [=>............................] - ETA: 2s - loss: 0.6442 - accuracy: 0.7500\n",
      "Epoch 1: val_loss improved from inf to 0.69323, saving model to ./4-1_model\\-001-0.7016-0.5714.hdf5\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.7016 - accuracy: 0.5714 - val_loss: 0.6932 - val_accuracy: 0.5714 - lr: 0.0100\n",
      "Epoch 2/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6845 - accuracy: 0.5625\n",
      "Epoch 2: val_loss improved from 0.69323 to 0.65559, saving model to ./4-1_model\\-002-0.6810-0.5944.hdf5\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.5944 - val_loss: 0.6556 - val_accuracy: 0.6429 - lr: 0.0100\n",
      "Epoch 3/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6973 - accuracy: 0.6250\n",
      "Epoch 3: val_loss improved from 0.65559 to 0.65167, saving model to ./4-1_model\\-003-0.6743-0.5867.hdf5\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.5867 - val_loss: 0.6517 - val_accuracy: 0.6429 - lr: 0.0100\n",
      "Epoch 4/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6637 - accuracy: 0.6562\n",
      "Epoch 4: val_loss improved from 0.65167 to 0.65015, saving model to ./4-1_model\\-004-0.6699-0.5867.hdf5\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.5867 - val_loss: 0.6502 - val_accuracy: 0.6327 - lr: 0.0100\n",
      "Epoch 5/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6368 - accuracy: 0.6875\n",
      "Epoch 5: val_loss improved from 0.65015 to 0.64604, saving model to ./4-1_model\\-005-0.6610-0.6403.hdf5\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6403 - val_loss: 0.6460 - val_accuracy: 0.6429 - lr: 0.0100\n",
      "Epoch 6/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6645 - accuracy: 0.6562\n",
      "Epoch 6: val_loss improved from 0.64604 to 0.63746, saving model to ./4-1_model\\-006-0.6568-0.5969.hdf5\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.5969 - val_loss: 0.6375 - val_accuracy: 0.6429 - lr: 0.0100\n",
      "Epoch 7/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6003 - accuracy: 0.7500\n",
      "Epoch 7: val_loss did not improve from 0.63746\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6378 - val_loss: 0.6475 - val_accuracy: 0.6429 - lr: 0.0100\n",
      "Epoch 8/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6693 - accuracy: 0.5938\n",
      "Epoch 8: val_loss improved from 0.63746 to 0.63729, saving model to ./4-1_model\\-008-0.6472-0.6403.hdf5\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6403 - val_loss: 0.6373 - val_accuracy: 0.6429 - lr: 0.0100\n",
      "Epoch 9/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6108 - accuracy: 0.7500\n",
      "Epoch 9: val_loss improved from 0.63729 to 0.63707, saving model to ./4-1_model\\-009-0.6507-0.6250.hdf5\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6250 - val_loss: 0.6371 - val_accuracy: 0.6429 - lr: 0.0100\n",
      "Epoch 10/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6847 - accuracy: 0.5625\n",
      "Epoch 10: val_loss did not improve from 0.63707\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6148 - val_loss: 0.6440 - val_accuracy: 0.6429 - lr: 0.0100\n",
      "Epoch 11/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5855 - accuracy: 0.6875\n",
      "Epoch 11: val_loss improved from 0.63707 to 0.63662, saving model to ./4-1_model\\-011-0.6516-0.5918.hdf5\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.5918 - val_loss: 0.6366 - val_accuracy: 0.6122 - lr: 0.0100\n",
      "Epoch 12/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6302 - accuracy: 0.6250\n",
      "Epoch 12: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6352 - val_loss: 0.6485 - val_accuracy: 0.6429 - lr: 0.0080\n",
      "Epoch 13/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7003 - accuracy: 0.5938\n",
      "Epoch 13: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6403 - val_loss: 0.6367 - val_accuracy: 0.6429 - lr: 0.0080\n",
      "Epoch 14/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5456 - accuracy: 0.7188\n",
      "Epoch 14: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6454 - val_loss: 0.6437 - val_accuracy: 0.6429 - lr: 0.0080\n",
      "Epoch 15/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6456 - accuracy: 0.5625\n",
      "Epoch 15: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6403 - val_loss: 0.6384 - val_accuracy: 0.6429 - lr: 0.0080\n",
      "Epoch 16/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5879 - accuracy: 0.7188\n",
      "Epoch 16: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6429 - val_loss: 0.6374 - val_accuracy: 0.6429 - lr: 0.0080\n",
      "Epoch 17/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6580 - accuracy: 0.5938\n",
      "Epoch 17: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6327 - val_loss: 0.6447 - val_accuracy: 0.6429 - lr: 0.0080\n",
      "Epoch 18/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5345 - accuracy: 0.8125\n",
      "Epoch 18: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.006399999558925629.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6429 - val_loss: 0.6386 - val_accuracy: 0.6429 - lr: 0.0080\n",
      "Epoch 19/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6256 - accuracy: 0.6250\n",
      "Epoch 19: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6429 - val_loss: 0.6385 - val_accuracy: 0.6429 - lr: 0.0064\n",
      "Epoch 20/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6887 - accuracy: 0.5000\n",
      "Epoch 20: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6429 - val_loss: 0.6414 - val_accuracy: 0.6429 - lr: 0.0064\n",
      "Epoch 21/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6433 - accuracy: 0.6875\n",
      "Epoch 21: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6429 - val_loss: 0.6399 - val_accuracy: 0.6429 - lr: 0.0064\n",
      "Epoch 22/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5946 - accuracy: 0.6562\n",
      "Epoch 22: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6429 - val_loss: 0.6451 - val_accuracy: 0.6429 - lr: 0.0064\n",
      "Epoch 23/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5917 - accuracy: 0.6562\n",
      "Epoch 23: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6250 - val_loss: 0.6427 - val_accuracy: 0.6429 - lr: 0.0064\n",
      "Epoch 24/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5199 - accuracy: 0.8438\n",
      "Epoch 24: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6429 - val_loss: 0.6420 - val_accuracy: 0.6429 - lr: 0.0064\n",
      "Epoch 25/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5907 - accuracy: 0.7500\n",
      "Epoch 25: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0051199994981288915.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6429 - val_loss: 0.6417 - val_accuracy: 0.6429 - lr: 0.0064\n",
      "Epoch 26/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7331 - accuracy: 0.5312\n",
      "Epoch 26: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6352 - val_loss: 0.6474 - val_accuracy: 0.6020 - lr: 0.0051\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5276 - accuracy: 0.7812\n",
      "Epoch 27: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6454 - val_loss: 0.6394 - val_accuracy: 0.6429 - lr: 0.0051\n",
      "Epoch 28/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5512 - accuracy: 0.7812\n",
      "Epoch 28: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.6429 - val_loss: 0.6426 - val_accuracy: 0.6429 - lr: 0.0051\n",
      "Epoch 29/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5877 - accuracy: 0.7188\n",
      "Epoch 29: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6327 - val_loss: 0.6482 - val_accuracy: 0.6020 - lr: 0.0051\n",
      "Epoch 30/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6735 - accuracy: 0.5938\n",
      "Epoch 30: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.004095999523997307.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6327 - val_loss: 0.6432 - val_accuracy: 0.6429 - lr: 0.0051\n",
      "Epoch 31/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6512 - accuracy: 0.6250\n",
      "Epoch 31: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6429 - val_loss: 0.6412 - val_accuracy: 0.6429 - lr: 0.0041\n",
      "Epoch 32/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5284 - accuracy: 0.6875\n",
      "Epoch 32: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6429 - val_loss: 0.6421 - val_accuracy: 0.6429 - lr: 0.0041\n",
      "Epoch 33/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5676 - accuracy: 0.6250\n",
      "Epoch 33: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0032767996191978457.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6429 - val_loss: 0.6421 - val_accuracy: 0.6429 - lr: 0.0041\n",
      "Epoch 34/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6634 - accuracy: 0.6250\n",
      "Epoch 34: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6429 - val_loss: 0.6420 - val_accuracy: 0.6429 - lr: 0.0033\n",
      "Epoch 35/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6173 - accuracy: 0.6562\n",
      "Epoch 35: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6429 - val_loss: 0.6440 - val_accuracy: 0.6429 - lr: 0.0033\n",
      "Epoch 36/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6444 - accuracy: 0.6562\n",
      "Epoch 36: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0026214396581053737.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6429 - val_loss: 0.6423 - val_accuracy: 0.6429 - lr: 0.0033\n",
      "Epoch 37/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5605 - accuracy: 0.6875\n",
      "Epoch 37: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6429 - val_loss: 0.6412 - val_accuracy: 0.6429 - lr: 0.0026\n",
      "Epoch 38/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7678 - accuracy: 0.5000\n",
      "Epoch 38: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6429 - val_loss: 0.6417 - val_accuracy: 0.6429 - lr: 0.0026\n",
      "Epoch 39/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6231 - accuracy: 0.6562\n",
      "Epoch 39: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0020971518009901048.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6429 - val_loss: 0.6425 - val_accuracy: 0.6429 - lr: 0.0026\n",
      "Epoch 40/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6218 - accuracy: 0.7500\n",
      "Epoch 40: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6429 - val_loss: 0.6423 - val_accuracy: 0.6429 - lr: 0.0021\n",
      "Epoch 41/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7023 - accuracy: 0.5938\n",
      "Epoch 41: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6429 - val_loss: 0.6414 - val_accuracy: 0.6429 - lr: 0.0021\n",
      "Epoch 42/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6415 - accuracy: 0.6250\n",
      "Epoch 42: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0016777213662862779.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6429 - val_loss: 0.6416 - val_accuracy: 0.6429 - lr: 0.0021\n",
      "Epoch 43/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6281 - accuracy: 0.6250\n",
      "Epoch 43: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6429 - val_loss: 0.6407 - val_accuracy: 0.6429 - lr: 0.0017\n",
      "Epoch 44/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6559 - accuracy: 0.6250\n",
      "Epoch 44: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6429 - val_loss: 0.6412 - val_accuracy: 0.6429 - lr: 0.0017\n",
      "Epoch 45/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6771 - accuracy: 0.5625\n",
      "Epoch 45: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6431 - val_accuracy: 0.6429 - lr: 0.0017\n",
      "Epoch 46/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6553 - accuracy: 0.6562\n",
      "Epoch 46: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6327 - val_loss: 0.6460 - val_accuracy: 0.6429 - lr: 0.0017\n",
      "Epoch 47/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6111 - accuracy: 0.6562\n",
      "Epoch 47: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6403 - val_loss: 0.6468 - val_accuracy: 0.6429 - lr: 0.0017\n",
      "Epoch 48/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7491 - accuracy: 0.5312\n",
      "Epoch 48: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0013421771116554739.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6454 - val_loss: 0.6439 - val_accuracy: 0.6429 - lr: 0.0017\n",
      "Epoch 49/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6572 - accuracy: 0.5312\n",
      "Epoch 49: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6429 - val_loss: 0.6418 - val_accuracy: 0.6429 - lr: 0.0013\n",
      "Epoch 50/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6291 - accuracy: 0.6875\n",
      "Epoch 50: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6429 - val_loss: 0.6423 - val_accuracy: 0.6429 - lr: 0.0013\n",
      "Epoch 51/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7117 - accuracy: 0.5312\n",
      "Epoch 51: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.001073741726577282.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6429 - val_loss: 0.6445 - val_accuracy: 0.6429 - lr: 0.0013\n",
      "Epoch 52/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6854 - accuracy: 0.6250\n",
      "Epoch 52: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6429 - val_loss: 0.6444 - val_accuracy: 0.6429 - lr: 0.0011\n",
      "Epoch 53/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6336 - accuracy: 0.5938\n",
      "Epoch 53: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6378 - val_loss: 0.6458 - val_accuracy: 0.6429 - lr: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6307 - accuracy: 0.5938\n",
      "Epoch 54: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0008589933626353742.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6378 - val_loss: 0.6454 - val_accuracy: 0.6429 - lr: 0.0011\n",
      "Epoch 55/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5732 - accuracy: 0.7188\n",
      "Epoch 55: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6429 - val_loss: 0.6451 - val_accuracy: 0.6429 - lr: 8.5899e-04\n",
      "Epoch 56/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6599 - accuracy: 0.6250\n",
      "Epoch 56: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6429 - val_loss: 0.6449 - val_accuracy: 0.6429 - lr: 8.5899e-04\n",
      "Epoch 57/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6157 - accuracy: 0.5938\n",
      "Epoch 57: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0006871947087347508.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6429 - val_loss: 0.6445 - val_accuracy: 0.6429 - lr: 8.5899e-04\n",
      "Epoch 58/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6260 - accuracy: 0.5625\n",
      "Epoch 58: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 6.8719e-04\n",
      "Epoch 59/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6067 - accuracy: 0.6875\n",
      "Epoch 59: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6429 - val_loss: 0.6429 - val_accuracy: 0.6429 - lr: 6.8719e-04\n",
      "Epoch 60/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5552 - accuracy: 0.7500\n",
      "Epoch 60: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0005497557576745749.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 0.6429 - val_accuracy: 0.6429 - lr: 6.8719e-04\n",
      "Epoch 61/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5850 - accuracy: 0.6562\n",
      "Epoch 61: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6429 - val_loss: 0.6435 - val_accuracy: 0.6429 - lr: 5.4976e-04\n",
      "Epoch 62/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6878 - accuracy: 0.5312\n",
      "Epoch 62: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6429 - val_loss: 0.6432 - val_accuracy: 0.6429 - lr: 5.4976e-04\n",
      "Epoch 63/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5919 - accuracy: 0.7500\n",
      "Epoch 63: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0004398046061396599.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 0.6431 - val_accuracy: 0.6429 - lr: 5.4976e-04\n",
      "Epoch 64/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6640 - accuracy: 0.5938\n",
      "Epoch 64: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6429 - val_loss: 0.6435 - val_accuracy: 0.6429 - lr: 4.3980e-04\n",
      "Epoch 65/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6483 - accuracy: 0.5312\n",
      "Epoch 65: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6431 - val_accuracy: 0.6429 - lr: 4.3980e-04\n",
      "Epoch 66/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7756 - accuracy: 0.5000\n",
      "Epoch 66: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00035184368025511505.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 0.6433 - val_accuracy: 0.6429 - lr: 4.3980e-04\n",
      "Epoch 67/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5584 - accuracy: 0.7812\n",
      "Epoch 67: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 0.6433 - val_accuracy: 0.6429 - lr: 3.5184e-04\n",
      "Epoch 68/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6634 - accuracy: 0.5000\n",
      "Epoch 68: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6429 - val_loss: 0.6431 - val_accuracy: 0.6429 - lr: 3.5184e-04\n",
      "Epoch 69/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5439 - accuracy: 0.7188\n",
      "Epoch 69: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0002814749488607049.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6429 - val_loss: 0.6434 - val_accuracy: 0.6429 - lr: 3.5184e-04\n",
      "Epoch 70/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5807 - accuracy: 0.7500\n",
      "Epoch 70: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 0.6433 - val_accuracy: 0.6429 - lr: 2.8147e-04\n",
      "Epoch 71/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7051 - accuracy: 0.5938\n",
      "Epoch 71: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 0.6434 - val_accuracy: 0.6429 - lr: 2.8147e-04\n",
      "Epoch 72/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6769 - accuracy: 0.6250\n",
      "Epoch 72: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0002251799684017897.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6436 - val_accuracy: 0.6429 - lr: 2.8147e-04\n",
      "Epoch 73/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6484 - accuracy: 0.5625\n",
      "Epoch 73: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 0.6439 - val_accuracy: 0.6429 - lr: 2.2518e-04\n",
      "Epoch 74/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6588 - accuracy: 0.5938\n",
      "Epoch 74: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6429 - val_loss: 0.6435 - val_accuracy: 0.6429 - lr: 2.2518e-04\n",
      "Epoch 75/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.4801 - accuracy: 0.8750\n",
      "Epoch 75: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0001801439793780446.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6436 - val_accuracy: 0.6429 - lr: 2.2518e-04\n",
      "Epoch 76/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6098 - accuracy: 0.6875\n",
      "Epoch 76: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 1.8014e-04\n",
      "Epoch 77/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6098 - accuracy: 0.7188\n",
      "Epoch 77: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 0.6439 - val_accuracy: 0.6429 - lr: 1.8014e-04\n",
      "Epoch 78/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6244 - accuracy: 0.6562\n",
      "Epoch 78: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.00014411518350243568.\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6436 - val_accuracy: 0.6429 - lr: 1.8014e-04\n",
      "Epoch 79/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6551 - accuracy: 0.5312\n",
      "Epoch 79: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6433 - val_accuracy: 0.6429 - lr: 1.4412e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6223 - accuracy: 0.6250\n",
      "Epoch 80: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6433 - val_accuracy: 0.6429 - lr: 1.4412e-04\n",
      "Epoch 81/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6329 - accuracy: 0.6562\n",
      "Epoch 81: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.00011529214680194855.\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6433 - val_accuracy: 0.6429 - lr: 1.4412e-04\n",
      "Epoch 82/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6477 - accuracy: 0.5938\n",
      "Epoch 82: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6429 - val_loss: 0.6433 - val_accuracy: 0.6429 - lr: 1.1529e-04\n",
      "Epoch 83/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6031 - accuracy: 0.5938\n",
      "Epoch 83: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6433 - val_accuracy: 0.6429 - lr: 1.1529e-04\n",
      "Epoch 84/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7230 - accuracy: 0.5000\n",
      "Epoch 84: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 9.223371744155885e-05.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6434 - val_accuracy: 0.6429 - lr: 1.1529e-04\n",
      "Epoch 85/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6055 - accuracy: 0.7188\n",
      "Epoch 85: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6435 - val_accuracy: 0.6429 - lr: 9.2234e-05\n",
      "Epoch 86/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6545 - accuracy: 0.5625\n",
      "Epoch 86: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6436 - val_accuracy: 0.6429 - lr: 9.2234e-05\n",
      "Epoch 87/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6470 - accuracy: 0.5625\n",
      "Epoch 87: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 7.378697628155351e-05.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6436 - val_accuracy: 0.6429 - lr: 9.2234e-05\n",
      "Epoch 88/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6491 - accuracy: 0.6250\n",
      "Epoch 88: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6436 - val_accuracy: 0.6429 - lr: 7.3787e-05\n",
      "Epoch 89/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6341 - accuracy: 0.5625\n",
      "Epoch 89: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6436 - val_accuracy: 0.6429 - lr: 7.3787e-05\n",
      "Epoch 90/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6474 - accuracy: 0.6562\n",
      "Epoch 90: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 5.9029582189396024e-05.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6437 - val_accuracy: 0.6429 - lr: 7.3787e-05\n",
      "Epoch 91/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6577 - accuracy: 0.5000\n",
      "Epoch 91: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6437 - val_accuracy: 0.6429 - lr: 5.9030e-05\n",
      "Epoch 92/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5343 - accuracy: 0.8125\n",
      "Epoch 92: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 5.9030e-05\n",
      "Epoch 93/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6414 - accuracy: 0.6562\n",
      "Epoch 93: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 4.722366575151682e-05.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 5.9030e-05\n",
      "Epoch 94/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6879 - accuracy: 0.6250\n",
      "Epoch 94: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 4.7224e-05\n",
      "Epoch 95/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6073 - accuracy: 0.6562\n",
      "Epoch 95: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 4.7224e-05\n",
      "Epoch 96/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5786 - accuracy: 0.6562\n",
      "Epoch 96: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 3.777893143706024e-05.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 4.7224e-05\n",
      "Epoch 97/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6271 - accuracy: 0.6875\n",
      "Epoch 97: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 3.7779e-05\n",
      "Epoch 98/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5873 - accuracy: 0.7188\n",
      "Epoch 98: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 3.7779e-05\n",
      "Epoch 99/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6251 - accuracy: 0.6562\n",
      "Epoch 99: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.022314631380141e-05.\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 3.7779e-05\n",
      "Epoch 100/100\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5848 - accuracy: 0.7188\n",
      "Epoch 100: val_loss did not improve from 0.63662\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6429 - val_loss: 0.6438 - val_accuracy: 0.6429 - lr: 3.0223e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23602d3e940>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=32, shuffle=True, epochs=100, \n",
    "          validation_data=(x_valid, y_valid), callbacks=CALLBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d7c969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./4-1_model/-011-0.6516-0.5918.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80fc9475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39807466],\n",
       "       [0.3643803 ],\n",
       "       [0.39807466],\n",
       "       [0.24913564],\n",
       "       [0.5240652 ],\n",
       "       [0.48835883],\n",
       "       [0.24913564],\n",
       "       [0.5240652 ],\n",
       "       [0.48835883],\n",
       "       [0.48835883],\n",
       "       [0.48835883],\n",
       "       [0.48835883],\n",
       "       [0.48835883],\n",
       "       [0.48835883],\n",
       "       [0.48835883],\n",
       "       [0.48835883],\n",
       "       [0.27681434],\n",
       "       [0.39807466],\n",
       "       [0.24913564],\n",
       "       [0.30631357],\n",
       "       [0.24913564],\n",
       "       [0.24913564],\n",
       "       [0.24913564],\n",
       "       [0.35585552],\n",
       "       [0.45277086],\n",
       "       [0.3643803 ],\n",
       "       [0.35585552],\n",
       "       [0.33196512],\n",
       "       [0.35585552],\n",
       "       [0.39807466],\n",
       "       [0.24913564],\n",
       "       [0.24913564],\n",
       "       [0.48835883],\n",
       "       [0.27681434],\n",
       "       [0.48835883],\n",
       "       [0.5240652 ],\n",
       "       [0.33196512],\n",
       "       [0.27681434],\n",
       "       [0.27681434],\n",
       "       [0.5240652 ],\n",
       "       [0.27681434],\n",
       "       [0.3643803 ],\n",
       "       [0.5240652 ],\n",
       "       [0.48835883],\n",
       "       [0.48835883],\n",
       "       [0.24913564],\n",
       "       [0.33196512],\n",
       "       [0.24913564],\n",
       "       [0.5240652 ],\n",
       "       [0.45277086],\n",
       "       [0.5240652 ],\n",
       "       [0.24913564],\n",
       "       [0.3643803 ],\n",
       "       [0.27681434],\n",
       "       [0.39807466],\n",
       "       [0.48835883],\n",
       "       [0.39807466],\n",
       "       [0.35585552],\n",
       "       [0.5240652 ],\n",
       "       [0.24913564],\n",
       "       [0.33196512],\n",
       "       [0.45277086],\n",
       "       [0.27681434],\n",
       "       [0.24913564],\n",
       "       [0.39807466],\n",
       "       [0.3643803 ],\n",
       "       [0.30631357],\n",
       "       [0.5595272 ],\n",
       "       [0.35585552],\n",
       "       [0.5240652 ],\n",
       "       [0.27681434],\n",
       "       [0.48835883],\n",
       "       [0.24913564],\n",
       "       [0.5240652 ],\n",
       "       [0.45277086],\n",
       "       [0.39807466],\n",
       "       [0.5240652 ],\n",
       "       [0.33196512],\n",
       "       [0.33196512],\n",
       "       [0.33196512],\n",
       "       [0.33196512],\n",
       "       [0.33196512],\n",
       "       [0.45277086],\n",
       "       [0.5240652 ],\n",
       "       [0.33196512],\n",
       "       [0.24913564],\n",
       "       [0.48835883],\n",
       "       [0.35585552],\n",
       "       [0.48835883],\n",
       "       [0.35585552],\n",
       "       [0.48835883],\n",
       "       [0.45277086],\n",
       "       [0.33196512],\n",
       "       [0.35585552],\n",
       "       [0.48835883],\n",
       "       [0.5240652 ],\n",
       "       [0.24913564],\n",
       "       [0.33196512]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "12fb3f9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_valid, model.predict(x_valid), 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c4ce838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52f8320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     0\n",
       "     ..\n",
       "93    0\n",
       "94    1\n",
       "95    0\n",
       "96    0\n",
       "97    0\n",
       "Name: Relapse, Length: 98, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "63d0c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalPrediction = pd.DataFrame({\n",
    "    'Label': y_valid,\n",
    "    'Prediction': model.predict(x_valid)[:,0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c6dc6db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Label', ylabel='Prediction'>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=FinalPrediction, x='Label', y='Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0842077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a0182256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0375bc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6462719298245614\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_valid, model.predict(x_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bdac5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# ROC curve 시각화\n",
    "Labels = y_valid\n",
    "pred = model.predict(x_valid)\n",
    "fpr, tpr, _ = metrics.roc_curve(y_valid,  pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c0c3f51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAApbElEQVR4nO3dd3xV9f3H8dcngbCH7IS9lyQoERx1YVVUcLR1j4qt1Lrqw1q1avVX7bCttdUOLW5bK3VVTVAcrasqMoSEgIIRZCVA2GGErM/vj3uxaQzhAjk59+a+n49HHrnnnnPvfR/G+dyzPl9zd0REJHmlhB1ARETCpUIgIpLkVAhERJKcCoGISJJTIRARSXLNwg6wr7p06eL9+vULO4aISEKZO3fuenfvWte8hCsE/fr1Y86cOWHHEBFJKGa2fE/zdGhIRCTJqRCIiCQ5FQIRkSSnQiAikuRUCEREklxghcDMHjWzdWZWsIf5Zmb3m1mhmeWb2aFBZRERkT0Lco/gcWBCPfNPAQZHf6YADwSYRURE9iCwQuDu7wIb61nkDOBJj5gJdDSz9KDyiIgkqtWbdzL13c/54PP1gbx/mDeU9QRW1pheFX2uuPaCZjaFyF4Dffr0aZRwIiJhWre1jOkLisnNL2bu8k0AfP+4gRw5sEuDf1aYhcDqeK7OUXLcfSowFSA7O1sj6YhIk7RxezmvFhSTk1fER8s24g7DerTjRycPZWJmOn07twnkc8MsBKuA3jWmewFFIWUREQnFlp0VvLZwDbn5xbxfuJ6qamdg1zZcO34wk7LSGdStXeAZwiwELwNXm9k0YBywxd2/clhIRKSp2barkn99spacvCLeXbKe8qpqendqxfeOGcDEzAyGp7fDrK6DJsEIrBCY2dPAcUAXM1sF3AE0B3D3B4FXgFOBQmAHMDmoLCIiYSurqOLfn64jN7+If32yjl2V1aR3aMklR/RlUlYGmb06NOrGv6bACoG7n7+X+Q5cFdTni4iEbVdlFe8tWU9OfhFvLlrL9vIqurRN47zDejMxK4MxfQ4iJSWcjX9NCdeGWkQknlVUVfPB5xvIzStixsI1lJZV0rF1c04fncGkzAzGDehMahxs/GtSIRAROUBV1c6sZRvJyS9iRsEaNm4vp12LZpw0sgcTs9L52qAuNE+N344+KgQiIvuhutqZt3ITOXnFTF9QTEnpLlo1T+XrI7ozKTOdY4Z0pWXz1LBjxkSFQEQkRu7OgtVbyM0vZnp+Mas37yStWQrjh3ZjYlY644d1o3Va4m1WEy+xiEgjcncWry0lJ6+I3Pxilm/YQfNU4+jBXbnh5CF8fXh32rVsHnbMA6JCICJSh89LtpGbV0xOfhGF67aRYnDUoC5cedxATh7Zg46t08KO2GBUCEREolZu3EFOfhG5ecUsKt6KGRzWrxN3nXkwpxzcgy5tW4QdMRAqBCKS1Iq37GR6fjE5+cXkrdwMwCF9OvKTiSM4bVQ6PTq0DDdgI1AhEJGkU1K6i1cLisnNK2bWF5Fu+SMz2nPzKcM4bVQ6vTu1Djlh41IhEJGksHlHOTMK1pCTX8SHn2+g2mFwt7Zcf+IQJmamM6Br27AjhkaFQESarK1lFbyxcC25+UW899l6Kqudfp1bc9Xxg5iYmcHQHsF39kwEKgQi0qTsKK/kX5+sIyeviLeXlFBeWU3Pjq34ztf6MzEzg4N7tg+tuVu8UiEQkYRXVlHF24tLvuzsubOiim7tWnDB2D5MysrgkN4d46K5W7xSIRCRhFReWc37hevJySvi9UVr2barkk5t0vjGoT2ZmJnB2P6d4q65W7xSIRCRhFFZVc3MpRvJzS/i1YI1bNlZQfuWzTjl4B5MysrgyIGdaRbHzd3ilQqBiMS16mpnzvJN5OQV8WpBMeu3ldMmbXdztwyOHtKFFs0So7lbvFIhEJG44+7krdpCTl4R0/OLWbO1jBbNUjhheDcmZWZw/LBuCdPZMxGoEIhIXHB3FhVvJTe/mNz8IlZu3EnzVOPYId348anDOGF4d9q20CYrCPpTFZFQfba2lJzoxn9pyXZSU4yjBnXh2vGDOWlkDzq0SuzOnolAhUBEGt3yDdvJzS8mJ6+IT9eUYgaH9+/Md77Wn1MOTqdTm6bT2TMRqBCISKNYvXkn0/MjPf3zV20BYEzfg/i/SSM4dVQ63do3/eZu8UqFQEQCs660jFeinT3nLt8EQGavDtxy6jBOy8ygZ8dWIScUUCEQkQa2cXu0uVteETOXbcAdhvVox49OHsppo9Lp16VN2BGlFhUCETlgW3ZW8PrCNeTmF/OfwvVUVTsDurbhmvGDmZSZzuDuau4Wz1QIROR/bNxeTt6qzbj7XpfdtL2CVwvW8O6SEsqrqundqRVTjhnAxMx0RqSruVuiUCEQkTq/0ceqR/uWXHJEXyZmZZDVq4M2/glIhUAkSW3fVcmbn6wlJ6/4y2/0PTu24vKjB3D80K4x3bnbonkKQ7q1U2fPBKdCIJJEyiqqeOvTdeTmF/OvT9dSVlFN9/YtuPiIvkzMTGd07476Rp+EVAhEmrjyymre+6yEnLwi3li0lu3lVXRpm8bZY3ozKSuD7L4H6Rt9klMhEGmCKquq+eDzDeTmFzGjYA1byyrp0Ko5k7IymJiZweEDOqlds3xJhUCkiaiqdmZ/sZGcvMjGf8P2ctq2aMZJI7ozKSuDowZ1Ia2ZNv7yVYEWAjObANwHpAIPu/vdteZ3AP4G9IlmucfdHwsyk0hT4u7MW7mZnLwiXllQzNqtu2jVPJUThndjYmYGx8V40leSW2CFwMxSgT8BJwKrgNlm9rK7L6qx2FXAInefZGZdgcVm9pS7lweVSyTRuTsLi7aSk19Ebl4xqzfvJK1ZCscN6cqkrAxOGN6N1mna2ZfYBfmvZSxQ6O5LAcxsGnAGULMQONDOIpcptAU2ApUBZhJJWEvWlpKTF2natmz9dpqlGEcP7sL1Jw7hxJHdad9S7Zpl/wRZCHoCK2tMrwLG1Vrmj8DLQBHQDjjX3atrv5GZTQGmAPTp0yeQsCLxaNn67eTmFZGTX8SStdtIMThiYGe+d8wATh7Zg4PUrlkaQJCFoK7r0WrfrngyMB8YDwwE3jCz99x96/+8yH0qMBUgOzs79lseRRLQyo07mL4gMlBLwerIf4Wx/Tpx5xkjOeXgdLq2axFyQmlqgiwEq4DeNaZ7EfnmX9Nk4G6PNDUpNLNlwDBgVoC5ROLO2q1lTM8vJie/iHkrNgOQ1bsjt502nNMy00nvoHbNEpwgC8FsYLCZ9QdWA+cBF9RaZgVwAvCemXUHhgJLA8wkEjfWb9vFqwVryM0rYtYXG3GHEentuXHCUCaOyqBP59ZhR5QkEVghcPdKM7saeI3I5aOPuvtCM7siOv9B4C7gcTNbQORQ0k3uvj6oTCJh27KjghkLi8nNL+aDzzdQVe0M6taW604YwsSsdAZ2bRt2RElCgV5j5u6vAK/Ueu7BGo+LgJOCzCASttKyii+bu733WQkVVU7fzq254tgBTMrKYGj3durvI6HSxcYiAVm+YTu/eW0xbyxay67KajI6tGTyUf2ZmJnOqJ5q1yzxQ4VApIHtqqxi6jtL+eNbhTRPTeH8sX2YlJXOIb3V3E3ikwqBSAP6oHA9t71UwNKS7ZyWmc7tE0fQvX3LsGOJ1EuFQKQBlJTu4ufTF/Hi/CL6dm7NE5eN5dghXcOOJRITFQKRA1BV7fx91gp+PeNTdlVUc+34QVx5/CA1epOEokIgsp8KVm/h1hcLyFu5mSMHduauMw/W5Z+SkFQIRPZRaVkF976xhCc++IJObdK477zRnJ6VoauAJGGpEIjEyN2ZvqCYu3IXsa50FxeN68sNJw+lQyt1/ZTEpkIgEoPlG7bzk5cW8u6SEkZmtOcvF2czunfHsGOJNAgVApF67Kqs4i/RewLSUlO4Y9IILj68r8b7lSYl5kJgZm3cfXuQYUTiyQeF67ntxQKWrtc9AdK07bUQmNmRwMNERhDrY2ZZwPfc/cqgw4mEQfcESLKJZY/gd0QGkHkZwN3zzOyYQFOJhED3BEiyiunQkLuvrHVpXFUwcUTCUbB6C7f+cwF5q7bongBJOrEUgpXRw0NuZmnAtcAnwcYSaRylZRX89vUlPPmh7gmQ5BVLIbgCuI/IYPSrgNcBnR+QhLb7noA7cxZRsk33BEhyi6UQDHX3C2s+YWZHAe8HE0kkeA+88zm/nrGYkRntmXqJ7gmQ5BbLxdB/iPE5kYRQuK6U37/xGRNG9uClq45SEZCkt8c9AjM7AjgS6Gpm19eY1Z7IGMQiCaeq2rnxuXxat0jlrjMP1o1hItR/aCiNyL0DzYB2NZ7fCnwryFAiQXnywy/4eMVm7j0ni67tWoQdRyQu7LEQuPs7wDtm9ri7L2/ETCKBWLlxB7+esZjjhnblrEN6hh1HJG7EcrJ4h5n9BhgJfHl/vbuPDyyVSANzd378wgJSDH5+1ihdHipSQywHSJ8CPgX6Az8FvgBmB5hJpME9O2cV/ylcz82nDqdnx1ZhxxGJK7EUgs7u/ghQ4e7vuPtlwOEB5xJpMGu3lnHX9EWM7deJC8f2CTuOSNyJ5dBQRfR3sZmdBhQBvYKLJNJw3J2fvFhAeWU1d39zFCkpOiQkUlssheBnZtYB+CGR+wfaA9cFGUqkobyyYA2vL1rLzacMY4B6B4nUaa+FwN1zow+3AMfDl3cWi8S1TdvLuePlAkb17MB3v9Y/7Dgicau+G8pSgXOI9Bia4e4FZjYRuAVoBRzSOBFF9s9duYvYvKOCJy8bpxvHROpR3x7BI0BvYBZwv5ktB44Abnb3Fxshm8h+e2vxOl6Yt5prxg9iREb7sOOIxLX6CkE2kOnu1WbWElgPDHL3NY0TTWT/lJZVcOsLCxjUrS1Xjx8UdhyRuFff/nK5u1cDuHsZsGRfi4CZTTCzxWZWaGY372GZ48xsvpktNLN39uX9Rery6xmLKd5axq++mUmLZmqLJbI39e0RDDOz/OhjAwZGpw1wd8+s742j5xj+BJxIZByD2Wb2srsvqrFMR+DPwAR3X2Fm3fZ/VSTZ7aqsYnp+MX+duZzLjurPmL4HhR1JJCHUVwiGH+B7jwUK3X0pgJlNA84AFtVY5gLgBXdfAeDu6w7wMyXJVFZV88HnG8jJK+K1hWvYWlbJoG5tueHkIWFHE0kY9TWdO9BGcz2BlTWmVwHjai0zBGhuZm8T6XB6n7s/WfuNzGwKMAWgTx/dGZrsqqqdWcs2kptfxKsFa9i4vZy2LZpx0sjuTMrM4KhBXUhrpquERGIV0+D1+6muWzi9js8fA5xA5JLUD81sprsv+Z8XuU8FpgJkZ2fXfg9JAu7Oxys2k5tfxPT8YtaV7qJV81ROGN6NSVkZHDukKy2b63yAyP4IshCsInL56W69iLSnqL3MenffDmw3s3eBLGAJkvTcnYVFW8nJKyI3v5jVm3eS1iyF44Z0ZVJWBicM70brtCD/CYskh5j+F5lZK6CPuy/eh/eeDQw2s/7AauA8IucEanoJ+KOZNSMyEM444Hf78BnSBC1eU0pufhE5eUV8sWEHzVKMowd34foTh3DiyO60b6kB5kUa0l4LgZlNAu4hsqHub2ajgTvd/fT6XufulWZ2NfAakaEtH3X3hWZ2RXT+g+7+iZnNAPKBauBhdy84oDWShLS0ZBu5+cXk5hexZO02UgyOGNiZK44dyMkje3BQm7SwI4o0WeZe/yF3M5sLjAfedvdDos/l7+3y0aBkZ2f7nDlzwvhoaWArN+5g+oJicvKKWFi0FYCx/ToxMSudUw5O11CSIg3IzOa6e3Zd82I5NFTp7ls0opM0hDVbypi+IPLNf96KzQBk9e7IbacN57TMdNI7aNAYkcYWSyEoMLMLgFQzGwxcC3wQbCxpStZv28WrBWvIySti9hcbcYcR6e25ccJQJo7KoE/n1mFHFElqsRSCa4BbgV3A34kc8/9ZkKEk8W3ZUcGMhcXk5hfzfuF6qh0Gdm3DD04YzMTMDAZ109gAIvEilkIw1N1vJVIMRPZq/srNXPzIR5SWVdKnU2u+f9xAJmZmMKxHOw0aLxKHYikE95pZOvAsMM3dFwacSRJYweotXPLIRxzUOo2/fmccWb06aOMvEuf2eh++ux8PHAeUAFPNbIGZ3RZ0MEk8nxRv5aJHPqJdy+b8/fJxjO7dUUVAJAHE1JDF3de4+/3AFcB84PYgQ0ni+WxtKRc9/BEtm6Xy9OWH0+sgnQAWSRR7LQRmNtzM/s/MCoA/ErliqFfgySRhfF6yjfMf+oiUFOPpKYfrKiCRBBPLOYLHgKeBk9y9dq8gSXLLN2zngodm4u5Mm3I4/bu0CTuSiOyjvRYCdz+8MYJI4lm5cQcXPPQR5ZXVPD3lcAZ1axd2JBHZD3ssBGb2jLufY2YL+N/20TGNUCZNW9HmnVzw8Ey27ark75ePY1gPDRAvkqjq2yP4QfT3xMYIIolj7dYyLnhoJpu3V/DU5eMYmdEh7EgicgD2eLLY3YujD6909+U1f4ArGyeexJuS0l1c8NBMSkp38fhlY8ns1THsSCJygGK5fPTEOp47paGDSPzbsG0XFz48k6LNZTw2eawGhxdpIuo7R/B9It/8B5hZfo1Z7YD3gw4m8WXzjnIuemQWyzfs4LFLD2Ns/05hRxKRBlLfOYK/A68CvwRurvF8qbtvDDSVxJUtOyu4+JFZfL5uGw9/O5sjB3UJO5KINKD6CoG7+xdmdlXtGWbWScUgOZSWVXDpY7P4dM1W/nLxGI4Z0jXsSCLSwPa2RzARmEvk8tGaTWMcGBBgLokD23dVctnjs1mwagt/vvBQxg/rHnYkEQnAHguBu0+M/u7feHEkXpRVVPHdJ+Ywd/km/nD+oZw0skfYkUQkILH0GjrKzNpEH19kZveaWZ/go0mY7n71Uz5cuoF7zxnNaZnpYccRkQDFcvnoA8AOM8sCbgSWA38NNJWE6u3F63j8gy+YfFQ/zjykZ9hxRCRgsRSCSnd34AzgPne/j8glpNIEbdi2ixuezWdo93bcNGFY2HFEpBHE0n201Mx+DFwMHG1mqUDzYGNJGNydm57PZ2tZBX/77lhaNk8NO5KINIJY9gjOJTJw/WXuvgboCfwm0FQSir/PWsGbn6zj5gnD1EROJInEMlTlGuApoIOZTQTK3P3JwJNJoypct427chdx9OAuXHpkv7DjiEgjiuWqoXOAWcDZwDnAR2b2raCDSeMpr6zmun/Mo1XzVH57dhYpKRpnWCSZxHKO4FbgMHdfB2BmXYE3geeCDCaN5943llCweitTLx5Dt/Ytw44jIo0slnMEKbuLQNSGGF8nCeDDzzfwl3c/5/yxfXTTmEiSimWPYIaZvUZk3GKInDx+JbhI0li27Kjg+mfm079zG34ycXjYcUQkJLGMWfwjM/sG8DUi/Yamuvs/A08mgXJ3bnlxASWlu/jnlUfROi2W7wQi0hTVNx7BYOAeYCCwALjB3Vc3VjAJ1gsfr2Z6fjE3ThjKqF4aalIkmdV3rP9RIBf4JpEOpH/Y1zc3swlmttjMCs3s5nqWO8zMqnQ1UuNYsWEHt79UwNj+nfjeMQPDjiMiIavveEA7d38o+nixmX28L28cvQP5T0SGulwFzDazl919UR3L/Qp4bV/eX/ZPZVXkUtGUFON3544mVZeKiiS9+gpBSzM7hP+OQ9Cq5rS7760wjAUK3X0pgJlNI9KvaFGt5a4BngcO28fssh/++FYhH6/YzP3nH0LPjq3CjiMicaC+QlAM3Ftjek2NaQfG7+W9ewIra0yvAsbVXMDMegJnRd9rj4XAzKYAUwD69FEH7P01d/km7v/XZ3zjkJ6cnpURdhwRiRP1DUxz/AG+d13HHLzW9O+Bm9y9ymzPhyjcfSowFSA7O7v2e0gMSssquO4f88jo2IqfnjEy7DgiEkeCvGZwFdC7xnQvoKjWMtnAtGgR6AKcamaV7v5igLmS0v+9vIjVm3byzPeOoF1LNY8Vkf8KshDMBgabWX9gNXAecEHNBWoOg2lmjwO5KgINLze/iOc/XsW1Jwwmu1+nsOOISJwJrBC4e6WZXU3kaqBU4FF3X2hmV0TnPxjUZ8t/FW3eyS0vLGB0745cO35Q2HFEJA7ttRBY5LjNhcAAd78zOl5xD3eftbfXuvsr1GpHsacC4O6XxpRYYlZV7Vz/zHyqqp37zhtNs1S1iBKRr4ply/Bn4Ajg/Oh0KZH7AyTOPfTeUmYu3cgdp4+kb+c2YccRkTgVy6Ghce5+qJnNA3D3TWaWFnAuOUAFq7fw29cXc+qoHpw9plfYcUQkjsWyR1ARvfvX4cvxCKoDTSUHZGd5FddOm0fnNi34xVmjqO/SXBGRWArB/cA/gW5m9nPgP8AvAk0lB+Rn0xexbP127j0ni46ttfMmIvWLpQ31U2Y2FziByE1iZ7r7J4Enk/3y5qK1PPXRCqYcM4AjB3UJO46IJIBYrhrqA+wAcmo+5+4rggwm+25daRk3Pp/PiPT2/PCkIWHHEZEEEcvJ4ulEzg8Y0BLoDywG1Kcgjrg7P3o2n+27Krn//NG0aJYadiQRSRCxHBoaVXPazA4FvhdYItkvT3zwBe8sKeGuM0YyqFu7sOOISALZ5zuMou2n1TI6jixZW8ovXv2U8cO6cdHhfcOOIyIJJpZzBNfXmEwBDgVKAksk+6Ssooprn55H+5bN+PW3MnWpqIjss1jOEdQ8zlBJ5JzB88HEkX31m9cW8+maUh679DC6tG0RdhwRSUD1FoLojWRt3f1HjZRH9sF7n5XwyH+WcckRfTl+WLew44hIgtrjOQIza+buVUQOBUmc2bi9nB8+k8egbm255dThYccRkQRW3x7BLCJFYL6ZvQw8C2zfPdPdXwg4m+yBu/PjF/LZtKOcxyYfRsvmulRURPZfLOcIOgEbiIwrvPt+AgdUCELyj9kreW3hWm49dTgjMzqEHUdEElx9haBb9IqhAv5bAHbTuMEhWVqyjZ/mLOKoQZ35ztf67/0FIiJ7UV8hSAXaEtsg9NIIKqqque4f80lrlsJvzx5NSoouFRWRA1dfISh29zsbLYns1e/fXEL+qi08cOGh9OjQMuw4ItJE1Hdnsb5uxpGPlm7gz29/zjnZvThlVHrYcUSkCamvEJzQaCmkXlt2VnD9M3n07dSaOyap15+INKw9Hhpy942NGUT27PaXCliztYznrjiCNi1iudBLRCR2+9x0ThrXi/NW89L8Iq47YTCH9Dko7Dgi0gSpEMSxlRt38JMXC8juexBXHj8o7Dgi0kSpEMSpqmrn+mfmA/C7c0eTqktFRSQgOuAcpx54u5DZX2zid+dm0btT67DjiEgTpj2CODR/5WZ+9+ZnnJ6VwZmje4YdR0SaOBWCOLN9VyXXTZtHj/YtuevMgzXQjIgEToeG4sydOYtYvnEH0y4/nA6tmocdR0SSgPYI4siMgmL+MWcl3z92IOMGdA47jogkCRWCOLFmSxk3v7CAzF4duO7rQ8KOIyJJJNBCYGYTzGyxmRWa2c11zL/QzPKjPx+YWVaQeeJVdbXzw2fns6uimt+fO5q0ZqrPItJ4AtviRMc7/hNwCjACON/MRtRabBlwrLtnAncBU4PKE88efX8Z7xdu4PZJIxjQtW3YcUQkyQT51XMsUOjuS929HJgGnFFzAXf/wN03RSdnAr0CzBOXFhZt4dczFnPSiO6cd1jvsOOISBIKshD0BFbWmF4VfW5PvgO8WtcMM5tiZnPMbE5JSUkDRgxXWUUVP5g2n46tm3P3NzN1qaiIhCLIQhDzyGZmdjyRQnBTXfPdfaq7Z7t7dteuXRswYrh++conFK7bxj1nZ9GpTVrYcUQkSQV5H8EqoOaxjl5AUe2FzCwTeBg4xd03BJgnrrz16Tqe+HA5lx3Vn2OGNJ3iJiKJJ8g9gtnAYDPrb2ZpwHnAyzUXMLM+wAvAxe6+JMAsceW9z0q45ul5DOvRjhsnDA07jogkucD2CNy90syuBl4DUoFH3X2hmV0Rnf8gcDvQGfhz9Ph4pbtnB5UpHjw3dxU3P5/PoG5teWzyYbRsnhp2JBFJcuZe52H7uJWdne1z5swJO8Y+c3f+8O9C7n1jCUcN6swDF42hfUu1kBCRxmFmc/f0RVu9hhpBRVU1P3mxgGmzV/KNQ3ty9zcyddOYiMQNFYKAbdtVyVVPfcw7S0q4Zvwgrj9xiC4TFZG4okIQoHVby5j8+Gw+XVPKL78xivPH9gk7kojIV6gQBKRwXSnffnQ2m3aU8/Al2Rw/rFvYkURE6qRCEICPlm7g8ifnkNYslX9MOYJRvTqEHUlEZI9UCBrYy3lF3PBMHr07teLxyWM13rCIxD0Vggbi7kx9dym/fPVTxvbrxNRLxtCxtdpGiEj8UyFoAFXVzk9zFvLkh8s5LTOd356dpRvFRCRhqBAcoJ3lVVw7bR5vLFrLlGMGcPOEYaSk6PJQEUkcKgQHYMO2XXzniTnkrdrMT08fybeP7Bd2JBGRfaZCsJ+Wrd/OpY/NYs2WMh64cAwTDu4RdiQRkf2iQrAfPl6xie8+Eel39PSUwzm0z0EhJxIR2X8qBPtoRsEafjBtHj06tOSJyWPp16VN2JFERA6ICsE+ePz9Zfw0dxFZvTryyLez6dy2RdiRREQOmApBDKqrnV+++gkPvbeME0d05/7zDqFVmi4PFZGmQYVgL8oqqvjhs3lMzy/mkiP6csekkaTq8lARaUJUCOqxeUc5U56cy6wvNnLLqcO4/OgBaiEtIk2OCsEerNy4g0sfm8XKjTv5w/mHMCkrI+xIIiKBUCGow4JVW5j8+GzKK6v463fGMm5A57AjiYgERoWglrc+XcdVf/+Yg1qn8fTl4xjcvV3YkUREAqVCUMPTs1Zw24sFDOvRjscuPYxu7VuGHUlEJHAqBERaSN/7xhL+8O9Cjh3SlT9feChtWuiPRkSSQ9Jv7corq7n5+XxemLeac7N787OzDqZ5akrYsUREGk1SF4KtZRV8/29zeb9wA9efOIRrxg/S5aEiknSSthAUb9nJ5MdmU7huG/ecncW3xvQKO5KISCiSshB8UryVyY/NZtuuSh6bfBhHD+4adiQRkdAkXSF4v3A9V/x1Lq1bpPLM945gREb7sCOJiIQqqQrBCx+v4sbn8hnYtS2PTT6MjI6two4kIhK6pCkE81Zs4vpn8jhyYGceuGgMHVo1DzuSiEhcSJrrJIs2lwFwx6SRKgIiIjUkTSHYTVeHioj8r0ALgZlNMLPFZlZoZjfXMd/M7P7o/HwzOzTIPCIi8lWBFQIzSwX+BJwCjADON7MRtRY7BRgc/ZkCPBBUHhERqVuQewRjgUJ3X+ru5cA04Ixay5wBPOkRM4GOZpYeYCYREaklyELQE1hZY3pV9Ll9XQYzm2Jmc8xsTklJyX6F6dGhJaeO6kFbNZMTEfkfQW4V6zot6/uxDO4+FZgKkJ2d/ZX5sRjT9yDG9B2zPy8VEWnSgtwjWAX0rjHdCyjaj2VERCRAQRaC2cBgM+tvZmnAecDLtZZ5GbgkevXQ4cAWdy8OMJOIiNQS2KEhd680s6uB14BU4FF3X2hmV0TnPwi8ApwKFAI7gMlB5RERkboFeubU3V8hsrGv+dyDNR47cFWQGUREpH5Jd2exiIj8LxUCEZEkp0IgIpLkVAhERJKcRc7XJg4zKwGW7+fLuwDrGzBOItA6Jwetc3I4kHXu6+51jsubcIXgQJjZHHfPDjtHY9I6Jwetc3IIap11aEhEJMmpEIiIJLlkKwRTww4QAq1zctA6J4dA1jmpzhGIiMhXJdsegYiI1KJCICKS5JpkITCzCWa22MwKzezmOuabmd0fnZ9vZoeGkbMhxbDOF0bXNd/MPjCzrDByNqS9rXON5Q4zsyoz+1Zj5gtCLOtsZseZ2XwzW2hm7zR2xoYWw7/tDmaWY2Z50XVO6C7GZvaoma0zs4I9zG/47Ze7N6kfIi2vPwcGAGlAHjCi1jKnAq8SGSHtcOCjsHM3wjofCRwUfXxKMqxzjeX+TaQL7rfCzt0If88dgUVAn+h0t7BzN8I63wL8Kvq4K7ARSAs7+wGs8zHAoUDBHuY3+ParKe4RjAUK3X2pu5cD04Azai1zBvCkR8wEOppZemMHbUB7XWd3/8DdN0UnZxIZDS6RxfL3DHAN8DywrjHDBSSWdb4AeMHdVwC4e6Kvdyzr7EA7MzOgLZFCUNm4MRuOu79LZB32pMG3X02xEPQEVtaYXhV9bl+XSST7uj7fIfKNIpHtdZ3NrCdwFvAgTUMsf89DgIPM7G0zm2tmlzRaumDEss5/BIYTGeZ2AfADd69unHihaPDtV6AD04TE6niu9jWysSyTSGJeHzM7nkgh+FqgiYIXyzr/HrjJ3asiXxYTXizr3AwYA5wAtAI+NLOZ7r4k6HABiWWdTwbmA+OBgcAbZvaeu28NOFtYGnz71RQLwSqgd43pXkS+KezrMokkpvUxs0zgYeAUd9/QSNmCEss6ZwPTokWgC3CqmVW6+4uNkrDhxfpve727bwe2m9m7QBaQqIUglnWeDNztkQPohWa2DBgGzGqciI2uwbdfTfHQ0GxgsJn1N7M04Dzg5VrLvAxcEj37fjiwxd2LGztoA9rrOptZH+AF4OIE/nZY017X2d37u3s/d+8HPAdcmcBFAGL7t/0ScLSZNTOz1sA44JNGztmQYlnnFUT2gDCz7sBQYGmjpmxcDb79anJ7BO5eaWZXA68RueLgUXdfaGZXROc/SOQKklOBQmAHkW8UCSvGdb4d6Az8OfoNudITuHNjjOvcpMSyzu7+iZnNAPKBauBhd6/zMsREEOPf813A42a2gMhhk5vcPWHbU5vZ08BxQBczWwXcATSH4LZfajEhIpLkmuKhIRER2QcqBCIiSU6FQEQkyakQiIgkORUCEZEkp0IgcSnaLXR+jZ9+9Sy7rQE+73EzWxb9rI/N7Ij9eI+HzWxE9PEtteZ9cKAZo++z+8+lINpxs+Nelh9tZqc2xGdL06XLRyUumdk2d2/b0MvW8x6PA7nu/pyZnQTc4+6ZB/B+B5xpb+9rZk8AS9z95/UsfymQ7e5XN3QWaTq0RyAJwczamtm/ot/WF5jZVzqNmlm6mb1b4xvz0dHnTzKzD6OvfdbM9raBfhcYFH3t9dH3KjCz66LPtTGz6dH+9wVmdm70+bfNLNvM7gZaRXM8FZ23Lfr7HzW/oUf3RL5pZqlm9hszm22RHvPfi+GP5UOizcbMbKxFxpmYF/09NHon7p3AudEs50azPxr9nHl1/TlKEgq797Z+9FPXD1BFpJHYfOCfRO6Cbx+d14XIXZW792i3RX//ELg1+jgVaBdd9l2gTfT5m4Db6/i8x4mOVwCcDXxEpHnbAqANkfbGC4FDgG8CD9V4bYfo77eJfPv+MlONZXZnPAt4Ivo4jUgXyVbAFOC26PMtgDlA/zpybquxfs8CE6LT7YFm0cdfB56PPr4U+GON1/8CuCj6uCORHkRtwv771k+4P02uxYQ0GTvdffTuCTNrDvzCzI4h0jqhJ9AdWFPjNbOBR6PLvuju883sWGAE8H60tUYakW/SdfmNmd0GlBDp0HoC8E+PNHDDzF4AjgZmAPeY2a+IHE56bx/W61XgfjNrAUwA3nX3ndHDUZn231HUOgCDgWW1Xt/KzOYD/YC5wBs1ln/CzAYT6UTZfA+ffxJwupndEJ1uCfQhsfsRyQFSIZBEcSGR0afGuHuFmX1BZCP2JXd/N1ooTgP+ama/ATYBb7j7+TF8xo/c/bndE2b29boWcvclZjaGSL+XX5rZ6+5+Zywr4e5lZvY2kdbJ5wJP7/444Bp3f20vb7HT3UebWQcgF7gKuJ9Iv5233P2s6In1t/fwegO+6e6LY8kryUHnCCRRdADWRYvA8UDf2guYWd/oMg8BjxAZ7m8mcJSZ7T7m39rMhsT4me8CZ0Zf04bIYZ33zCwD2OHufwPuiX5ObRXRPZO6TCPSKOxoIs3UiP7+/u7XmNmQ6GfWyd23ANcCN0Rf0wFYHZ19aY1FS4kcItvtNeAai+4emdkhe/oMSR4qBJIongKyzWwOkb2DT+tY5jhgvpnNI3Ic/z53LyGyYXzazPKJFIZhsXygu39M5NzBLCLnDB5293nAKGBW9BDNrcDP6nj5VCB/98niWl4nMi7tmx4ZfhEi40QsAj62yKDlf2Eve+zRLHlEWjP/msjeyftEzh/s9hYwYvfJYiJ7Ds2j2Qqi05LkdPmoiEiS0x6BiEiSUyEQEUlyKgQiIklOhUBEJMmpEIiIJDkVAhGRJKdCICKS5P4fcblYXLAclPwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba9a48",
   "metadata": {},
   "source": [
    "예시\n",
    "# Call-back 함수 validation에 setting 하는 방법\n",
    "# CheckPoint: Epoch 마다 validation 성능을 검증하여, best performance 일 경우 저장\n",
    "CP = ModelCheckpoint(filepath='-{epoch:03d}-{loss:.4f}-{accuracy:.4f}-{val_loss:.4f}.hdf5',\n",
    "            monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "#minitor -> loss -> val_loss\n",
    "# Learning Rate 줄여나가기\n",
    "LR = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3,\n",
    "                       verbose=1, min_lr=1e-8)\n",
    "# factor: Learning rate에 곱할 것.\n",
    "#0.1 -> 0.08 -> 0.064 ....\n",
    "#monitor='loss' -> monitor='val_loss'\n",
    "CALLBACK = [CP, LR]\n",
    "\n",
    "######## Validation을 fit에 추가\n",
    "model.fit(x=InputFeature, y=Label, epochs=300, shuffle=True)\n",
    "###validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
